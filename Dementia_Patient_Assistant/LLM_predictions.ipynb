{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "707c5590-ee1f-4e29-9172-d397b0c7767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from textwrap import dedent\n",
    "from typing import Dict, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import os\n",
    "from datasets import Dataset, load_dataset\n",
    "import warnings\n",
    "\n",
    "from peft import LoraConfig, PeftModel, TaskType, get_peft_model, prepare_model_for_kbit_training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, pipeline, AutoConfig\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM, SFTConfig\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d222f4dc-13fc-4c4b-b564-9e80f3c3e9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['questions', 'answers', 'text', 'token_count'],\n",
       "        num_rows: 189\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['questions', 'answers', 'text', 'token_count'],\n",
       "        num_rows: 38\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['questions', 'answers', 'text', 'token_count'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files = {\"train\" : \"train.json\", \"validation\" : \"val.json\", \"test\" : \"test.json\", }\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "766206af-db16-4252-8d07-6885f1cb782c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a9923c293a4f309c20f222f46b16c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = 'finetuned_llama_medicare'\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_types=\"nf4\",\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast = True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config = quantization_config,\n",
    "    # torch_dtype = torch.float16,\n",
    "    # offload_folder = \"./offload\",\n",
    "    device_map = \"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3e6bfeb-1d0b-489b-85d3-818d13ab28e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    task = \"text-generation\",\n",
    "    model = model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens = 512,\n",
    "    return_full_text = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ed9668c-d2da-4629-bf7a-6bb8d75c6025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_prompt(data_row):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "        {row[\"questions\"]}\n",
    "        You are an assistant for someone who is a patient with dementia, give appropriate and kind responses.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\":\"system\",\n",
    "            \"content\":\"Use only the information to answer the question\",\n",
    "        },\n",
    "        {\"role\" : \"user\", \"content\":prompt},\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize = False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a780b143-48a3-4d61-88a9-dff6635d9d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>>\n",
      "Use only the information to answer the question\n",
      "<</SYS>>\n",
      "\n",
      "\n",
      "What lessons did Arjun learn from his uncle Sajan’s journey as a successful entrepreneur about balancing risk and reward?\n",
      "You are an assistant for someone who is a patient with dementia, give appropriate and kind responses. [/INST]\n"
     ]
    }
   ],
   "source": [
    "row = dataset[\"test\"][0]\n",
    "prompt = create_test_prompt(row)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d46d97be-591b-4c8f-b4ad-0d1af55e6f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    answer : Sajan’s experiences highlighted the importance of strategic planning and perseverance, influencing Arjun’s approach to managing business ventures.\n",
      "    prediction :   Arjun’s uncle Sajan’s entrepreneurial journey taught him the importance of calculated risks. He showed how taking calculated risks can lead to greater rewards. Arjun learned that balancing calculated risks with careful planning and research can lead to long-term success. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(prompt)\n",
    "response = f\"\"\"\n",
    "    answer : {row[\"answers\"]}\n",
    "    prediction : {outputs[0][\"generated_text\"]}\n",
    "\"\"\"\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34ed79a4-ece4-4b5e-9cb7-073cd2b98a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>>\n",
      "Use only the information to answer the question\n",
      "<</SYS>>\n",
      "\n",
      "\n",
      "Who is Malini and what is her relationship with Arjun?\n",
      "You are an assistant for someone who is a patient with dementia, give appropriate and kind responses. [/INST]\n"
     ]
    }
   ],
   "source": [
    "row = dataset[\"test\"][1]\n",
    "prompt = create_test_prompt(row)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0998b159-c246-416c-82d5-e9a5c8037123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    answer : Malini is Arjun’s wife and childhood sweetheart. She is a software engineer and a steady presence in Arjun’s life, balancing his ambitious spirit with pragmatism and warmth. Their partnership is grounded in shared values, mutual respect, and a deep history of growing up and building a life together.\n",
      "    prediction :  Oh, such a lovely memory! Malini is Arjun’s wife, and they were so happy together. Malini would often surprise him with his favorite meals and reminisce about their adventures. She’d make him feel loved and cherished. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(prompt)\n",
    "response = f\"\"\"\n",
    "    answer : {row[\"answers\"]}\n",
    "    prediction : {outputs[0][\"generated_text\"]}\n",
    "\"\"\"\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
