{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83b28643-32a6-4114-86c0-eb15674980ca",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "d5ea3290-9626-4562-b943-ae8045dd8164",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/wav2vec2-base-960h and revision 55bb623 (https://huggingface.co/facebook/wav2vec2-base-960h).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "p = pipeline(\"automatic-speech-recognition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a96ca0bd-7430-416e-aaed-6fcd1c3858b7",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "f007b3ed-0ae3-424b-9189-9a3b639c7294",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef6913ba-0a1a-46e5-8255-509c53527848",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "0d5a37f1-fa15-4641-96ca-8a6b2c69d9c2",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "class audi:\n",
    "    def __init__(self):\n",
    "        self.text_f = \" \"\n",
    "\n",
    "    def transcribe(self,audio, state=\"\"):\n",
    "        time.sleep(3)\n",
    "        text = p(audio)[\"text\"]\n",
    "        state += text + \" \"\n",
    "        self.text_f += text + \" \"\n",
    "        return state, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c66333f7-84e4-4b0b-a9d4-9c1ee7fb7c4a",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "d44e4ab5-a9fa-42ee-8752-1689e1b1187e",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikas\\AppData\\Local\\Temp\\ipykernel_22832\\21486067.py:6: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  gr.inputs.Audio(source=\"microphone\", type=\"filepath\"),\n",
      "C:\\Users\\vikas\\AppData\\Local\\Temp\\ipykernel_22832\\21486067.py:6: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  gr.inputs.Audio(source=\"microphone\", type=\"filepath\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikas\\anaconda3\\envs\\tf\\lib\\site-packages\\gradio\\processing_utils.py:188: UserWarning: Trying to convert audio automatically from int32 to 16-bit int format.\n",
      "  warnings.warn(warning.format(data.dtype))\n"
     ]
    }
   ],
   "source": [
    "obj = audi()\n",
    "\n",
    "gr.Interface(\n",
    "    fn=obj.transcribe, \n",
    "    inputs=[\n",
    "        gr.inputs.Audio(source=\"microphone\", type=\"filepath\"),\n",
    "        'state'\n",
    "    ],\n",
    "    outputs=[\n",
    "        \"textbox\",\n",
    "        \"state\"\n",
    "    ],\n",
    "    live=True).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "49eee163-22db-42cd-9a6a-5e56be922659",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "a927757a-8196-4ea5-84c7-47107eecfaae",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' HE HOW ARE YOU DOING '"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.text_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ad92acf-4bb5-4dad-9add-beda719435ca",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "36eb31bf-56d9-4736-b2c3-3b0c07c560a9",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d98847d-5482-4b54-9fab-225231f1b86e",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "f138daf5-40a3-4a89-87de-5c12ea7e45b5",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "emotion_analysis = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4998a307-d96e-423b-b389-7372f457a793",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "badb0fab-245a-4ffb-8f11-f5511d9aa771",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "sentences = [obj.text_f]\n",
    "results = emotion_analysis(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "55e3cb0b-415b-49fc-a151-ac2598c5abe2",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "c7d0e11a-c0a0-4e57-b500-46ffd6950a4d",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_val = list(results[0].values())\n",
    "int(emotion_val[0][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "564ee002-a489-49e3-839d-b1cb500bab6e",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "df34c9f1-67a8-4949-8253-de416c54d362",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9009239f-22d2-44bd-9fff-3edbd55e6c0a",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "a8de2c10-1406-4c3a-8348-1d98e53dfdae",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "738e7fdd-231c-48f8-be86-64e386e3c436",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "9f6a11c9-4ae9-4c29-abab-500dd87e668b",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# load_dotenv(find_dotenv())\n",
    "# embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59400556-d4b7-4cf3-9369-60eab4d06f6e",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "5c6973e3-bcb6-4c9b-b4e0-02f438398689",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# def create_db_from_life(life_doc):\n",
    "#     loader = TextLoader(life_doc)\n",
    "#     transcript = loader.load()\n",
    "\n",
    "#     text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "#     docs = text_splitter.split_documents(transcript)\n",
    "\n",
    "#     db = FAISS.from_documents(docs, embeddings)\n",
    "#     return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c34356b-1401-4665-9dd8-6f17fce478c9",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "54442806-af67-4831-a446-e80b7d34f6bb",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# def get_response_from_query(db, query, k=4):\n",
    "#     docs = db.similarity_search(query, k=k)\n",
    "#     docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "\n",
    "#     chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.2)\n",
    "\n",
    "#     # Template to use for the system message prompt\n",
    "#     template = \"\"\"\n",
    "#         You are a Patient assistant that responds to questions and thoughts of the patient and give\n",
    "#         a response. He is currently happy, so respond accordingly.\n",
    "        \n",
    "#         If the person asks something on their personal life, Only use the information from the transcript to answer the question.\n",
    "        \n",
    "#         If you feel like you don't have enough information to answer the question, say \"Im but I don't know emma\".\n",
    "        \n",
    "#         \"\"\"\n",
    "\n",
    "#     system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "#     # Human question prompt\n",
    "#     human_template = \"Respond as a patient assistant: {question}\"\n",
    "#     human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "#     chat_prompt = ChatPromptTemplate.from_messages(\n",
    "#         [system_message_prompt, human_message_prompt]\n",
    "#     )\n",
    "\n",
    "#     chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "\n",
    "#     response = chain.run(question=query, docs=docs_page_content)\n",
    "#     response = response.replace(\"\\n\", \"\")\n",
    "#     return response, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb46afb-256a-4c1f-9bd7-55560a1eaee6",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "450868d5-54e0-4efb-9da2-0cc911028616",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# doc = \"life.txt\"\n",
    "# db = create_db_from_life(doc)\n",
    "\n",
    "# query = \"Hello !\"\n",
    "# response, docs = get_response_from_query(db, query)\n",
    "# print(textwrap.fill(response, width=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f67331dc-758e-49ff-9e16-04d8f4f0aa8a",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "2292da13-0f33-4ed1-9d4c-cfe39bc21f37",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "\n",
    "# llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "# prompt = \"Hello\"\n",
    "# print(llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3161c6d-4ee9-4cea-8d2d-6bfb9a3fb840",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "8cc2354b-8ad7-4560-ad9a-079bd4480967",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"cerebras/Cerebras-GPT-2.7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c71bda5-68de-49cb-8a9d-1e55927c43c3",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "02fb3ae3-f3c2-43e3-bba4-1d97cc87d411",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", model=model, tokenizer=tokenizer,\n",
    "    max_new_tokens=100, early_stopping=True, no_repeat_ngram_size=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f1d1918-42bd-4d13-acf4-d6eef6b0aa53",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "0c15481d-9e8f-4f9a-b54e-b6046e49f6f7",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "# pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=10)\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d5ad1a6-e0b2-4326-941f-ec69b53cefc4",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "d2b8d72b-1909-476d-8a4e-d870f61e3ee4",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    prompt=prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1bbb2457-5317-4aa2-a45d-dac986b86fb8",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "911b6de7-1cb3-44cc-aeab-cb7476a2b71a",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikas\\anaconda3\\envs\\tf\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\vikas\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:430: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "When I opened the door, I saw a\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "woman in a white dress,\n",
      "with a black veil over her face.\n",
      "She was holding a baby in her arms.\n"
     ]
    }
   ],
   "source": [
    "response = chain.run(\"\"\"When I opened the door, I saw a\"\"\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ca093e7-8559-44f9-b70b-23d3744dd0d3",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "a822f5be-e2f7-4981-ba3e-71375ab1eb3f",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
    "# embeddings = HuggingFaceInstructEmbeddings(model_name = 'hkunlp/instructor-large', model_kwargs={\"device\":\"cuda\"})\n",
    "# print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbfc52b-22d0-4fc4-aad4-743cad602f89",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "6941b582-1988-4fee-8ff1-3d8107e34a96",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "from InstructorEmbedding import INSTRUCTOR\n",
    "model = INSTRUCTOR('hkunlp/instructor-large')\n",
    "sentence = \"3D ActionSLAM: wearable person tracking in multi-floor environments\"\n",
    "instruction = \"Represent the Science title:\"\n",
    "embeddings = model.encode([[instruction,sentence]])\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "582b92d2-220c-427a-bffc-24d83ad1b93e",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "34d6ebcd-e096-4cd7-b44e-6c5f6609047d",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "def create_db_from_life(life_doc):\n",
    "    loader = TextLoader(life_doc)\n",
    "    transcript = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(transcript)\n",
    "    \n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5b2d4e0-442a-4975-a907-17be613be946",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "c8bedba0-9994-45c6-be5e-4ef6cf418366",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "865fb30d-f960-45b7-a9ac-c62a45ce41c3",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "3b9ba064-bec4-407f-86f4-018ffc00e0aa",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": [
    "def get_response_from_query(db, query, k=4):\n",
    "    docs = db.similarity_search(query, k=k)\n",
    "    docs_page_content = \" \".join([d.page_content for d in docs])\n",
    "    llm = HuggingFacePipeline(pipeline=pipe)\n",
    "    # chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.2)\n",
    "\n",
    "    # Template to use for the system message prompt\n",
    "    template = \"\"\"\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "    # system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "    system_message_prompt = PromptTemplate(\n",
    "        input_variables=[\"input\"],\n",
    "        template=template,\n",
    "    )\n",
    "    # Human question prompt\n",
    "    human_template = \"Respond normally like a person would to:{question}\"\n",
    "    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        # [system_message_prompt, human_message_prompt]\n",
    "        (\"system\", template),\n",
    "        (\"human\", human_template)\n",
    "    ])\n",
    "\n",
    "    chain = LLMChain(llm=llm, prompt=chat_prompt)\n",
    "\n",
    "    response = chain.run(question=query, docs=docs_page_content)\n",
    "    response = response.replace(\"\\n\", \"\")\n",
    "    return response, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "714dc496-0a13-42ee-8bcd-65320b4faa40",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "transparent",
     "id": "6e1f9cdc-b2c3-4170-a3a3-571b6712ff3b",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikas\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:430: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!English: I am fine.\n"
     ]
    }
   ],
   "source": [
    "doc = \"life.txt\"\n",
    "db = create_db_from_life(doc)\n",
    "\n",
    "query = obj.text_f\n",
    "response, docs = get_response_from_query(db, query)\n",
    "print(textwrap.fill(response, width=50))"
   ]
  }
 ],
 "metadata": {
  "canvas": {
   "colorPalette": [
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit"
   ],
   "parameters": [],
   "version": "1.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
