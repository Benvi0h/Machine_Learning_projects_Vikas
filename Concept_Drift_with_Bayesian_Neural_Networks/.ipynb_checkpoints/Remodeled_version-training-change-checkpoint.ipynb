{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad8cb6a7-3510-4d8f-9b07-575732a96f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy\n",
    "from scipy.stats import wilcoxon, ttest_ind\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kstest\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c199a33d-521a-4889-9642-52c9b7568fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reinforced_DNN:\n",
    "    def __init__(self,\n",
    "                 state_space, \n",
    "                 action_space, \n",
    "                 input_dim = None, \n",
    "                 activation = \"relu\", \n",
    "                 input_units = 12,\n",
    "                 learning_rate=0.1, \n",
    "                 discount_factor=0.9, \n",
    "                 exploration_rate=1.0, \n",
    "                 exploration_decay=0.995):\n",
    "\n",
    "        self.model = None\n",
    "        self.input_units_DNN = input_units\n",
    "        self.activation_DNN = activation\n",
    "        self.input_dim_DNN = input_dim\n",
    "        # print(input_dim)\n",
    "        # self.state_space = state_space\n",
    "        # self.action_space = action_space\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.exploration_rate = exploration_rate\n",
    "        self.exploration_decay = exploration_decay\n",
    "        self.q_table = np.zeros((state_space, action_space))\n",
    "\n",
    "        self.final_performance = []\n",
    "        self.initial_performance = []\n",
    "        self.performance_improvement = []\n",
    "        self.drift_points = []\n",
    "        \n",
    "        self.state_ref_data = {}\n",
    "        self.state_ref_weights = {}\n",
    "        self.number_of_actions = 0\n",
    "        self.model_current_state = 0\n",
    "        self.action_threshold = action_space\n",
    "\n",
    "        self.display_loss = []\n",
    "        self.dispaly_accuracy = []\n",
    "        \n",
    "    class DNN_model(Model):\n",
    "        def __init__(self, parent):\n",
    "            super(Reinforced_DNN.DNN_model, self).__init__()\n",
    "            \n",
    "            self.dense1 = Dense(units = parent.input_units_DNN, activation = parent.activation_DNN, input_dim = parent.input_dim_DNN)\n",
    "            self.dense2 = Dense(units = parent.input_units_DNN * 2, activation = parent.activation_DNN)\n",
    "            self.dense3 = Dense(units = parent.input_units_DNN * 4, activation = parent.activation_DNN)\n",
    "            self.dense4 = Dense(units = parent.input_units_DNN * 2, activation = parent.activation_DNN)\n",
    "            self.dense5 = Dense(units = parent.input_units_DNN, activation = parent.activation_DNN)\n",
    "            \n",
    "            self.output_layer = Dense(units = 1, activation = parent.activation_DNN)\n",
    "\n",
    "        def call(self,  x):\n",
    "            x = self.dense1(x)\n",
    "            x = self.dense2(x)\n",
    "            x = self.dense3(x)\n",
    "            x = self.dense4(x)\n",
    "            x = self.dense5(x)\n",
    "            \n",
    "            x = self.output_layer(x)\n",
    "            return x\n",
    "            \n",
    "    # Custom callback to stop training at desired accuracy\n",
    "    @tf.function(jit_compile = True)\n",
    "    class StopAtAccuracy(tf.keras.callbacks.Callback):\n",
    "        def __init__(self, target, target_loss, patience = 5):\n",
    "            super(Reinforced_DNN.StopAtAccuracy, self).__init__()\n",
    "            self.target_accuracy = target\n",
    "            self.target_loss = target_loss * 0.4\n",
    "            self.patience = patience\n",
    "            self.max_accuracy = 0\n",
    "            self.epochs_since_improvement = 0\n",
    "            \n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            current_accuracy = logs.get(\"accuracy\")\n",
    "            current_loss = logs.get(\"loss\")\n",
    "            \n",
    "            # if current_accuracy is not None and current_loss is not None:\n",
    "            # current_accuracy >= self.target_accuracy and\n",
    "            if  current_loss < self.target_loss and current_accuracy >= self.target_accuracy:\n",
    "                print(f\"\\nTarget accuracy ({self.target_accuracy:.2f}) and loss ({self.target_loss:.2f}) reached. Stopping training.\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "            # if current_accuracy > self.max_accuracy:\n",
    "            #     self.max_accuracy = current_accuracy\n",
    "            #     self.epochs_since_improvement = 0\n",
    "            # else:\n",
    "            #     self.epochs_since_improvement += 1\n",
    "                \n",
    "            # if self.epochs_since_improvement == self.patience:\n",
    "            #     print(f\"\\nNo improvement in accuracy for {self.patience} consecutive epochs. Stopping training.\")\n",
    "            #     self.model.stop_training = True\n",
    "            \n",
    "    @tf.function(jit_compile= True)\n",
    "    def create_new_action(self, data, target, target_state, model, previous_loss, target_accuracy = 0.80, init = 0):\n",
    "        print(f\"Model Compiled for new action\")\n",
    "        new_performance_loss = previous_loss + 0.1\n",
    "        while new_performance_loss > previous_loss:\n",
    "            if init == 0:\n",
    "                action_taken = random.choice(range(self.number_of_actions))\n",
    "            model.compile(\n",
    "                optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                loss=keras.losses.BinaryCrossentropy(),\n",
    "                metrics=[\n",
    "                    keras.metrics.BinaryAccuracy(),\n",
    "                    keras.metrics.FalseNegatives(),\n",
    "                    \"accuracy\"\n",
    "                ],\n",
    "            )\n",
    "            if init == 0:\n",
    "                model.load_weights(self.state_ref_weights[action_taken], skip_mismatch=True)\n",
    "            print(f\"Model Compiled...\")\n",
    "            target_accuracy = target_accuracy\n",
    "            early_stopping = EarlyStopping(\n",
    "                monitor='accuracy',          # Monitor the training accuracy\n",
    "                patience=0,                  # Stop as soon as condition is met\n",
    "                mode='max',                  # Maximize accuracy\n",
    "                min_delta=0.001,             # Minimum change to qualify as improvement\n",
    "                restore_best_weights=True\n",
    "            )\n",
    "            stop_at_accuracy = self.StopAtAccuracy(target=target_accuracy, target_loss = previous_loss)\n",
    "    \n",
    "            print(f\"Model Fitting...\")\n",
    "            print(f\"Target loss {previous_loss}\")\n",
    "            model.fit(x= data, y = target, epochs = 100, verbose = 0, callbacks=[stop_at_accuracy])\n",
    "            new_performance_loss = model.evaluate(data, target, verbose = 0)[0]\n",
    "            if new_performance_loss > previous_loss:\n",
    "                print(f\"Model training failed, new performance {new_performance_loss} is greater than the previous loss {previous_loss}\")\n",
    "\n",
    "        print(f\"Model trained from scratch, new performance loss : {new_performance_loss}\")\n",
    "        \n",
    "        if self.number_of_actions < self.action_threshold:\n",
    "            action_taken = self.number_of_actions\n",
    "            model.save_weights(f\"Model_weights/model_action{action_taken}.weights.h5\")\n",
    "            self.state_ref_weights[action_taken] = f\"Model_weights/model_action{action_taken}.weights.h5\"\n",
    "            print(f\"Model weights for action {action_taken} has been saved at {self.state_ref_weights[action_taken]}\")\n",
    "            reward = previous_loss - new_performance_loss\n",
    "            \n",
    "            print(f\"Model reward for new action {action_taken} : {reward}\\n\")\n",
    "            # self.update_q_table(target_state, action_taken, reward, target_state)\n",
    "            self.number_of_actions += 1\n",
    "            \n",
    "        else :   \n",
    "            action_taken = self.number_of_actions + 1\n",
    "            print(\"Action threshold reached... No new action can be added\")\n",
    "            \n",
    "        print(f\"Total number of actions : {self.number_of_actions}\\n\")   \n",
    "        return model, action_taken, reward\n",
    "        \n",
    "    def get_action(self, data, target, model, target_state, performance_threshold = 0.75):\n",
    "        ## This function determines the action that the model must take to achive goo performance\n",
    "        ## This takes the exploration and exploitation methods to determine its next actions\n",
    "        dup_model = model\n",
    "        action = 0 \n",
    "        reward = 0\n",
    "        action_taken = 0\n",
    "        new_performance = 0\n",
    "        print(\"Determining action ...\")\n",
    "        \n",
    "        ## First check the models performanceabs\n",
    "        current_performance_accuracy = round(model.evaluate(data, target, verbose = 0)[-1], 2)\n",
    "        previous_loss = round(model.evaluate(data, target, verbose = 0)[0], 2)\n",
    "        \n",
    "        if current_performance_accuracy < performance_threshold:\n",
    "            print(f\"Model's current performance {current_performance_accuracy} was less than the threshold : {performance_threshold}\")\n",
    "            # Exploration\n",
    "            if (random.uniform(0, 1) < self.exploration_rate and self.number_of_actions > 10):\n",
    "                print(\"Exploration action taken, model training start...\")\n",
    "                action_taken = random.choice(range(self.number_of_actions))\n",
    "                model.compile(\n",
    "                    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                    loss=keras.losses.BinaryCrossentropy(),\n",
    "                    metrics=[\n",
    "                        keras.metrics.BinaryAccuracy(),\n",
    "                        keras.metrics.FalseNegatives(),\n",
    "                        \"accuracy\"\n",
    "                    ],\n",
    "                )\n",
    "                model.load_weights(self.state_ref_weights[action_taken], skip_mismatch=True)\n",
    "                print(f\"model weights {action_taken} were loaded\")\n",
    "                # model.fit(x= data, y = target, epochs = 10, verbose = 0)\n",
    "                # print(f\"model {model} was fit using weights {action_taken}\\n\")\n",
    "                new_performance_loss = round(model.evaluate(data, target, verbose = 0)[0], 2)\n",
    "                new_performance_accuracy = round(model.evaluate(data, target, verbose = 0)[-1], 2)\n",
    "                \n",
    "                reward = previous_loss - new_performance_loss\n",
    "                \n",
    "                if new_performance_loss <= previous_loss:\n",
    "                    action = action_taken\n",
    "                else:\n",
    "                    action = action_taken\n",
    "                    model = dup_model\n",
    "                    \n",
    "                print(f\"Model's performance loss before weight fit {previous_loss} \\nModel's performance loss after weight fit {new_performance_loss}\")\n",
    "                print(f\"Model's performance accuracy before weight fit {current_performance_accuracy} \\nModel's performance loss after weight fit {new_performance_accuracy}\")\n",
    "            \n",
    "            else:       \n",
    "                # Exploitation\n",
    "                print(\"Exploitation action taken, model training start...\")\n",
    "                action_taken = np.argmax(self.q_table[target_state])\n",
    "                # model.compile(\n",
    "                #     optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                #     loss=keras.losses.BinaryCrossentropy(),\n",
    "                #     metrics=[\n",
    "                #         keras.metrics.BinaryAccuracy(),\n",
    "                #         keras.metrics.FalseNegatives(),\n",
    "                #         \"accuracy\"\n",
    "                #     ],\n",
    "                # )\n",
    "                model.load_weights(self.state_ref_weights[action_taken], skip_mismatch=True)\n",
    "                print(f\"model weights {action_taken} were loaded\")\n",
    "                # model.fit(x= data, y = target, epochs = 10, verbose = 0)\n",
    "                print(f\"model {model} was initialized using weights {action_taken}\\n\")\n",
    "                      \n",
    "                new_performance_loss = round(model.evaluate(data, target, verbose = 0)[0], 2)\n",
    "                new_performance_accuracy = round(model.evaluate(data, target, verbose = 0)[-1], 2)\n",
    "                \n",
    "                reward =  previous_loss - new_performance_loss \n",
    "                \n",
    "                if new_performance_loss < previous_loss:\n",
    "                    action = action_taken  \n",
    "                else:\n",
    "                    print(f\"New action created due to inadequate performance in exploit\\n\")\n",
    "                    # self.performance_history.append(new_performance_loss)\n",
    "                    model_res, action_taken, reward_r = self.create_new_action(data, target, target_state, model, previous_loss, performance_threshold)\n",
    "                    model = model_res\n",
    "                    action = action_taken\n",
    "                    reward = reward_r\n",
    "                    new_performance_loss = round(model.evaluate(data, target, verbose = 0)[0], 2)\n",
    "                    new_performance_accuracy = round(model.evaluate(data, target, verbose = 0)[-1], 2)\n",
    "                    \n",
    "                print(f\"Model's performance loss before weight fit {previous_loss} \\nModel's performance loss after weight fit {new_performance_loss}\")\n",
    "                print(f\"Model's performance accuracy before weight fit {current_performance_accuracy} \\nModel's performance loss after weight fit {new_performance_accuracy}\")\n",
    "                \n",
    "        elif current_performance_accuracy >= performance_threshold:\n",
    "            print(f\"No significant change in performance accuracy, so no new action\\n\")\n",
    "            action = 0 \n",
    "            reward = 0 \n",
    "            new_performance_loss = previous_loss\n",
    "            print(f\"Model's performance loss before weight fit {previous_loss} \\nModel's performance loss after weight fit {new_performance_loss}\")\n",
    "            print(f\"Model's performance accuracy before weight fit {current_performance_accuracy} \\nModel's performance loss after weight fit {current_performance_accuracy}\")\n",
    "\n",
    "        print(f\"\\nAction determination done\")    \n",
    "        \n",
    "        print(f\"Action taken : {action} \\nReward : {reward}\\n\")\n",
    "        return action, reward, new_performance_loss, model\n",
    "        \n",
    "    \n",
    "    def update_q_table(self, state, action, reward, next_state):\n",
    "        best_next_action = np.argmax(self.q_table[next_state])\n",
    "        self.q_table[state, action] += self.learning_rate * (reward + self.discount_factor * self.q_table[next_state, best_next_action] - self.q_table[state, action])\n",
    "    \n",
    "    def decay_exploration(self):\n",
    "        self.exploration_rate *= self.exploration_decay\n",
    "\n",
    "    def init_state(self, state, data):\n",
    "        self.state_ref_data[state] = data\n",
    "        return state\n",
    "        \n",
    "    def determine_state(self, current_data, wil_p_value = 0.5, evaluation = 0):\n",
    "        print(f\"Number of states available {len(self.state_ref_data)}\")\n",
    "        state_iter = 0\n",
    "        target = 10000\n",
    "        max_state = 0\n",
    "        similarity_score = []\n",
    "        \n",
    "        for state_iter, ref_data in enumerate(self.state_ref_data):\n",
    "            # print(f\"The current state {current_data}\")\n",
    "            # print(f\"The reference state {self.state_ref_data[ref_data]}\\n\")\n",
    "            # res = wilcoxon(x = current_data, y = self.state_ref_data[ref_data])\n",
    "            res = ttest_ind(a=current_data, b=self.state_ref_data[ref_data], equal_var=True)\n",
    "            similar_columns = list(res[1] <= np.full(res[1].shape, wil_p_value)).count(True)\n",
    "            if similar_columns > 2:\n",
    "                if similar_columns > max_state:\n",
    "                    target = state_iter\n",
    "                    similarity_score = res[1]\n",
    "                    max_state = similar_columns\n",
    "        if target != 10000:    \n",
    "            print(f\"The similarity score of target state {target} : {similarity_score}\")\n",
    "            # print(f\"The truth values with w_p-value {wil_p_value} is : {list(res[1] <= np.full(res[0].shape, wil_p_value)).count(True)}\")\n",
    "            # target = state_iter\n",
    "        \n",
    "        elif target == 10000:\n",
    "            if evaluation == 0:  \n",
    "                print(f\"No appropriate state found in the existing list, creating new state\") \n",
    "                state_iter += 1\n",
    "                target = self.init_state(state_iter, current_data)\n",
    "                print(f\"New state {target} created\")\n",
    "                print(f\"Target state : {target}\")\n",
    "                res = ttest_ind(a=current_data, b=self.state_ref_data[ref_data], equal_var=True)\n",
    "                similar_columns = list(res[1] > np.full(res[1].shape, 0.05)).count(True)\n",
    "                \n",
    "                print(f\"Number of similar columns {similar_columns}\\n\")\n",
    "                \n",
    "            if evaluation == 1:\n",
    "                eval_will_p_value = wil_p_value\n",
    "                print(f\"Similar state not found, finding the next best option...\")\n",
    "                \n",
    "                while(target == 10000):\n",
    "                    max_state_columns = 0\n",
    "                    eval_will_p_value -= 0.2 * eval_will_p_value\n",
    "                    print(f\"Search with p_value {eval_will_p_value}...\")\n",
    "                    for state_iter, ref_data in enumerate(self.state_ref_data):\n",
    "                        res = ttest_ind(a=current_data, b=self.state_ref_data[ref_data], equal_var=True)\n",
    "                        similar_columns = list(res[1] > np.full(res[1].shape, eval_will_p_value)).count(True)\n",
    "                        if similar_columns > 2:\n",
    "                            if similar_columns > max_state_columns:\n",
    "                                target = state_iter\n",
    "                                similarity_score = res[1]\n",
    "                                max_state_columns = similar_columns\n",
    "                    \n",
    "                    if target == 10000:\n",
    "                        print(\"Search failed, retrying...\\n\")\n",
    "                if target == 10000:\n",
    "                    print(f\"\\nNo state found, assigning random state\")\n",
    "                    target = random.choice(range(len(self.state_ref_data)))\n",
    "                else:\n",
    "                    print(f\"The similarity score of target state {target} : {similarity_score}\\n\")            \n",
    "\n",
    "        return target\n",
    "\n",
    "    def detect_drift(self, data, ref_data, ks_pvalue = 0.05):\n",
    "        test_stat = kstest(data, ref_data)\n",
    "        if list(test_stat[1] < np.full(test_stat[1].shape, ks_pvalue)).count(True) > 3:\n",
    "            return 1, test_stat\n",
    "        else:\n",
    "            return 0, test_stat\n",
    "        \n",
    "    def train_with_drift_detection(self, model, X_train, y_train, n_episodes = 1000, batch_size = 32, performance_threshold = 0.75, ks_pvalue = 0.05, wil_p_value = 0.05):\n",
    "        # model_current_state = 0\n",
    "        # print(n_episodes)\n",
    "        prev_loss = 0\n",
    "        for episode in range(n_episodes):\n",
    "            pos = random.randint(0, len(X_train) - batch_size)\n",
    "            batch_X = X_train[pos:pos+batch_size]\n",
    "            batch_y = y_train[pos:pos+batch_size]\n",
    "            \n",
    "            # print(batch_X.shape)\n",
    "            if episode != 0:\n",
    "                detect_drifted, detected_stat = self.detect_drift(batch_X, prev_data_x, ks_pvalue = ks_pvalue)\n",
    "                # target_state_eval = self.determine_state(batch_X, wil_p_value = wil_p_value, evaluation=1)\n",
    "                \n",
    "                # prev_loss = self.model.evaluate(prev_data_x, prev_data_y, verbose = 0)[0]\n",
    "                current_model_loss = self.model.evaluate(batch_X, batch_y, verbose = 0)[0]\n",
    "                \n",
    "            if (episode == 0):\n",
    "                print(\"Start Training ...\")\n",
    "                self.initial_performance.append(self.model.evaluate(batch_X, batch_y, verbose = 0)[0])\n",
    "                model(batch_X)\n",
    "                self.model_current_state = self.init_state(0 , batch_X) #Model state initialization = 0\n",
    "                print(f\"Model initialized with state {self.model_current_state}\")\n",
    "                r_model, action, reward = self.create_new_action(batch_X, batch_y, 0, model, 1, performance_threshold, init = 1)\n",
    "                print(f\"Model created with action {action} with accuracy {model.evaluate(batch_X, batch_y, verbose = 0)[-1]}\")\n",
    "                self.model  = r_model\n",
    "                prev_data_x = batch_X\n",
    "                prev_data_y = batch_y\n",
    "                prev_loss = self.model.evaluate(batch_X, batch_y, verbose = 0)[0]\n",
    "                self.final_performance.append(round(self.model.evaluate(batch_X, batch_y)[0], 2))\n",
    "                self.performance_improvement.append(reward)\n",
    "                self.update_q_table(self.model_current_state, action, reward, self.model_current_state)\n",
    "                \n",
    "                \n",
    "            elif (( detect_drifted == 1 or current_model_loss > prev_loss) and episode != 0):\n",
    "                ## Determine the target state for the model to reach, if there is no state that\n",
    "                ## currently does not accommodate the data, a new state will be created\n",
    "                self.initial_performance.append(current_model_loss)\n",
    "                if detect_drifted == 1:\n",
    "                    print(f\"Drift_detected in episode {episode}\")\n",
    "                    print(f\"Statistic values : {detected_stat[0]}\")\n",
    "                    print(f\"Statistic p-values : {detected_stat[1]}\\n\")\n",
    "                else:\n",
    "                    print(f\"Decline in model's performance in episode {episode}\")\n",
    "                    print(f\"Current model loss {current_model_loss}\")\n",
    "                    print(f\"Model loss previously {prev_loss}\")\n",
    "                    \n",
    "                print(\"Determining State...\")\n",
    "                target_state = self.determine_state(batch_X, wil_p_value = wil_p_value)\n",
    "                self.drift_points.append(episode)\n",
    "                action, reward, performance,r_model = self.get_action(batch_X, batch_y, self.model, target_state, performance_threshold = performance_threshold)\n",
    "                final_action = action\n",
    "                self.model = r_model\n",
    "                self.final_performance.append(performance)\n",
    "                self.performance_improvement.append(reward)\n",
    "                self.model_current_state = target_state\n",
    "                prev_loss = self.model.evaluate(batch_X, batch_y, verbose = 0)[0]\n",
    "                self.update_q_table(self.model_current_state, action, reward, target_state)\n",
    "                prev_data_x = batch_X\n",
    "                prev_data_y = batch_y\n",
    "                \n",
    "\n",
    "            else:\n",
    "                self.initial_performance.append(current_model_loss)\n",
    "                print(f\"No Drift_detected in episode {episode}\")\n",
    "                print(f\"No change in model performance :\")\n",
    "                print(f\"previous loss {prev_loss}\")\n",
    "                print(f\"current loss {current_model_loss}\\n\")\n",
    "                \n",
    "                print(\"No action performed\")\n",
    "                self.final_performance.append(current_model_loss)\n",
    "                self.performance_improvement.append(0)\n",
    "                ## Updating to the model's current state as there is no state change detected (drift) in this case\n",
    "                self.update_q_table(self.model_current_state, 0, 0, self.model_current_state)\n",
    "                prev_data_x = batch_X\n",
    "                prev_data_y = batch_y\n",
    "                prev_loss = current_model_loss\n",
    "            \n",
    "            # Decay exploration\n",
    "            self.decay_exploration()\n",
    "            print(f\"Episode {episode} done...\\n\")\n",
    "            print(\"=\"*70,\"\\n\")\n",
    "        \n",
    "        return self.initial_performance, self.final_performance, self.performance_improvement, self.drift_points, self.model   \n",
    "\n",
    "    def plot_results(self, performance_data, drift_data, indicate_drift = 1):\n",
    "        plt.plot(performance_data)\n",
    "        if indicate_drift == 1:\n",
    "            for point in drift_points:\n",
    "                plt.axvline(x= point, color = \"red\", linestyle = \"dotted\")\n",
    "\n",
    "    #Apply styling to the dataframe (Q-table)\n",
    "    def highlight_max_and_threshold(row):\n",
    "        max_value = row.max()  # Find the max value in the row\n",
    "        styles = []\n",
    "        for value in row:\n",
    "            if value == max_value:\n",
    "                styles.append('background-color: blue')  # Highlight max value\n",
    "            elif value > 0.0:\n",
    "                styles.append('background-color: green')  # Highlight values over threshold\n",
    "            elif value < 0.0:\n",
    "                styles.append('background-color: red')\n",
    "            else:\n",
    "                styles.append('')  # No styling for other cells          \n",
    "        return styles\n",
    "        \n",
    "    def display_q_table(self):\n",
    "        pd.set_option(\"display.max_columns\", 100)\n",
    "        pd.set_option(\"display.max_rows\", 100)\n",
    "        \n",
    "        df = pd.DataFrame(self.q_table[:,:self.number_of_actions])\n",
    "        styled_df = df.head(len(self.state_ref_data)).style.apply(highlight_max_and_threshold, axis = 1)\n",
    "        \n",
    "        return styled_df\n",
    "    \n",
    "    def initialize_train_model(self, X_train, y_train, n_episodes = 1000, batch_size = 32, performance_threshold = 0.75, ks_pvalue = 0.05, wil_p_value = 0.05):\n",
    "        self.model = self.DNN_model(self)\n",
    "        self.model(X_train)\n",
    "        self.model.compile(\n",
    "                    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                    loss=keras.losses.BinaryCrossentropy(),\n",
    "                    metrics=[\n",
    "                        keras.metrics.BinaryAccuracy(),\n",
    "                        keras.metrics.FalseNegatives(),\n",
    "                        \"accuracy\"\n",
    "                    ],\n",
    "                )\n",
    "        self.model.summary()\n",
    "        print(n_episodes)\n",
    "        initial_history, final_history, improvement_history, drift_points, model = self.train_with_drift_detection(self.model, \n",
    "                                                                       X_train, \n",
    "                                                                       y_train, \n",
    "                                                                       n_episodes = n_episodes, \n",
    "                                                                       batch_size = batch_size, \n",
    "                                                                       performance_threshold = performance_threshold,\n",
    "                                                                       ks_pvalue = ks_pvalue, \n",
    "                                                                       wil_p_value = wil_p_value)\n",
    "        \n",
    "        self.model = model\n",
    "        return model, initial_history, final_history, improvement_history, drift_points\n",
    "\n",
    "    def evaluate_model(self, X_test, y_test, batch_size = 32, n_episodes = 1000,  wil_p_value = 0.5, verbose = 1):\n",
    "        model = self.model\n",
    "        pos = random.randint(0, len(X_test) - batch_size)\n",
    "        batch_X = X_test[pos:pos+batch_size]\n",
    "        batch_y = y_test[pos:pos+batch_size]\n",
    "        acc_list = []\n",
    "        loss_list = []\n",
    "        for episode in range(n_episodes):\n",
    "            \n",
    "            target_state = self.determine_state(batch_X, wil_p_value = wil_p_value, evaluation = 1)\n",
    "            action_taken = np.argmax(self.q_table[target_state])\n",
    "\n",
    "            # self.model.compile(\n",
    "            #         optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "            #         loss=keras.losses.BinaryCrossentropy(),\n",
    "            #         metrics=[\n",
    "            #             keras.metrics.BinaryAccuracy(),\n",
    "            #             keras.metrics.FalseNegatives(),\n",
    "            #             \"accuracy\"\n",
    "            #         ],\n",
    "            # )\n",
    "            self.model.load_weights(self.state_ref_weights[action_taken], skip_mismatch=True)\n",
    "            model_accuracy = self.model.evaluate(batch_X, batch_y, verbose = 0)[-1]\n",
    "            model_loss = self.model.evaluate(batch_X, batch_y, verbose = 0)[0]\n",
    "            if (episode == 0):\n",
    "                print(\"Starting Evaluation...\")\n",
    "                prev_model_accuracy = model_accuracy\n",
    "                prev_model_loss = model_loss\n",
    "                \n",
    "            acc_list.append(model_accuracy)\n",
    "            loss_list.append(model_loss)\n",
    "            \n",
    "        self.dispaly_accuracy = acc_list\n",
    "        self.display_loss = loss_list\n",
    "        print(f\"Average loss of the model : {np.mean(model_loss)}\")\n",
    "        print(f\"Standard deviation loss of the model : {np.std(model_loss)}\")\n",
    "        print(f\"Maximum loss of the model : {np.max(model_loss)}\")\n",
    "        print(f\"Minimum loss of the model : {np.min(model_loss)}\\n\")\n",
    "        \n",
    "        print(f\"Average accuracy of the model : {np.mean(model_accuracy)}\")\n",
    "        print(f\"Standard deviation accuracy of the model : {np.std(model_accuracy)}\")\n",
    "        print(f\"Maximum accuracy of the model : {np.max(model_accuracy)}\")\n",
    "        print(f\"Minimum accuracy of the model : {np.min(model_accuracy)}\\n\")\n",
    "\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        ax[0].set_ylim(min(self.dispaly_accuracy), max(self.dispaly_accuracy))\n",
    "        ax[0].plot(self.dispaly_accuracy, color = \"red\")\n",
    "        ax[1].set_ylim(min(self.display_loss), max(self.display_loss))\n",
    "        ax[1].plot(self.display_loss, color = \"orange\")\n",
    "\n",
    "        plt.show()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da645b-2af3-4098-9b3e-1dd76a0f45e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"dnn_model_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"dnn_model_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">80000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">80000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">80000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">80000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">80000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">80000</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m80000\u001b[0m, \u001b[38;5;34m12\u001b[0m)            │            \u001b[38;5;34m72\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m80000\u001b[0m, \u001b[38;5;34m24\u001b[0m)            │           \u001b[38;5;34m312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m80000\u001b[0m, \u001b[38;5;34m48\u001b[0m)            │         \u001b[38;5;34m1,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m80000\u001b[0m, \u001b[38;5;34m24\u001b[0m)            │         \u001b[38;5;34m1,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m80000\u001b[0m, \u001b[38;5;34m12\u001b[0m)            │           \u001b[38;5;34m300\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m80000\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │            \u001b[38;5;34m13\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,073</span> (12.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,073\u001b[0m (12.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,073</span> (12.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,073\u001b[0m (12.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "Start Training ...\n",
      "Model initialized with state 0\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1\n",
      "\n",
      "Target accuracy (0.80) and loss (0.40) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.3875809907913208\n",
      "Model weights for action 0 has been saved at Model_weights/model_action0.weights.h5\n",
      "Model reward for new action 0 : 0.6124190092086792\n",
      "\n",
      "Total number of actions : 1\n",
      "\n",
      "Model created with action 0 with accuracy 0.84375\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8438 - binary_accuracy: 0.8438 - false_negatives_130: 3.0000 - loss: 0.3876\n",
      "Episode 0 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 1\n",
      "Current model loss 1.4588897228240967\n",
      "Model loss previously 0.3875809907913208\n",
      "Determining State...\n",
      "Number of states available 1\n",
      "No appropriate state found in the existing list, creating new state\n",
      "New state 1 created\n",
      "Target state : 1\n",
      "Number of similar columns 5\n",
      "\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.46\n",
      "Model trained from scratch, new performance loss : 0.9963991641998291\n",
      "Model weights for action 1 has been saved at Model_weights/model_action1.weights.h5\n",
      "Model reward for new action 1 : 0.46360083580017086\n",
      "\n",
      "Total number of actions : 2\n",
      "\n",
      "Model's performance loss before weight fit 1.46 \n",
      "Model's performance loss after weight fit 1.0\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.94\n",
      "\n",
      "Action determination done\n",
      "Action taken : 1 \n",
      "Reward : 0.46360083580017086\n",
      "\n",
      "Episode 1 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 2\n",
      "Current model loss 2.5035414695739746\n",
      "Model loss previously 0.9963991641998291\n",
      "Determining State...\n",
      "Number of states available 2\n",
      "No appropriate state found in the existing list, creating new state\n",
      "New state 2 created\n",
      "Target state : 2\n",
      "Number of similar columns 5\n",
      "\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 2.5 \n",
      "Model's performance loss after weight fit 0.43\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.78\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 2.07\n",
      "\n",
      "Episode 2 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 3\n",
      "Current model loss 1.1590124368667603\n",
      "Model loss previously 0.4279550015926361\n",
      "Determining State...\n",
      "Number of states available 3\n",
      "No appropriate state found in the existing list, creating new state\n",
      "New state 3 created\n",
      "Target state : 3\n",
      "Number of similar columns 5\n",
      "\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.16\n",
      "Model training failed, new performance 3.0242671966552734 is greater than the previous loss 1.16\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.16\n",
      "Model training failed, new performance 3.0242671966552734 is greater than the previous loss 1.16\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.16\n",
      "\n",
      "Target accuracy (0.80) and loss (0.46) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.4181964695453644\n",
      "Model weights for action 2 has been saved at Model_weights/model_action2.weights.h5\n",
      "Model reward for new action 2 : 0.7418035304546355\n",
      "\n",
      "Total number of actions : 3\n",
      "\n",
      "Model's performance loss before weight fit 1.16 \n",
      "Model's performance loss after weight fit 0.42\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.84\n",
      "\n",
      "Action determination done\n",
      "Action taken : 2 \n",
      "Reward : 0.7418035304546355\n",
      "\n",
      "Episode 3 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 4\n",
      "Current model loss 0.7344062328338623\n",
      "Model loss previously 0.4181964695453644\n",
      "Determining State...\n",
      "Number of states available 4\n",
      "No appropriate state found in the existing list, creating new state\n",
      "New state 4 created\n",
      "Target state : 4\n",
      "Number of similar columns 5\n",
      "\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 0.73 \n",
      "Model's performance loss after weight fit 0.63\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0.09999999999999998\n",
      "\n",
      "Episode 4 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 5\n",
      "Current model loss 1.163086175918579\n",
      "Model loss previously 0.6336758136749268\n",
      "Determining State...\n",
      "Number of states available 5\n",
      "The similarity score of target state 4 : [0.9639718  0.8147991  0.66431742 0.98125636 0.40477524]\n",
      "Determining action ...\n",
      "Model's current performance 0.56 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.16\n",
      "\n",
      "Target accuracy (0.80) and loss (0.46) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.45237308740615845\n",
      "Model weights for action 3 has been saved at Model_weights/model_action3.weights.h5\n",
      "Model reward for new action 3 : 0.7076269125938415\n",
      "\n",
      "Total number of actions : 4\n",
      "\n",
      "Model's performance loss before weight fit 1.16 \n",
      "Model's performance loss after weight fit 0.45\n",
      "Model's performance accuracy before weight fit 0.56 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 3 \n",
      "Reward : 0.7076269125938415\n",
      "\n",
      "Episode 5 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 6\n",
      "Current model loss 0.7858650088310242\n",
      "Model loss previously 0.45237308740615845\n",
      "Determining State...\n",
      "Number of states available 5\n",
      "No appropriate state found in the existing list, creating new state\n",
      "New state 5 created\n",
      "Target state : 5\n",
      "Number of similar columns 5\n",
      "\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.79\n",
      "Model training failed, new performance 3.0001792907714844 is greater than the previous loss 0.79\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.79\n",
      "Model training failed, new performance 3.0001792907714844 is greater than the previous loss 0.79\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.79\n",
      "Model training failed, new performance 3.0001792907714844 is greater than the previous loss 0.79\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.79\n",
      "Model training failed, new performance 3.0001792907714844 is greater than the previous loss 0.79\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.79\n",
      "Model training failed, new performance 3.0001792907714844 is greater than the previous loss 0.79\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.79\n",
      "\n",
      "Target accuracy (0.80) and loss (0.32) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.30562669038772583\n",
      "Model weights for action 4 has been saved at Model_weights/model_action4.weights.h5\n",
      "Model reward for new action 4 : 0.4843733096122742\n",
      "\n",
      "Total number of actions : 5\n",
      "\n",
      "Model's performance loss before weight fit 0.79 \n",
      "Model's performance loss after weight fit 0.31\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.84\n",
      "\n",
      "Action determination done\n",
      "Action taken : 4 \n",
      "Reward : 0.4843733096122742\n",
      "\n",
      "Episode 6 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 7\n",
      "Current model loss 2.6349124908447266\n",
      "Model loss previously 0.30562669038772583\n",
      "Determining State...\n",
      "Number of states available 6\n",
      "The similarity score of target state 3 : [0.92241108 0.60960883 0.745416   0.78072007 0.28127931]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 2 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 2\n",
      "\n",
      "Model's performance loss before weight fit 2.63 \n",
      "Model's performance loss after weight fit 1.73\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.62\n",
      "\n",
      "Action determination done\n",
      "Action taken : 2 \n",
      "Reward : 0.8999999999999999\n",
      "\n",
      "Episode 7 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 8\n",
      "No change in model performance :\n",
      "previous loss 1.7265639305114746\n",
      "current loss 1.153710961341858\n",
      "\n",
      "No action performed\n",
      "Episode 8 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 9\n",
      "No change in model performance :\n",
      "previous loss 1.153710961341858\n",
      "current loss 0.6822476983070374\n",
      "\n",
      "No action performed\n",
      "Episode 9 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 10\n",
      "Current model loss 0.7813386917114258\n",
      "Model loss previously 0.6822476983070374\n",
      "Determining State...\n",
      "Number of states available 6\n",
      "The similarity score of target state 2 : [0.9795282  0.86045019 0.93087673 0.69635789 0.99235038]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.78\n",
      "Model training failed, new performance 2.5552358627319336 is greater than the previous loss 0.78\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.78\n",
      "Model training failed, new performance 2.5552358627319336 is greater than the previous loss 0.78\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.78\n",
      "Model training failed, new performance 2.5552358627319336 is greater than the previous loss 0.78\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.78\n",
      "Model training failed, new performance 1.1046535968780518 is greater than the previous loss 0.78\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.78\n",
      "\n",
      "Target accuracy (0.80) and loss (0.31) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.30222296714782715\n",
      "Model weights for action 5 has been saved at Model_weights/model_action5.weights.h5\n",
      "Model reward for new action 5 : 0.4777770328521729\n",
      "\n",
      "Total number of actions : 6\n",
      "\n",
      "Model's performance loss before weight fit 0.78 \n",
      "Model's performance loss after weight fit 0.3\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.84\n",
      "\n",
      "Action determination done\n",
      "Action taken : 5 \n",
      "Reward : 0.4777770328521729\n",
      "\n",
      "Episode 10 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 11\n",
      "Current model loss 2.1421568393707275\n",
      "Model loss previously 0.30222296714782715\n",
      "Determining State...\n",
      "Number of states available 6\n",
      "The similarity score of target state 2 : [0.76749312 0.01221578 0.6099862  0.4597867  0.77369586]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 2.14 \n",
      "Model's performance loss after weight fit 0.69\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 1.4500000000000002\n",
      "\n",
      "Episode 11 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 12\n",
      "Current model loss 1.3445864915847778\n",
      "Model loss previously 0.6938618421554565\n",
      "Determining State...\n",
      "Number of states available 6\n",
      "The similarity score of target state 2 : [0.98789797 0.5179543  0.99515932 0.7505872  0.58064232]\n",
      "Determining action ...\n",
      "Model's current performance 0.53 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.34\n",
      "Model training failed, new performance 3.5038695335388184 is greater than the previous loss 1.34\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.34\n",
      "\n",
      "Target accuracy (0.80) and loss (0.54) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.40685662627220154\n",
      "Model weights for action 6 has been saved at Model_weights/model_action6.weights.h5\n",
      "Model reward for new action 6 : 0.9331433737277985\n",
      "\n",
      "Total number of actions : 7\n",
      "\n",
      "Model's performance loss before weight fit 1.34 \n",
      "Model's performance loss after weight fit 0.41\n",
      "Model's performance accuracy before weight fit 0.53 \n",
      "Model's performance loss after weight fit 0.84\n",
      "\n",
      "Action determination done\n",
      "Action taken : 6 \n",
      "Reward : 0.9331433737277985\n",
      "\n",
      "Episode 12 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 13\n",
      "Current model loss 0.977528989315033\n",
      "Model loss previously 0.40685662627220154\n",
      "Determining State...\n",
      "Number of states available 6\n",
      "The similarity score of target state 3 : [0.97547413 0.433363   0.68630151 0.00342153 0.70450494]\n",
      "Determining action ...\n",
      "Model's current performance 0.78 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 2 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 2\n",
      "\n",
      "Model's performance loss before weight fit 0.98 \n",
      "Model's performance loss after weight fit 0.71\n",
      "Model's performance accuracy before weight fit 0.78 \n",
      "Model's performance loss after weight fit 0.75\n",
      "\n",
      "Action determination done\n",
      "Action taken : 2 \n",
      "Reward : 0.27\n",
      "\n",
      "Episode 13 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 14\n",
      "Current model loss 1.232139229774475\n",
      "Model loss previously 0.7064414024353027\n",
      "Determining State...\n",
      "Number of states available 6\n",
      "The similarity score of target state 3 : [0.29469473 0.864118   0.9568665  0.86184011 0.22442399]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 2 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 2\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.23\n",
      "Model trained from scratch, new performance loss : 0.5599989295005798\n",
      "Model weights for action 7 has been saved at Model_weights/model_action7.weights.h5\n",
      "Model reward for new action 7 : 0.6700010704994201\n",
      "\n",
      "Total number of actions : 8\n",
      "\n",
      "Model's performance loss before weight fit 1.23 \n",
      "Model's performance loss after weight fit 0.56\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.94\n",
      "\n",
      "Action determination done\n",
      "Action taken : 7 \n",
      "Reward : 0.6700010704994201\n",
      "\n",
      "Episode 14 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 15\n",
      "Current model loss 2.407961130142212\n",
      "Model loss previously 0.5599989295005798\n",
      "Determining State...\n",
      "Number of states available 6\n",
      "The similarity score of target state 2 : [0.42816629 0.75150983 0.9726946  0.97927778 0.4363425 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 2.41 \n",
      "Model's performance loss after weight fit 0.78\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.5\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 1.6300000000000001\n",
      "\n",
      "Episode 15 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 16\n",
      "Current model loss 1.0768952369689941\n",
      "Model loss previously 0.7801530361175537\n",
      "Determining State...\n",
      "Number of states available 6\n",
      "No appropriate state found in the existing list, creating new state\n",
      "New state 6 created\n",
      "Target state : 6\n",
      "Number of similar columns 4\n",
      "\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.08\n",
      "Model trained from scratch, new performance loss : 0.4981996417045593\n",
      "Model weights for action 8 has been saved at Model_weights/model_action8.weights.h5\n",
      "Model reward for new action 8 : 0.5818003582954407\n",
      "\n",
      "Total number of actions : 9\n",
      "\n",
      "Model's performance loss before weight fit 1.08 \n",
      "Model's performance loss after weight fit 0.5\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.97\n",
      "\n",
      "Action determination done\n",
      "Action taken : 8 \n",
      "Reward : 0.5818003582954407\n",
      "\n",
      "Episode 16 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 17\n",
      "Current model loss 2.1420624256134033\n",
      "Model loss previously 0.4981996417045593\n",
      "Determining State...\n",
      "Number of states available 7\n",
      "The similarity score of target state 1 : [0.65006847 0.33453447 0.94845109 0.11886265 0.86577727]\n",
      "Determining action ...\n",
      "Model's current performance 0.78 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 1 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 1\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 2.14\n",
      "\n",
      "Target accuracy (0.80) and loss (0.86) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.829675555229187\n",
      "Model weights for action 9 has been saved at Model_weights/model_action9.weights.h5\n",
      "Model reward for new action 9 : 1.3103244447708131\n",
      "\n",
      "Total number of actions : 10\n",
      "\n",
      "Model's performance loss before weight fit 2.14 \n",
      "Model's performance loss after weight fit 0.83\n",
      "Model's performance accuracy before weight fit 0.78 \n",
      "Model's performance loss after weight fit 0.84\n",
      "\n",
      "Action determination done\n",
      "Action taken : 9 \n",
      "Reward : 1.3103244447708131\n",
      "\n",
      "Episode 17 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 18\n",
      "Current model loss 1.4476852416992188\n",
      "Model loss previously 0.829675555229187\n",
      "Determining State...\n",
      "Number of states available 7\n",
      "The similarity score of target state 2 : [0.50929814 0.82533141 0.95340303 0.73926973 0.12003084]\n",
      "Determining action ...\n",
      "Model's current performance 0.75 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 1.45 \n",
      "Model's performance loss after weight fit 0.61\n",
      "Model's performance accuracy before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0.84\n",
      "\n",
      "Episode 18 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 19\n",
      "Current model loss 1.5501874685287476\n",
      "Model loss previously 0.6051651835441589\n",
      "Determining State...\n",
      "Number of states available 7\n",
      "No appropriate state found in the existing list, creating new state\n",
      "New state 7 created\n",
      "Target state : 7\n",
      "Number of similar columns 3\n",
      "\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.55\n",
      "\n",
      "Target accuracy (0.80) and loss (0.62) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.3216525912284851\n",
      "Model weights for action 10 has been saved at Model_weights/model_action10.weights.h5\n",
      "Model reward for new action 10 : 1.228347408771515\n",
      "\n",
      "Total number of actions : 11\n",
      "\n",
      "Model's performance loss before weight fit 1.55 \n",
      "Model's performance loss after weight fit 0.32\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 10 \n",
      "Reward : 1.228347408771515\n",
      "\n",
      "Episode 19 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 20\n",
      "Current model loss 1.3970003128051758\n",
      "Model loss previously 0.3216525912284851\n",
      "Determining State...\n",
      "Number of states available 8\n",
      "The similarity score of target state 4 : [0.28903577 0.7147735  0.75322754 0.64280939 0.67130642]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 3 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 3\n",
      "\n",
      "Model's performance loss before weight fit 1.4 \n",
      "Model's performance loss after weight fit 1.17\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.56\n",
      "\n",
      "Action determination done\n",
      "Action taken : 3 \n",
      "Reward : 0.22999999999999998\n",
      "\n",
      "Episode 20 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 21\n",
      "No change in model performance :\n",
      "previous loss 1.1671680212020874\n",
      "current loss 0.7870625853538513\n",
      "\n",
      "No action performed\n",
      "Episode 21 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 22\n",
      "No change in model performance :\n",
      "previous loss 0.7870625853538513\n",
      "current loss 0.6723150014877319\n",
      "\n",
      "No action performed\n",
      "Episode 22 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 23\n",
      "Current model loss 0.7373519539833069\n",
      "Model loss previously 0.6723150014877319\n",
      "Determining State...\n",
      "Number of states available 8\n",
      "The similarity score of target state 2 : [0.97304718 0.2514865  0.97464919 0.96302459 0.33643853]\n",
      "Determining action ...\n",
      "Model's current performance 0.56 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "Model's performance loss before weight fit 0.74 \n",
      "Model's performance loss after weight fit 0.76\n",
      "Model's performance accuracy before weight fit 0.56 \n",
      "Model's performance loss after weight fit 0.56\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : -0.020000000000000018\n",
      "\n",
      "Episode 23 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 24\n",
      "No change in model performance :\n",
      "previous loss 0.7649121284484863\n",
      "current loss 0.6061804890632629\n",
      "\n",
      "No action performed\n",
      "Episode 24 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 25\n",
      "Current model loss 1.2686272859573364\n",
      "Model loss previously 0.6061804890632629\n",
      "Determining State...\n",
      "Number of states available 8\n",
      "The similarity score of target state 0 : [0.79804101 0.7907808  0.72366001 0.45818506 0.21930681]\n",
      "Determining action ...\n",
      "Model's current performance 0.56 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 5 were loaded\n",
      "Model's performance loss before weight fit 1.27 \n",
      "Model's performance loss after weight fit 1.83\n",
      "Model's performance accuracy before weight fit 0.56 \n",
      "Model's performance loss after weight fit 0.56\n",
      "\n",
      "Action determination done\n",
      "Action taken : 5 \n",
      "Reward : -0.56\n",
      "\n",
      "Episode 25 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 26\n",
      "No change in model performance :\n",
      "previous loss 1.8305299282073975\n",
      "current loss 0.6371948719024658\n",
      "\n",
      "No action performed\n",
      "Episode 26 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 27\n",
      "Current model loss 0.8775340914726257\n",
      "Model loss previously 0.6371948719024658\n",
      "Determining State...\n",
      "Number of states available 8\n",
      "No appropriate state found in the existing list, creating new state\n",
      "New state 8 created\n",
      "Target state : 8\n",
      "Number of similar columns 3\n",
      "\n",
      "Determining action ...\n",
      "Model's current performance 0.75 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "Model's performance loss before weight fit 0.88 \n",
      "Model's performance loss after weight fit 0.55\n",
      "Model's performance accuracy before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.72\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0.32999999999999996\n",
      "\n",
      "Episode 27 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 28\n",
      "Current model loss 1.0248897075653076\n",
      "Model loss previously 0.5543525218963623\n",
      "Determining State...\n",
      "Number of states available 9\n",
      "The similarity score of target state 0 : [0.87409096 0.0916691  0.6998952  0.68899134 0.00378395]\n",
      "Determining action ...\n",
      "No significant change in performance accuracy, so no new action\n",
      "\n",
      "Model's performance loss before weight fit 1.02 \n",
      "Model's performance loss after weight fit 1.02\n",
      "Model's performance accuracy before weight fit 0.81 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0\n",
      "\n",
      "Episode 28 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 29\n",
      "Current model loss 1.0772905349731445\n",
      "Model loss previously 1.0248897075653076\n",
      "Determining State...\n",
      "Number of states available 9\n",
      "The similarity score of target state 3 : [0.65619568 0.74567034 0.72261857 0.85654208 0.23471092]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 7 were loaded\n",
      "Model's performance loss before weight fit 1.08 \n",
      "Model's performance loss after weight fit 2.13\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.56\n",
      "\n",
      "Action determination done\n",
      "Action taken : 7 \n",
      "Reward : -1.0499999999999998\n",
      "\n",
      "Episode 29 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 30\n",
      "No change in model performance :\n",
      "previous loss 2.1337897777557373\n",
      "current loss 1.9132332801818848\n",
      "\n",
      "No action performed\n",
      "Episode 30 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 31\n",
      "Current model loss 3.8476006984710693\n",
      "Model loss previously 1.9132332801818848\n",
      "Determining State...\n",
      "Number of states available 9\n",
      "The similarity score of target state 7 : [0.90749806 0.22135681 0.82675658 0.88559275 0.48352262]\n",
      "Determining action ...\n",
      "Model's current performance 0.53 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "Model's performance loss before weight fit 3.85 \n",
      "Model's performance loss after weight fit 3.33\n",
      "Model's performance accuracy before weight fit 0.53 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 10 \n",
      "Reward : 0.52\n",
      "\n",
      "Episode 31 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 32\n",
      "No change in model performance :\n",
      "previous loss 3.3282268047332764\n",
      "current loss 2.540496349334717\n",
      "\n",
      "No action performed\n",
      "Episode 32 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 33\n",
      "Current model loss 2.8528788089752197\n",
      "Model loss previously 2.540496349334717\n",
      "Determining State...\n",
      "Number of states available 9\n",
      "The similarity score of target state 2 : [0.95364089 0.63069645 0.58526504 0.48191736 0.82472974]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 8 were loaded\n",
      "Model's performance loss before weight fit 2.85 \n",
      "Model's performance loss after weight fit 3.83\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 8 \n",
      "Reward : -0.98\n",
      "\n",
      "Episode 33 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 34\n",
      "Current model loss 4.026907444000244\n",
      "Model loss previously 3.8307623863220215\n",
      "Determining State...\n",
      "Number of states available 9\n",
      "The similarity score of target state 2 : [0.94795375 0.24813139 0.61159365 0.64568915 0.80841671]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "Model's performance loss before weight fit 4.03 \n",
      "Model's performance loss after weight fit 0.6\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 3.43\n",
      "\n",
      "Episode 34 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 35\n",
      "No change in model performance :\n",
      "previous loss 0.6029177308082581\n",
      "current loss 0.576488733291626\n",
      "\n",
      "No action performed\n",
      "Episode 35 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 36\n",
      "Current model loss 0.7539346814155579\n",
      "Model loss previously 0.576488733291626\n",
      "Determining State...\n",
      "Number of states available 9\n",
      "The similarity score of target state 0 : [0.81517202 0.97996161 0.62577122 0.10247685 0.20606935]\n",
      "Determining action ...\n",
      "Model's current performance 0.47 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "Model's performance loss before weight fit 0.75 \n",
      "Model's performance loss after weight fit 1.42\n",
      "Model's performance accuracy before weight fit 0.47 \n",
      "Model's performance loss after weight fit 0.72\n",
      "\n",
      "Action determination done\n",
      "Action taken : 10 \n",
      "Reward : -0.6699999999999999\n",
      "\n",
      "Episode 36 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 37\n",
      "No change in model performance :\n",
      "previous loss 1.4240870475769043\n",
      "current loss 0.9629287719726562\n",
      "\n",
      "No action performed\n",
      "Episode 37 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 38\n",
      "Current model loss 2.0223536491394043\n",
      "Model loss previously 0.9629287719726562\n",
      "Determining State...\n",
      "Number of states available 9\n",
      "The similarity score of target state 0 : [0.79638792 0.91814962 0.19697    0.89459828 0.03038599]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 7 were loaded\n",
      "Model's performance loss before weight fit 2.02 \n",
      "Model's performance loss after weight fit 1.89\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.72\n",
      "\n",
      "Action determination done\n",
      "Action taken : 7 \n",
      "Reward : 0.13000000000000012\n",
      "\n",
      "Episode 38 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 39\n",
      "Current model loss 2.264979839324951\n",
      "Model loss previously 1.8899562358856201\n",
      "Determining State...\n",
      "Number of states available 9\n",
      "The similarity score of target state 0 : [0.57987342 0.6255694  0.93375706 0.99081745 0.00495336]\n",
      "Determining action ...\n",
      "Model's current performance 0.75 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 2.26 \n",
      "Model's performance loss after weight fit 0.67\n",
      "Model's performance accuracy before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 1.5899999999999999\n",
      "\n",
      "Episode 39 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 40\n",
      "No change in model performance :\n",
      "previous loss 0.6691694855690002\n",
      "current loss 0.5133053064346313\n",
      "\n",
      "No action performed\n",
      "Episode 40 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 41\n",
      "Current model loss 1.2716636657714844\n",
      "Model loss previously 0.5133053064346313\n",
      "Determining State...\n",
      "Number of states available 9\n",
      "The similarity score of target state 0 : [0.99927617 0.84488352 0.80063567 0.64880261 0.08673871]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.27\n",
      "\n",
      "Target accuracy (0.80) and loss (0.51) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.5071121454238892\n",
      "Model weights for action 11 has been saved at Model_weights/model_action11.weights.h5\n",
      "Model reward for new action 11 : 0.7628878545761109\n",
      "\n",
      "Total number of actions : 12\n",
      "\n",
      "Model's performance loss before weight fit 1.27 \n",
      "Model's performance loss after weight fit 0.51\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.97\n",
      "\n",
      "Action determination done\n",
      "Action taken : 11 \n",
      "Reward : 0.7628878545761109\n",
      "\n",
      "Episode 41 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 42\n",
      "Current model loss 4.281434059143066\n",
      "Model loss previously 0.5071121454238892\n",
      "Determining State...\n",
      "Number of states available 9\n",
      "The similarity score of target state 5 : [0.70361579 0.64771654 0.73637828 0.84090962 0.0237677 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 8 were loaded\n",
      "Model's performance loss before weight fit 4.28 \n",
      "Model's performance loss after weight fit 4.37\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.62\n",
      "\n",
      "Action determination done\n",
      "Action taken : 8 \n",
      "Reward : -0.08999999999999986\n",
      "\n",
      "Episode 42 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 43\n",
      "No change in model performance :\n",
      "previous loss 4.368854999542236\n",
      "current loss 3.911391258239746\n",
      "\n",
      "No action performed\n",
      "Episode 43 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 44\n",
      "No change in model performance :\n",
      "previous loss 3.911391258239746\n",
      "current loss 2.8252649307250977\n",
      "\n",
      "No action performed\n",
      "Episode 44 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 45\n",
      "Current model loss 5.156546592712402\n",
      "Model loss previously 2.8252649307250977\n",
      "Determining State...\n",
      "Number of states available 9\n",
      "The similarity score of target state 2 : [0.98357662 0.98179111 0.97407283 0.60565664 0.81909914]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 3 were loaded\n",
      "Model's performance loss before weight fit 5.16 \n",
      "Model's performance loss after weight fit 0.78\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.62\n",
      "\n",
      "Action determination done\n",
      "Action taken : 3 \n",
      "Reward : 4.38\n",
      "\n",
      "Episode 45 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 46\n",
      "No change in model performance :\n",
      "previous loss 0.7819175720214844\n",
      "current loss 0.6599827408790588\n",
      "\n",
      "No action performed\n",
      "Episode 46 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 47\n",
      "No change in model performance :\n",
      "previous loss 0.6599827408790588\n",
      "current loss 0.5326350331306458\n",
      "\n",
      "No action performed\n",
      "Episode 47 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 48\n",
      "Current model loss 0.6794880628585815\n",
      "Model loss previously 0.5326350331306458\n",
      "Determining State...\n",
      "Number of states available 9\n",
      "The similarity score of target state 3 : [7.97779085e-01 6.56395031e-01 3.89037374e-01 6.02245212e-01\n",
      " 4.94350664e-04]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 4 were loaded\n",
      "Model's performance loss before weight fit 0.68 \n",
      "Model's performance loss after weight fit 1.22\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.56\n",
      "\n",
      "Action determination done\n",
      "Action taken : 4 \n",
      "Reward : -0.5399999999999999\n",
      "\n",
      "Episode 48 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 49\n",
      "Current model loss 1.931847095489502\n",
      "Model loss previously 1.2234625816345215\n",
      "Determining State...\n",
      "Number of states available 9\n",
      "The similarity score of target state 2 : [0.71704829 0.10249427 0.82204188 0.75975979 0.70999498]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "Model's performance loss before weight fit 1.93 \n",
      "Model's performance loss after weight fit 0.55\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 1.38\n",
      "\n",
      "Episode 49 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 50\n",
      "Current model loss 0.721112847328186\n",
      "Model loss previously 0.5536016225814819\n",
      "Determining State...\n",
      "Number of states available 9\n",
      "No appropriate state found in the existing list, creating new state\n",
      "New state 9 created\n",
      "Target state : 9\n",
      "Number of similar columns 3\n",
      "\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "Model's performance loss before weight fit 0.72 \n",
      "Model's performance loss after weight fit 1.91\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 10 \n",
      "Reward : -1.19\n",
      "\n",
      "Episode 50 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 51\n",
      "Current model loss 2.652177095413208\n",
      "Model loss previously 1.9139903783798218\n",
      "Determining State...\n",
      "Number of states available 10\n",
      "The similarity score of target state 6 : [0.69883785 0.05731127 0.01515617 0.94593302 0.63268511]\n",
      "Determining action ...\n",
      "Model's current performance 0.5 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 4 were loaded\n",
      "Model's performance loss before weight fit 2.65 \n",
      "Model's performance loss after weight fit 3.56\n",
      "Model's performance accuracy before weight fit 0.5 \n",
      "Model's performance loss after weight fit 0.56\n",
      "\n",
      "Action determination done\n",
      "Action taken : 4 \n",
      "Reward : -0.9100000000000001\n",
      "\n",
      "Episode 51 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 52\n",
      "No change in model performance :\n",
      "previous loss 3.5635175704956055\n",
      "current loss 1.098668098449707\n",
      "\n",
      "No action performed\n",
      "Episode 52 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 53\n",
      "Current model loss 2.074882984161377\n",
      "Model loss previously 1.098668098449707\n",
      "Determining State...\n",
      "Number of states available 10\n",
      "The similarity score of target state 0 : [0.64472436 0.64451176 0.96773385 0.24715614 0.12460547]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 2.07 \n",
      "Model's performance loss after weight fit 1.22\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0.8499999999999999\n",
      "\n",
      "Episode 53 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 54\n",
      "No change in model performance :\n",
      "previous loss 1.220578670501709\n",
      "current loss 0.7288014888763428\n",
      "\n",
      "No action performed\n",
      "Episode 54 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 55\n",
      "No change in model performance :\n",
      "previous loss 0.7288014888763428\n",
      "current loss 0.48033607006073\n",
      "\n",
      "No action performed\n",
      "Episode 55 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 56\n",
      "Current model loss 0.9065892696380615\n",
      "Model loss previously 0.48033607006073\n",
      "Determining State...\n",
      "Number of states available 10\n",
      "The similarity score of target state 2 : [0.71862869 0.92737152 0.64225734 0.85621911 0.29473917]\n",
      "Determining action ...\n",
      "Model's current performance 0.5 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 3 were loaded\n",
      "Model's performance loss before weight fit 0.91 \n",
      "Model's performance loss after weight fit 0.78\n",
      "Model's performance accuracy before weight fit 0.5 \n",
      "Model's performance loss after weight fit 0.5\n",
      "\n",
      "Action determination done\n",
      "Action taken : 3 \n",
      "Reward : 0.13\n",
      "\n",
      "Episode 56 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 57\n",
      "No change in model performance :\n",
      "previous loss 0.7760095596313477\n",
      "current loss 0.7380928993225098\n",
      "\n",
      "No action performed\n",
      "Episode 57 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 58\n",
      "No change in model performance :\n",
      "previous loss 0.7380928993225098\n",
      "current loss 0.5784430503845215\n",
      "\n",
      "No action performed\n",
      "Episode 58 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 59\n",
      "Current model loss 1.3351786136627197\n",
      "Model loss previously 0.5784430503845215\n",
      "Determining State...\n",
      "Number of states available 10\n",
      "The similarity score of target state 1 : [0.69170343 0.82638332 0.54752959 0.09034361 0.80010332]\n",
      "Determining action ...\n",
      "Model's current performance 0.53 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "Model's performance loss before weight fit 1.34 \n",
      "Model's performance loss after weight fit 1.74\n",
      "Model's performance accuracy before weight fit 0.53 \n",
      "Model's performance loss after weight fit 0.53\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : -0.3999999999999999\n",
      "\n",
      "Episode 59 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 60\n",
      "No change in model performance :\n",
      "previous loss 1.7366513013839722\n",
      "current loss 1.0359604358673096\n",
      "\n",
      "No action performed\n",
      "Episode 60 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 61\n",
      "Current model loss 1.1052627563476562\n",
      "Model loss previously 1.0359604358673096\n",
      "Determining State...\n",
      "Number of states available 10\n",
      "The similarity score of target state 1 : [0.60598453 0.05079285 0.86209913 0.75299975 0.59557378]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 9 were loaded\n",
      "Model's performance loss before weight fit 1.11 \n",
      "Model's performance loss after weight fit 1.9\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.72\n",
      "\n",
      "Action determination done\n",
      "Action taken : 9 \n",
      "Reward : -0.7899999999999998\n",
      "\n",
      "Episode 61 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 62\n",
      "Current model loss 2.012907028198242\n",
      "Model loss previously 1.9026530981063843\n",
      "Determining State...\n",
      "Number of states available 10\n",
      "The similarity score of target state 6 : [0.1785418  0.00406227 0.76111103 0.96010619 0.89634375]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 8 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 8\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 2.01\n",
      "Model training failed, new performance 4.0240325927734375 is greater than the previous loss 2.01\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 2.01\n",
      "\n",
      "Target accuracy (0.80) and loss (0.80) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.7270064353942871\n",
      "Model weights for action 12 has been saved at Model_weights/model_action12.weights.h5\n",
      "Model reward for new action 12 : 1.2829935646057127\n",
      "\n",
      "Total number of actions : 13\n",
      "\n",
      "Model's performance loss before weight fit 2.01 \n",
      "Model's performance loss after weight fit 0.73\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.84\n",
      "\n",
      "Action determination done\n",
      "Action taken : 12 \n",
      "Reward : 1.2829935646057127\n",
      "\n",
      "Episode 62 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 63\n",
      "Current model loss 0.7549006342887878\n",
      "Model loss previously 0.7270064353942871\n",
      "Determining State...\n",
      "Number of states available 10\n",
      "The similarity score of target state 0 : [0.80058749 0.87208807 0.85932575 0.74900259 0.458882  ]\n",
      "Determining action ...\n",
      "No significant change in performance accuracy, so no new action\n",
      "\n",
      "Model's performance loss before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.75\n",
      "Model's performance accuracy before weight fit 0.81 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0\n",
      "\n",
      "Episode 63 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 64\n",
      "Current model loss 2.432767391204834\n",
      "Model loss previously 0.7549006342887878\n",
      "Determining State...\n",
      "Number of states available 10\n",
      "The similarity score of target state 0 : [0.60989988 0.87968807 0.80382426 0.15257776 0.08587239]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "Model's performance loss before weight fit 2.43 \n",
      "Model's performance loss after weight fit 0.98\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.53\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 1.4500000000000002\n",
      "\n",
      "Episode 64 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 65\n",
      "No change in model performance :\n",
      "previous loss 0.9826595783233643\n",
      "current loss 0.8307784199714661\n",
      "\n",
      "No action performed\n",
      "Episode 65 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 66\n",
      "No change in model performance :\n",
      "previous loss 0.8307784199714661\n",
      "current loss 0.7017304301261902\n",
      "\n",
      "No action performed\n",
      "Episode 66 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 67\n",
      "No change in model performance :\n",
      "previous loss 0.7017304301261902\n",
      "current loss 0.5615062713623047\n",
      "\n",
      "No action performed\n",
      "Episode 67 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 68\n",
      "Current model loss 0.6798228621482849\n",
      "Model loss previously 0.5615062713623047\n",
      "Determining State...\n",
      "Number of states available 10\n",
      "No appropriate state found in the existing list, creating new state\n",
      "New state 10 created\n",
      "Target state : 10\n",
      "Number of similar columns 4\n",
      "\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 8 were loaded\n",
      "Model's performance loss before weight fit 0.68 \n",
      "Model's performance loss after weight fit 3.21\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.53\n",
      "\n",
      "Action determination done\n",
      "Action taken : 8 \n",
      "Reward : -2.53\n",
      "\n",
      "Episode 68 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 69\n",
      "Current model loss 4.783132553100586\n",
      "Model loss previously 3.2091846466064453\n",
      "Determining State...\n",
      "Number of states available 11\n",
      "The similarity score of target state 4 : [0.86637733 0.59098665 0.36679556 0.75359162 0.67673259]\n",
      "Determining action ...\n",
      "Model's current performance 0.56 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "Model's performance loss before weight fit 4.78 \n",
      "Model's performance loss after weight fit 2.14\n",
      "Model's performance accuracy before weight fit 0.56 \n",
      "Model's performance loss after weight fit 0.56\n",
      "\n",
      "Action determination done\n",
      "Action taken : 10 \n",
      "Reward : 2.64\n",
      "\n",
      "Episode 69 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 70\n",
      "No change in model performance :\n",
      "previous loss 2.1427533626556396\n",
      "current loss 1.5341856479644775\n",
      "\n",
      "No action performed\n",
      "Episode 70 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 71\n",
      "Current model loss 2.3619205951690674\n",
      "Model loss previously 1.5341856479644775\n",
      "Determining State...\n",
      "Number of states available 11\n",
      "The similarity score of target state 1 : [0.5365303  0.56611406 0.9127709  0.91576783 0.91967869]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 9 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 9\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 2.36\n",
      "Model training failed, new performance 2.5022192001342773 is greater than the previous loss 2.36\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 2.36\n",
      "\n",
      "Target accuracy (0.80) and loss (0.94) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.24607111513614655\n",
      "Model weights for action 13 has been saved at Model_weights/model_action13.weights.h5\n",
      "Model reward for new action 13 : 2.1139288848638533\n",
      "\n",
      "Total number of actions : 14\n",
      "\n",
      "Model's performance loss before weight fit 2.36 \n",
      "Model's performance loss after weight fit 0.25\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 13 \n",
      "Reward : 2.1139288848638533\n",
      "\n",
      "Episode 71 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 72\n",
      "Current model loss 1.9520015716552734\n",
      "Model loss previously 0.24607111513614655\n",
      "Determining State...\n",
      "Number of states available 11\n",
      "The similarity score of target state 4 : [0.99730703 0.68519053 0.5877231  0.9343896  0.65740844]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 7 were loaded\n",
      "Model's performance loss before weight fit 1.95 \n",
      "Model's performance loss after weight fit 1.81\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.78\n",
      "\n",
      "Action determination done\n",
      "Action taken : 7 \n",
      "Reward : 0.1399999999999999\n",
      "\n",
      "Episode 72 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 73\n",
      "No change in model performance :\n",
      "previous loss 1.8110638856887817\n",
      "current loss 1.524524450302124\n",
      "\n",
      "No action performed\n",
      "Episode 73 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 74\n",
      "Current model loss 2.0268454551696777\n",
      "Model loss previously 1.524524450302124\n",
      "Determining State...\n",
      "Number of states available 11\n",
      "The similarity score of target state 6 : [0.89386847 0.00871024 0.82145047 0.0306783  0.99590257]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 11 were loaded\n",
      "Model's performance loss before weight fit 2.03 \n",
      "Model's performance loss after weight fit 3.85\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 11 \n",
      "Reward : -1.8200000000000003\n",
      "\n",
      "Episode 74 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 75\n",
      "No change in model performance :\n",
      "previous loss 3.8503494262695312\n",
      "current loss 1.825445532798767\n",
      "\n",
      "No action performed\n",
      "Episode 75 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 76\n",
      "Current model loss 4.956897735595703\n",
      "Model loss previously 1.825445532798767\n",
      "Determining State...\n",
      "Number of states available 11\n",
      "The similarity score of target state 3 : [0.71554743 0.90637607 0.68491514 0.69558176 0.06585088]\n",
      "Determining action ...\n",
      "Model's current performance 0.47 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 11 were loaded\n",
      "Model's performance loss before weight fit 4.96 \n",
      "Model's performance loss after weight fit 4.96\n",
      "Model's performance accuracy before weight fit 0.47 \n",
      "Model's performance loss after weight fit 0.47\n",
      "\n",
      "Action determination done\n",
      "Action taken : 11 \n",
      "Reward : 0.0\n",
      "\n",
      "Episode 76 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 77\n",
      "No change in model performance :\n",
      "previous loss 4.956897735595703\n",
      "current loss 4.393396854400635\n",
      "\n",
      "No action performed\n",
      "Episode 77 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 78\n",
      "No change in model performance :\n",
      "previous loss 4.393396854400635\n",
      "current loss 4.281757831573486\n",
      "\n",
      "No action performed\n",
      "Episode 78 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 79\n",
      "No change in model performance :\n",
      "previous loss 4.281757831573486\n",
      "current loss 2.4382739067077637\n",
      "\n",
      "No action performed\n",
      "Episode 79 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 80\n",
      "Current model loss 2.8710012435913086\n",
      "Model loss previously 2.4382739067077637\n",
      "Determining State...\n",
      "Number of states available 11\n",
      "The similarity score of target state 2 : [0.4665135  0.76581159 0.70570627 0.96119515 0.68440079]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 5 were loaded\n",
      "Model's performance loss before weight fit 2.87 \n",
      "Model's performance loss after weight fit 0.87\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.84\n",
      "\n",
      "Action determination done\n",
      "Action taken : 5 \n",
      "Reward : 2.0\n",
      "\n",
      "Episode 80 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 81\n",
      "Current model loss 2.1017982959747314\n",
      "Model loss previously 0.8674413561820984\n",
      "Determining State...\n",
      "Number of states available 11\n",
      "The similarity score of target state 2 : [0.91654381 0.06577564 0.45315478 0.75220089 0.83814526]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "Model's performance loss before weight fit 2.1 \n",
      "Model's performance loss after weight fit 1.65\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.53\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0.4500000000000002\n",
      "\n",
      "Episode 81 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 82\n",
      "No change in model performance :\n",
      "previous loss 1.6527979373931885\n",
      "current loss 0.6552464962005615\n",
      "\n",
      "No action performed\n",
      "Episode 82 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 83\n",
      "No change in model performance :\n",
      "previous loss 0.6552464962005615\n",
      "current loss 0.5172809362411499\n",
      "\n",
      "No action performed\n",
      "Episode 83 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 84\n",
      "Current model loss 1.579060673713684\n",
      "Model loss previously 0.5172809362411499\n",
      "Determining State...\n",
      "Number of states available 11\n",
      "The similarity score of target state 4 : [0.58359749 0.74188218 0.71719875 0.66438051 0.85139901]\n",
      "Determining action ...\n",
      "Model's current performance 0.78 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 3 were loaded\n",
      "Model's performance loss before weight fit 1.58 \n",
      "Model's performance loss after weight fit 1.16\n",
      "Model's performance accuracy before weight fit 0.78 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 3 \n",
      "Reward : 0.42000000000000015\n",
      "\n",
      "Episode 84 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 85\n",
      "No change in model performance :\n",
      "previous loss 1.1602952480316162\n",
      "current loss 0.5121264457702637\n",
      "\n",
      "No action performed\n",
      "Episode 85 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 86\n",
      "Current model loss 0.8538081645965576\n",
      "Model loss previously 0.5121264457702637\n",
      "Determining State...\n",
      "Number of states available 11\n",
      "The similarity score of target state 2 : [0.70419041 0.72732919 0.96119667 0.95227826 0.44252182]\n",
      "Determining action ...\n",
      "Model's current performance 0.47 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 6 were loaded\n",
      "Model's performance loss before weight fit 0.85 \n",
      "Model's performance loss after weight fit 1.05\n",
      "Model's performance accuracy before weight fit 0.47 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 6 \n",
      "Reward : -0.20000000000000007\n",
      "\n",
      "Episode 86 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 87\n",
      "No change in model performance :\n",
      "previous loss 1.0476784706115723\n",
      "current loss 0.4868890345096588\n",
      "\n",
      "No action performed\n",
      "Episode 87 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 88\n",
      "Current model loss 0.9754781126976013\n",
      "Model loss previously 0.4868890345096588\n",
      "Determining State...\n",
      "Number of states available 11\n",
      "The similarity score of target state 4 : [0.66517722 0.99100049 0.19366514 0.63910603 0.94115015]\n",
      "Determining action ...\n",
      "No significant change in performance accuracy, so no new action\n",
      "\n",
      "Model's performance loss before weight fit 0.98 \n",
      "Model's performance loss after weight fit 0.98\n",
      "Model's performance accuracy before weight fit 0.81 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0\n",
      "\n",
      "Episode 88 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 89\n",
      "No change in model performance :\n",
      "previous loss 0.9754781126976013\n",
      "current loss 0.46941959857940674\n",
      "\n",
      "No action performed\n",
      "Episode 89 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 90\n",
      "Current model loss 1.472618818283081\n",
      "Model loss previously 0.46941959857940674\n",
      "Determining State...\n",
      "Number of states available 11\n",
      "The similarity score of target state 4 : [0.45754182 0.84931703 0.64873806 0.87086748 0.79468535]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 1 were loaded\n",
      "Model's performance loss before weight fit 1.47 \n",
      "Model's performance loss after weight fit 3.72\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.62\n",
      "\n",
      "Action determination done\n",
      "Action taken : 1 \n",
      "Reward : -2.25\n",
      "\n",
      "Episode 90 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 91\n",
      "Current model loss 3.9798381328582764\n",
      "Model loss previously 3.7225852012634277\n",
      "Determining State...\n",
      "Number of states available 11\n",
      "No appropriate state found in the existing list, creating new state\n",
      "New state 11 created\n",
      "Target state : 11\n",
      "Number of similar columns 3\n",
      "\n",
      "Determining action ...\n",
      "Model's current performance 0.56 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 13 were loaded\n",
      "Model's performance loss before weight fit 3.98 \n",
      "Model's performance loss after weight fit 2.08\n",
      "Model's performance accuracy before weight fit 0.56 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 13 \n",
      "Reward : 1.9\n",
      "\n",
      "Episode 91 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 92\n",
      "Current model loss 2.0828170776367188\n",
      "Model loss previously 2.078702211380005\n",
      "Determining State...\n",
      "Number of states available 12\n",
      "The similarity score of target state 2 : [0.95894634 0.79122576 0.49770568 0.66189852 0.60427319]\n",
      "Determining action ...\n",
      "Model's current performance 0.5 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "Model's performance loss before weight fit 2.08 \n",
      "Model's performance loss after weight fit 0.65\n",
      "Model's performance accuracy before weight fit 0.5 \n",
      "Model's performance loss after weight fit 0.56\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 1.4300000000000002\n",
      "\n",
      "Episode 92 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 93\n",
      "No change in model performance :\n",
      "previous loss 0.6455488204956055\n",
      "current loss 0.5865828394889832\n",
      "\n",
      "No action performed\n",
      "Episode 93 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 94\n",
      "No change in model performance :\n",
      "previous loss 0.5865828394889832\n",
      "current loss 0.5496964454650879\n",
      "\n",
      "No action performed\n",
      "Episode 94 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 95\n",
      "Current model loss 1.1187119483947754\n",
      "Model loss previously 0.5496964454650879\n",
      "Determining State...\n",
      "Number of states available 12\n",
      "The similarity score of target state 1 : [0.26002215 0.98858581 0.83759766 0.80674121 0.10876083]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 1 were loaded\n",
      "Model's performance loss before weight fit 1.12 \n",
      "Model's performance loss after weight fit 4.14\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 1 \n",
      "Reward : -3.0199999999999996\n",
      "\n",
      "Episode 95 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 96\n",
      "No change in model performance :\n",
      "previous loss 4.135709762573242\n",
      "current loss 3.186995029449463\n",
      "\n",
      "No action performed\n",
      "Episode 96 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 97\n",
      "No change in model performance :\n",
      "previous loss 3.186995029449463\n",
      "current loss 2.823166608810425\n",
      "\n",
      "No action performed\n",
      "Episode 97 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 98\n",
      "Current model loss 3.372751474380493\n",
      "Model loss previously 2.823166608810425\n",
      "Determining State...\n",
      "Number of states available 12\n",
      "The similarity score of target state 2 : [0.52643411 0.78930684 0.98146843 0.94197672 0.91014231]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 9 were loaded\n",
      "Model's performance loss before weight fit 3.37 \n",
      "Model's performance loss after weight fit 1.1\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 9 \n",
      "Reward : 2.27\n",
      "\n",
      "Episode 98 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 99\n",
      "Current model loss 2.4790329933166504\n",
      "Model loss previously 1.099226713180542\n",
      "Determining State...\n",
      "Number of states available 12\n",
      "The similarity score of target state 1 : [0.02985626 0.76817208 0.9393546  0.96130341 0.42241001]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 3 were loaded\n",
      "Model's performance loss before weight fit 2.48 \n",
      "Model's performance loss after weight fit 1.45\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 3 \n",
      "Reward : 1.03\n",
      "\n",
      "Episode 99 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 100\n",
      "No change in model performance :\n",
      "previous loss 1.445922613143921\n",
      "current loss 0.7151584625244141\n",
      "\n",
      "No action performed\n",
      "Episode 100 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 101\n",
      "No change in model performance :\n",
      "previous loss 0.7151584625244141\n",
      "current loss 0.6276727914810181\n",
      "\n",
      "No action performed\n",
      "Episode 101 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 102\n",
      "No change in model performance :\n",
      "previous loss 0.6276727914810181\n",
      "current loss 0.5811870098114014\n",
      "\n",
      "No action performed\n",
      "Episode 102 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 103\n",
      "Current model loss 0.6086130142211914\n",
      "Model loss previously 0.5811870098114014\n",
      "Determining State...\n",
      "Number of states available 12\n",
      "The similarity score of target state 0 : [0.77246443 0.65180222 0.8097625  0.61046605 0.00445658]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "Model's performance loss before weight fit 0.61 \n",
      "Model's performance loss after weight fit 0.78\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : -0.17000000000000004\n",
      "\n",
      "Episode 103 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 104\n",
      "No change in model performance :\n",
      "previous loss 0.7795494794845581\n",
      "current loss 0.6576883792877197\n",
      "\n",
      "No action performed\n",
      "Episode 104 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 105\n",
      "No change in model performance :\n",
      "previous loss 0.6576883792877197\n",
      "current loss 0.5978654623031616\n",
      "\n",
      "No action performed\n",
      "Episode 105 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 106\n",
      "Current model loss 0.8259368538856506\n",
      "Model loss previously 0.5978654623031616\n",
      "Determining State...\n",
      "Number of states available 12\n",
      "The similarity score of target state 4 : [0.76445476 0.07871072 0.99397968 0.88238331 0.75062588]\n",
      "Determining action ...\n",
      "Model's current performance 0.56 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.83\n",
      "\n",
      "Target accuracy (0.80) and loss (0.33) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.310573935508728\n",
      "Model weights for action 14 has been saved at Model_weights/model_action14.weights.h5\n",
      "Model reward for new action 14 : 0.5194260644912719\n",
      "\n",
      "Total number of actions : 15\n",
      "\n",
      "Model's performance loss before weight fit 0.83 \n",
      "Model's performance loss after weight fit 0.31\n",
      "Model's performance accuracy before weight fit 0.56 \n",
      "Model's performance loss after weight fit 0.84\n",
      "\n",
      "Action determination done\n",
      "Action taken : 14 \n",
      "Reward : 0.5194260644912719\n",
      "\n",
      "Episode 106 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 107\n",
      "Current model loss 1.038269281387329\n",
      "Model loss previously 0.310573935508728\n",
      "Determining State...\n",
      "Number of states available 12\n",
      "No appropriate state found in the existing list, creating new state\n",
      "New state 12 created\n",
      "Target state : 12\n",
      "Number of similar columns 4\n",
      "\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 1.04 \n",
      "Model's performance loss after weight fit 0.62\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.62\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0.42000000000000004\n",
      "\n",
      "Episode 107 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 108\n",
      "Current model loss 0.7011956572532654\n",
      "Model loss previously 0.620292067527771\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 0 : [0.8824525  0.57041419 0.92620893 0.78245494 0.0112389 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.7\n",
      "Model training failed, new performance 1.0412389039993286 is greater than the previous loss 0.7\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.7\n",
      "\n",
      "Target accuracy (0.80) and loss (0.28) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.26660600304603577\n",
      "Model weights for action 15 has been saved at Model_weights/model_action15.weights.h5\n",
      "Model reward for new action 15 : 0.4333939969539642\n",
      "\n",
      "Total number of actions : 16\n",
      "\n",
      "Model's performance loss before weight fit 0.7 \n",
      "Model's performance loss after weight fit 0.27\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.91\n",
      "\n",
      "Action determination done\n",
      "Action taken : 15 \n",
      "Reward : 0.4333939969539642\n",
      "\n",
      "Episode 108 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 109\n",
      "Current model loss 0.4809626042842865\n",
      "Model loss previously 0.26660600304603577\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 5 : [0.60135182 0.70656987 0.64774837 0.93321251 0.03634641]\n",
      "Determining action ...\n",
      "Model's current performance 0.78 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 15 were loaded\n",
      "Model's performance loss before weight fit 0.48 \n",
      "Model's performance loss after weight fit 0.48\n",
      "Model's performance accuracy before weight fit 0.78 \n",
      "Model's performance loss after weight fit 0.78\n",
      "\n",
      "Action determination done\n",
      "Action taken : 15 \n",
      "Reward : 0.0\n",
      "\n",
      "Episode 109 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 110\n",
      "Current model loss 1.0176177024841309\n",
      "Model loss previously 0.4809626042842865\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 4 : [0.79192148 0.06829541 0.74707667 0.86766931 0.96954905]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 11 were loaded\n",
      "Model's performance loss before weight fit 1.02 \n",
      "Model's performance loss after weight fit 3.05\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.62\n",
      "\n",
      "Action determination done\n",
      "Action taken : 11 \n",
      "Reward : -2.03\n",
      "\n",
      "Episode 110 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 111\n",
      "Current model loss 5.1384172439575195\n",
      "Model loss previously 3.054664373397827\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 1 : [0.22509249 0.61651946 0.12178677 0.82239651 0.79816022]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "Model's performance loss before weight fit 5.14 \n",
      "Model's performance loss after weight fit 1.44\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 10 \n",
      "Reward : 3.6999999999999997\n",
      "\n",
      "Episode 111 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 112\n",
      "No change in model performance :\n",
      "previous loss 1.4364501237869263\n",
      "current loss 0.4298527240753174\n",
      "\n",
      "No action performed\n",
      "Episode 112 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 113\n",
      "Current model loss 2.5067992210388184\n",
      "Model loss previously 0.4298527240753174\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 1 : [0.27108504 0.68381376 0.81179606 0.20883095 0.84966542]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 2.51\n",
      "\n",
      "Target accuracy (0.80) and loss (1.00) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.8100128173828125\n",
      "Model weights for action 16 has been saved at Model_weights/model_action16.weights.h5\n",
      "Model reward for new action 16 : 1.6999871826171873\n",
      "\n",
      "Total number of actions : 17\n",
      "\n",
      "Model's performance loss before weight fit 2.51 \n",
      "Model's performance loss after weight fit 0.81\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 16 \n",
      "Reward : 1.6999871826171873\n",
      "\n",
      "Episode 113 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 114\n",
      "Current model loss 2.5992484092712402\n",
      "Model loss previously 0.8100128173828125\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 7 : [0.99098925 0.82099858 0.027138   0.81064552 0.7728552 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.56 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 15 were loaded\n",
      "Model's performance loss before weight fit 2.6 \n",
      "Model's performance loss after weight fit 1.49\n",
      "Model's performance accuracy before weight fit 0.56 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 15 \n",
      "Reward : 1.11\n",
      "\n",
      "Episode 114 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 115\n",
      "No change in model performance :\n",
      "previous loss 1.4882640838623047\n",
      "current loss 1.1057980060577393\n",
      "\n",
      "No action performed\n",
      "Episode 115 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 116\n",
      "No change in model performance :\n",
      "previous loss 1.1057980060577393\n",
      "current loss 0.511756956577301\n",
      "\n",
      "No action performed\n",
      "Episode 116 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 117\n",
      "No change in model performance :\n",
      "previous loss 0.511756956577301\n",
      "current loss 0.39712274074554443\n",
      "\n",
      "No action performed\n",
      "Episode 117 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 118\n",
      "Current model loss 0.8170531988143921\n",
      "Model loss previously 0.39712274074554443\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 12 : [0.51176373 0.63652655 0.94565309 0.71034578 0.77639152]\n",
      "Determining action ...\n",
      "No significant change in performance accuracy, so no new action\n",
      "\n",
      "Model's performance loss before weight fit 0.82 \n",
      "Model's performance loss after weight fit 0.82\n",
      "Model's performance accuracy before weight fit 0.84 \n",
      "Model's performance loss after weight fit 0.84\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0\n",
      "\n",
      "Episode 118 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 119\n",
      "Current model loss 0.981913149356842\n",
      "Model loss previously 0.8170531988143921\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 2 : [0.49810453 0.37105618 0.62522779 0.64861572 0.97733257]\n",
      "Determining action ...\n",
      "Model's current performance 0.75 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 9 were loaded\n",
      "Model's performance loss before weight fit 0.98 \n",
      "Model's performance loss after weight fit 1.21\n",
      "Model's performance accuracy before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.78\n",
      "\n",
      "Action determination done\n",
      "Action taken : 9 \n",
      "Reward : -0.22999999999999998\n",
      "\n",
      "Episode 119 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 120\n",
      "Current model loss 2.2762207984924316\n",
      "Model loss previously 1.2088980674743652\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 1 : [0.8116407  0.60258944 0.67689935 0.19362766 0.66463717]\n",
      "Determining action ...\n",
      "Model's current performance 0.75 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 2.28\n",
      "\n",
      "Target accuracy (0.80) and loss (0.91) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.5224592685699463\n",
      "Model weights for action 17 has been saved at Model_weights/model_action17.weights.h5\n",
      "Model reward for new action 17 : 1.7575407314300535\n",
      "\n",
      "Total number of actions : 18\n",
      "\n",
      "Model's performance loss before weight fit 2.28 \n",
      "Model's performance loss after weight fit 0.52\n",
      "Model's performance accuracy before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.78\n",
      "\n",
      "Action determination done\n",
      "Action taken : 17 \n",
      "Reward : 1.7575407314300535\n",
      "\n",
      "Episode 120 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 121\n",
      "Current model loss 1.4538555145263672\n",
      "Model loss previously 0.5224592685699463\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 4 : [0.7193133  0.75954398 0.85070242 0.69579637 0.88261513]\n",
      "Determining action ...\n",
      "Model's current performance 0.75 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 1 were loaded\n",
      "Model's performance loss before weight fit 1.45 \n",
      "Model's performance loss after weight fit 3.89\n",
      "Model's performance accuracy before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.62\n",
      "\n",
      "Action determination done\n",
      "Action taken : 1 \n",
      "Reward : -2.4400000000000004\n",
      "\n",
      "Episode 121 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 122\n",
      "No change in model performance :\n",
      "previous loss 3.894425868988037\n",
      "current loss 2.5779764652252197\n",
      "\n",
      "No action performed\n",
      "Episode 122 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 123\n",
      "No change in model performance :\n",
      "previous loss 2.5779764652252197\n",
      "current loss 2.5496902465820312\n",
      "\n",
      "No action performed\n",
      "Episode 123 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 124\n",
      "No change in model performance :\n",
      "previous loss 2.5496902465820312\n",
      "current loss 1.784001111984253\n",
      "\n",
      "No action performed\n",
      "Episode 124 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 125\n",
      "Current model loss 3.8646509647369385\n",
      "Model loss previously 1.784001111984253\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 3 : [0.62969788 0.66614154 0.14716177 0.83455182 0.71282035]\n",
      "Determining action ...\n",
      "Model's current performance 0.5 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "Model's performance loss before weight fit 3.86 \n",
      "Model's performance loss after weight fit 1.99\n",
      "Model's performance accuracy before weight fit 0.5 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 12 \n",
      "Reward : 1.8699999999999999\n",
      "\n",
      "Episode 125 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 126\n",
      "Current model loss 2.392324447631836\n",
      "Model loss previously 1.9855310916900635\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 8 : [0.68065048 0.66095251 0.08082127 0.71958894 0.6193471 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "Model's performance loss before weight fit 2.39 \n",
      "Model's performance loss after weight fit 0.58\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 1.81\n",
      "\n",
      "Episode 126 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 127\n",
      "Current model loss 1.1883927583694458\n",
      "Model loss previously 0.5759110450744629\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 1 : [0.01372793 0.7384768  0.6712575  0.60855981 0.3204073 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 1 were loaded\n",
      "Model's performance loss before weight fit 1.19 \n",
      "Model's performance loss after weight fit 4.32\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 1 \n",
      "Reward : -3.1300000000000003\n",
      "\n",
      "Episode 127 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 128\n",
      "Current model loss 4.7425456047058105\n",
      "Model loss previously 4.323053359985352\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 1 : [0.04089155 0.69628693 0.70218273 0.07758874 0.68114244]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "Model's performance loss before weight fit 4.74 \n",
      "Model's performance loss after weight fit 0.82\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.78\n",
      "\n",
      "Action determination done\n",
      "Action taken : 12 \n",
      "Reward : 3.9200000000000004\n",
      "\n",
      "Episode 128 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 129\n",
      "Current model loss 3.198542594909668\n",
      "Model loss previously 0.8180013298988342\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 1 : [0.07385929 0.10178877 0.70641896 0.96814116 0.66730853]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 11 were loaded\n",
      "Model's performance loss before weight fit 3.2 \n",
      "Model's performance loss after weight fit 3.77\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.62\n",
      "\n",
      "Action determination done\n",
      "Action taken : 11 \n",
      "Reward : -0.5699999999999998\n",
      "\n",
      "Episode 129 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 130\n",
      "No change in model performance :\n",
      "previous loss 3.773616313934326\n",
      "current loss 3.1984808444976807\n",
      "\n",
      "No action performed\n",
      "Episode 130 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 131\n",
      "No change in model performance :\n",
      "previous loss 3.1984808444976807\n",
      "current loss 1.2151248455047607\n",
      "\n",
      "No action performed\n",
      "Episode 131 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 132\n",
      "Current model loss 2.1769373416900635\n",
      "Model loss previously 1.2151248455047607\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 2 : [0.79641333 0.07223604 0.71634651 0.99259211 0.7568586 ]\n",
      "Determining action ...\n",
      "No significant change in performance accuracy, so no new action\n",
      "\n",
      "Model's performance loss before weight fit 2.18 \n",
      "Model's performance loss after weight fit 2.18\n",
      "Model's performance accuracy before weight fit 0.84 \n",
      "Model's performance loss after weight fit 0.84\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0\n",
      "\n",
      "Episode 132 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 133\n",
      "Current model loss 2.833860397338867\n",
      "Model loss previously 2.1769373416900635\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 1 : [0.90200939 0.78940444 0.7878376  0.06807052 0.50884187]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 14 were loaded\n",
      "Model's performance loss before weight fit 2.83 \n",
      "Model's performance loss after weight fit 1.52\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 14 \n",
      "Reward : 1.31\n",
      "\n",
      "Episode 133 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 134\n",
      "No change in model performance :\n",
      "previous loss 1.517664909362793\n",
      "current loss 0.5491385459899902\n",
      "\n",
      "No action performed\n",
      "Episode 134 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 135\n",
      "No change in model performance :\n",
      "previous loss 0.5491385459899902\n",
      "current loss 0.5447998046875\n",
      "\n",
      "No action performed\n",
      "Episode 135 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 136\n",
      "Current model loss 0.6198784112930298\n",
      "Model loss previously 0.5447998046875\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 0 : [0.12277345 0.83088489 0.98102324 0.92333715 0.01659792]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 7 were loaded\n",
      "Model's performance loss before weight fit 0.62 \n",
      "Model's performance loss after weight fit 3.44\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 7 \n",
      "Reward : -2.82\n",
      "\n",
      "Episode 136 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 137\n",
      "No change in model performance :\n",
      "previous loss 3.4363789558410645\n",
      "current loss 2.5028772354125977\n",
      "\n",
      "No action performed\n",
      "Episode 137 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 138\n",
      "Current model loss 4.824392318725586\n",
      "Model loss previously 2.5028772354125977\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 11 : [0.90555764 0.79026708 0.33853483 0.8976736  0.70883378]\n",
      "Determining action ...\n",
      "Model's current performance 0.53 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 13 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 13\n",
      "\n",
      "Model's performance loss before weight fit 4.82 \n",
      "Model's performance loss after weight fit 2.4\n",
      "Model's performance accuracy before weight fit 0.53 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 13 \n",
      "Reward : 2.4200000000000004\n",
      "\n",
      "Episode 138 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 139\n",
      "No change in model performance :\n",
      "previous loss 2.4008841514587402\n",
      "current loss 1.0066595077514648\n",
      "\n",
      "No action performed\n",
      "Episode 139 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 140\n",
      "Current model loss 2.054669141769409\n",
      "Model loss previously 1.0066595077514648\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 5 : [0.80308983 0.90313586 0.80185956 0.64814567 0.021095  ]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 5 were loaded\n",
      "Model's performance loss before weight fit 2.05 \n",
      "Model's performance loss after weight fit 0.43\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.78\n",
      "\n",
      "Action determination done\n",
      "Action taken : 5 \n",
      "Reward : 1.6199999999999999\n",
      "\n",
      "Episode 140 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 141\n",
      "Current model loss 2.039492130279541\n",
      "Model loss previously 0.43047887086868286\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 4 : [0.96120281 0.0850703  0.73123477 0.87315923 0.16619763]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 2 were loaded\n",
      "Model's performance loss before weight fit 2.04 \n",
      "Model's performance loss after weight fit 0.59\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 2 \n",
      "Reward : 1.4500000000000002\n",
      "\n",
      "Episode 141 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 142\n",
      "Current model loss 1.5528602600097656\n",
      "Model loss previously 0.5851351022720337\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 2 : [0.37674062 0.73836337 0.8095199  0.75784308 0.62849196]\n",
      "Determining action ...\n",
      "Model's current performance 0.56 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.55\n",
      "\n",
      "Target accuracy (0.80) and loss (0.62) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.38995152711868286\n",
      "Model weights for action 18 has been saved at Model_weights/model_action18.weights.h5\n",
      "Model reward for new action 18 : 1.1600484728813172\n",
      "\n",
      "Total number of actions : 19\n",
      "\n",
      "Model's performance loss before weight fit 1.55 \n",
      "Model's performance loss after weight fit 0.39\n",
      "Model's performance accuracy before weight fit 0.56 \n",
      "Model's performance loss after weight fit 0.88\n",
      "\n",
      "Action determination done\n",
      "Action taken : 18 \n",
      "Reward : 1.1600484728813172\n",
      "\n",
      "Episode 142 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 143\n",
      "Current model loss 0.4097120463848114\n",
      "Model loss previously 0.38995152711868286\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 4 : [0.92851634 0.4968214  0.85094472 0.98515753 0.7401076 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.78 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 9 were loaded\n",
      "Model's performance loss before weight fit 0.41 \n",
      "Model's performance loss after weight fit 0.84\n",
      "Model's performance accuracy before weight fit 0.78 \n",
      "Model's performance loss after weight fit 0.72\n",
      "\n",
      "Action determination done\n",
      "Action taken : 9 \n",
      "Reward : -0.43\n",
      "\n",
      "Episode 143 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 144\n",
      "Current model loss 2.3965554237365723\n",
      "Model loss previously 0.8353614211082458\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 4 : [0.72368821 0.24344137 0.73729257 0.92685531 0.73119862]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "Model's performance loss before weight fit 2.4 \n",
      "Model's performance loss after weight fit 1.43\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 10 \n",
      "Reward : 0.97\n",
      "\n",
      "Episode 144 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 145\n",
      "No change in model performance :\n",
      "previous loss 1.4259461164474487\n",
      "current loss 0.3770367503166199\n",
      "\n",
      "No action performed\n",
      "Episode 145 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 146\n",
      "Current model loss 1.9989545345306396\n",
      "Model loss previously 0.3770367503166199\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 6 : [0.86008344 0.16330563 0.81328001 0.60930203 0.82201356]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "Model's performance loss before weight fit 2.0 \n",
      "Model's performance loss after weight fit 1.19\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 12 \n",
      "Reward : 0.81\n",
      "\n",
      "Episode 146 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 147\n",
      "Current model loss 1.3328005075454712\n",
      "Model loss previously 1.1880698204040527\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 3 : [0.43079725 0.94302562 0.8338489  0.79730095 0.87366676]\n",
      "Determining action ...\n",
      "Model's current performance 0.75 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.33\n",
      "Model trained from scratch, new performance loss : 0.5342774391174316\n",
      "Model weights for action 19 has been saved at Model_weights/model_action19.weights.h5\n",
      "Model reward for new action 19 : 0.7957225608825684\n",
      "\n",
      "Total number of actions : 20\n",
      "\n",
      "Model's performance loss before weight fit 1.33 \n",
      "Model's performance loss after weight fit 0.53\n",
      "Model's performance accuracy before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.97\n",
      "\n",
      "Action determination done\n",
      "Action taken : 19 \n",
      "Reward : 0.7957225608825684\n",
      "\n",
      "Episode 147 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 148\n",
      "Current model loss 4.215976715087891\n",
      "Model loss previously 0.5342774391174316\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 12 : [0.99623826 0.75735535 0.82020542 0.89063328 0.18346489]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 2 were loaded\n",
      "Model's performance loss before weight fit 4.22 \n",
      "Model's performance loss after weight fit 0.68\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 2 \n",
      "Reward : 3.5399999999999996\n",
      "\n",
      "Episode 148 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 149\n",
      "No change in model performance :\n",
      "previous loss 0.6757824420928955\n",
      "current loss 0.5301839709281921\n",
      "\n",
      "No action performed\n",
      "Episode 149 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 150\n",
      "Current model loss 1.4120793342590332\n",
      "Model loss previously 0.5301839709281921\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 2 : [0.94698057 0.05246697 0.66614014 0.85938961 0.65612268]\n",
      "Determining action ...\n",
      "Model's current performance 0.75 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.41\n",
      "Model training failed, new performance 1.5000925064086914 is greater than the previous loss 1.41\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.41\n",
      "\n",
      "Target accuracy (0.80) and loss (0.56) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.5570583343505859\n",
      "Model weights for action 20 has been saved at Model_weights/model_action20.weights.h5\n",
      "Model reward for new action 20 : 0.852941665649414\n",
      "\n",
      "Total number of actions : 21\n",
      "\n",
      "Model's performance loss before weight fit 1.41 \n",
      "Model's performance loss after weight fit 0.56\n",
      "Model's performance accuracy before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.94\n",
      "\n",
      "Action determination done\n",
      "Action taken : 20 \n",
      "Reward : 0.852941665649414\n",
      "\n",
      "Episode 150 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 151\n",
      "Current model loss 1.3113240003585815\n",
      "Model loss previously 0.5570583343505859\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 4 : [0.69547404 0.06865662 0.13568897 0.76741223 0.98327333]\n",
      "Determining action ...\n",
      "No significant change in performance accuracy, so no new action\n",
      "\n",
      "Model's performance loss before weight fit 1.31 \n",
      "Model's performance loss after weight fit 1.31\n",
      "Model's performance accuracy before weight fit 0.81 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0\n",
      "\n",
      "Episode 151 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 152\n",
      "No change in model performance :\n",
      "previous loss 1.3113240003585815\n",
      "current loss 0.973845899105072\n",
      "\n",
      "No action performed\n",
      "Episode 152 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 153\n",
      "Current model loss 2.847820997238159\n",
      "Model loss previously 0.973845899105072\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 6 : [0.87677833 0.0117645  0.8218235  0.93083553 0.7105141 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 3 were loaded\n",
      "Model's performance loss before weight fit 2.85 \n",
      "Model's performance loss after weight fit 2.12\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.62\n",
      "\n",
      "Action determination done\n",
      "Action taken : 3 \n",
      "Reward : 0.73\n",
      "\n",
      "Episode 153 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 154\n",
      "No change in model performance :\n",
      "previous loss 2.1205644607543945\n",
      "current loss 0.540771484375\n",
      "\n",
      "No action performed\n",
      "Episode 154 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 155\n",
      "Current model loss 0.5544751882553101\n",
      "Model loss previously 0.540771484375\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 0 : [0.75639158 0.66919258 0.13689226 0.78886662 0.01441876]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 9 were loaded\n",
      "Model's performance loss before weight fit 0.55 \n",
      "Model's performance loss after weight fit 1.34\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 9 \n",
      "Reward : -0.79\n",
      "\n",
      "Episode 155 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 156\n",
      "No change in model performance :\n",
      "previous loss 1.337109923362732\n",
      "current loss 1.0116032361984253\n",
      "\n",
      "No action performed\n",
      "Episode 156 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 157\n",
      "Current model loss 1.23344087600708\n",
      "Model loss previously 1.0116032361984253\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 4 : [0.85266043 0.16736596 0.95654272 0.88271986 0.54470901]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.23\n",
      "Model trained from scratch, new performance loss : 0.5037265419960022\n",
      "Model weights for action 21 has been saved at Model_weights/model_action21.weights.h5\n",
      "Model reward for new action 21 : 0.7262734580039978\n",
      "\n",
      "Total number of actions : 22\n",
      "\n",
      "Model's performance loss before weight fit 1.23 \n",
      "Model's performance loss after weight fit 0.5\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.97\n",
      "\n",
      "Action determination done\n",
      "Action taken : 21 \n",
      "Reward : 0.7262734580039978\n",
      "\n",
      "Episode 157 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 158\n",
      "Current model loss 2.1851439476013184\n",
      "Model loss previously 0.5037265419960022\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 5 : [0.69429219 0.64169914 0.02059422 0.89708144 0.0180301 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.78 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 5 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 5\n",
      "\n",
      "Model's performance loss before weight fit 2.19 \n",
      "Model's performance loss after weight fit 0.96\n",
      "Model's performance accuracy before weight fit 0.78 \n",
      "Model's performance loss after weight fit 0.62\n",
      "\n",
      "Action determination done\n",
      "Action taken : 5 \n",
      "Reward : 1.23\n",
      "\n",
      "Episode 158 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 159\n",
      "Current model loss 1.059316635131836\n",
      "Model loss previously 0.9582931399345398\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 7 : [0.69113618 0.67154046 0.0171162  0.84594223 0.84402973]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 3 were loaded\n",
      "Model's performance loss before weight fit 1.06 \n",
      "Model's performance loss after weight fit 0.6\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.72\n",
      "\n",
      "Action determination done\n",
      "Action taken : 3 \n",
      "Reward : 0.4600000000000001\n",
      "\n",
      "Episode 159 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 160\n",
      "No change in model performance :\n",
      "previous loss 0.5967524647712708\n",
      "current loss 0.5226966142654419\n",
      "\n",
      "No action performed\n",
      "Episode 160 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 161\n",
      "Current model loss 0.6466376781463623\n",
      "Model loss previously 0.5226966142654419\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 3 : [9.39094346e-01 7.32573165e-01 6.34368046e-01 6.06949416e-01\n",
      " 2.86526622e-04]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "Model's performance loss before weight fit 0.65 \n",
      "Model's performance loss after weight fit 1.52\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 10 \n",
      "Reward : -0.87\n",
      "\n",
      "Episode 161 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 162\n",
      "Current model loss 1.8732727766036987\n",
      "Model loss previously 1.524006724357605\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 3 : [0.6411159  0.85548984 0.68629719 0.01500516 0.18769503]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 3 were loaded\n",
      "Model's performance loss before weight fit 1.87 \n",
      "Model's performance loss after weight fit 0.63\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.62\n",
      "\n",
      "Action determination done\n",
      "Action taken : 3 \n",
      "Reward : 1.2400000000000002\n",
      "\n",
      "Episode 162 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 163\n",
      "Current model loss 1.576290488243103\n",
      "Model loss previously 0.6290586590766907\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 0 : [6.09981527e-01 8.34412816e-01 9.40886382e-01 2.73965400e-01\n",
      " 2.80524463e-04]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 1.58 \n",
      "Model's performance loss after weight fit 0.59\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0.9900000000000001\n",
      "\n",
      "Episode 163 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 164\n",
      "No change in model performance :\n",
      "previous loss 0.5871584415435791\n",
      "current loss 0.5613889098167419\n",
      "\n",
      "No action performed\n",
      "Episode 164 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 165\n",
      "Current model loss 0.6494342684745789\n",
      "Model loss previously 0.5613889098167419\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 6 : [0.79526543 0.05243313 0.75784353 0.81557051 0.71501165]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.65\n",
      "\n",
      "Target accuracy (0.80) and loss (0.26) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.2437780350446701\n",
      "Model weights for action 22 has been saved at Model_weights/model_action22.weights.h5\n",
      "Model reward for new action 22 : 0.4062219649553299\n",
      "\n",
      "Total number of actions : 23\n",
      "\n",
      "Model's performance loss before weight fit 0.65 \n",
      "Model's performance loss after weight fit 0.24\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.91\n",
      "\n",
      "Action determination done\n",
      "Action taken : 22 \n",
      "Reward : 0.4062219649553299\n",
      "\n",
      "Episode 165 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 166\n",
      "Current model loss 2.2236452102661133\n",
      "Model loss previously 0.2437780350446701\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 4 : [0.89821595 0.40131341 0.79745034 0.96397471 0.0944796 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 2.22\n",
      "Model trained from scratch, new performance loss : 0.3403836488723755\n",
      "Model weights for action 23 has been saved at Model_weights/model_action23.weights.h5\n",
      "Model reward for new action 23 : 1.8796163511276247\n",
      "\n",
      "Total number of actions : 24\n",
      "\n",
      "Model's performance loss before weight fit 2.22 \n",
      "Model's performance loss after weight fit 0.34\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.78\n",
      "\n",
      "Action determination done\n",
      "Action taken : 23 \n",
      "Reward : 1.8796163511276247\n",
      "\n",
      "Episode 166 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 167\n",
      "Current model loss 1.4401262998580933\n",
      "Model loss previously 0.3403836488723755\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 4 : [0.03201777 0.97886527 0.73619608 0.85684453 0.09720086]\n",
      "Determining action ...\n",
      "Model's current performance 0.75 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.44\n",
      "Model trained from scratch, new performance loss : 1.0105854272842407\n",
      "Model weights for action 24 has been saved at Model_weights/model_action24.weights.h5\n",
      "Model reward for new action 24 : 0.4294145727157592\n",
      "\n",
      "Total number of actions : 25\n",
      "\n",
      "Model's performance loss before weight fit 1.44 \n",
      "Model's performance loss after weight fit 1.01\n",
      "Model's performance accuracy before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.94\n",
      "\n",
      "Action determination done\n",
      "Action taken : 24 \n",
      "Reward : 0.4294145727157592\n",
      "\n",
      "Episode 167 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 168\n",
      "Current model loss 2.188154935836792\n",
      "Model loss previously 1.0105854272842407\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 0 : [0.63615358 0.18577763 0.86745684 0.67299483 0.1971305 ]\n",
      "Determining action ...\n",
      "No significant change in performance accuracy, so no new action\n",
      "\n",
      "Model's performance loss before weight fit 2.19 \n",
      "Model's performance loss after weight fit 2.19\n",
      "Model's performance accuracy before weight fit 0.81 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0\n",
      "\n",
      "Episode 168 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 169\n",
      "Current model loss 3.3703246116638184\n",
      "Model loss previously 2.188154935836792\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "The similarity score of target state 12 : [0.62722191 0.96408355 0.01677866 0.89072392 0.83130429]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 21 were loaded\n",
      "Model's performance loss before weight fit 3.37 \n",
      "Model's performance loss after weight fit 1.52\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.62\n",
      "\n",
      "Action determination done\n",
      "Action taken : 21 \n",
      "Reward : 1.85\n",
      "\n",
      "Episode 169 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 170\n",
      "Current model loss 2.5890491008758545\n",
      "Model loss previously 1.52146315574646\n",
      "Determining State...\n",
      "Number of states available 13\n",
      "No appropriate state found in the existing list, creating new state\n",
      "New state 13 created\n",
      "Target state : 13\n",
      "Number of similar columns 5\n",
      "\n",
      "Determining action ...\n",
      "Model's current performance 0.56 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 5 were loaded\n",
      "Model's performance loss before weight fit 2.59 \n",
      "Model's performance loss after weight fit 1.17\n",
      "Model's performance accuracy before weight fit 0.56 \n",
      "Model's performance loss after weight fit 0.53\n",
      "\n",
      "Action determination done\n",
      "Action taken : 5 \n",
      "Reward : 1.42\n",
      "\n",
      "Episode 170 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 171\n",
      "Current model loss 1.203758716583252\n",
      "Model loss previously 1.1726795434951782\n",
      "Determining State...\n",
      "Number of states available 14\n",
      "The similarity score of target state 11 : [0.96595367 0.19017911 0.70707433 0.77277209 0.65156293]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 13 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 13\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.2\n",
      "Model trained from scratch, new performance loss : 0.5465799570083618\n",
      "Model weights for action 25 has been saved at Model_weights/model_action25.weights.h5\n",
      "Model reward for new action 25 : 0.6534200429916381\n",
      "\n",
      "Total number of actions : 26\n",
      "\n",
      "Model's performance loss before weight fit 1.2 \n",
      "Model's performance loss after weight fit 0.55\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.94\n",
      "\n",
      "Action determination done\n",
      "Action taken : 25 \n",
      "Reward : 0.6534200429916381\n",
      "\n",
      "Episode 171 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 172\n",
      "Current model loss 4.716886043548584\n",
      "Model loss previously 0.5465799570083618\n",
      "Determining State...\n",
      "Number of states available 14\n",
      "The similarity score of target state 1 : [0.80139671 0.71849303 0.99304836 0.99207085 0.83874782]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "Model's performance loss before weight fit 4.72 \n",
      "Model's performance loss after weight fit 2.44\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.53\n",
      "\n",
      "Action determination done\n",
      "Action taken : 12 \n",
      "Reward : 2.28\n",
      "\n",
      "Episode 172 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 173\n",
      "Current model loss 2.4759514331817627\n",
      "Model loss previously 2.439764976501465\n",
      "Determining State...\n",
      "Number of states available 14\n",
      "The similarity score of target state 4 : [0.16993773 0.68634819 0.91624076 0.15028251 0.6051506 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "Model's performance loss before weight fit 2.48 \n",
      "Model's performance loss after weight fit 1.04\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 10 \n",
      "Reward : 1.44\n",
      "\n",
      "Episode 173 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 174\n",
      "Current model loss 2.881650686264038\n",
      "Model loss previously 1.0389735698699951\n",
      "Determining State...\n",
      "Number of states available 14\n",
      "The similarity score of target state 0 : [0.61060317 0.9987657  0.87661175 0.7506236  0.21061133]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 2.88 \n",
      "Model's performance loss after weight fit 0.81\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 2.07\n",
      "\n",
      "Episode 174 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 175\n",
      "No change in model performance :\n",
      "previous loss 0.8087250590324402\n",
      "current loss 0.5884082913398743\n",
      "\n",
      "No action performed\n",
      "Episode 175 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 176\n",
      "Current model loss 1.121608853340149\n",
      "Model loss previously 0.5884082913398743\n",
      "Determining State...\n",
      "Number of states available 14\n",
      "The similarity score of target state 1 : [0.99833812 0.8479467  0.83956266 0.11708957 0.93508798]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 24 were loaded\n",
      "Model's performance loss before weight fit 1.12 \n",
      "Model's performance loss after weight fit 1.3\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 24 \n",
      "Reward : -0.17999999999999994\n",
      "\n",
      "Episode 176 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 177\n",
      "No change in model performance :\n",
      "previous loss 1.2999794483184814\n",
      "current loss 0.815794825553894\n",
      "\n",
      "No action performed\n",
      "Episode 177 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 178\n",
      "Current model loss 3.976522445678711\n",
      "Model loss previously 0.815794825553894\n",
      "Determining State...\n",
      "Number of states available 14\n",
      "The similarity score of target state 1 : [0.85766754 0.75183033 0.82877616 0.37818573 0.50361168]\n",
      "Determining action ...\n",
      "Model's current performance 0.53 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 24 were loaded\n",
      "Model's performance loss before weight fit 3.98 \n",
      "Model's performance loss after weight fit 3.98\n",
      "Model's performance accuracy before weight fit 0.53 \n",
      "Model's performance loss after weight fit 0.53\n",
      "\n",
      "Action determination done\n",
      "Action taken : 24 \n",
      "Reward : 0.0\n",
      "\n",
      "Episode 178 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 179\n",
      "Current model loss 4.130870819091797\n",
      "Model loss previously 3.976522445678711\n",
      "Determining State...\n",
      "Number of states available 14\n",
      "The similarity score of target state 1 : [0.0431941  0.89259085 0.95818281 0.1627341  0.80649276]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "Model's performance loss before weight fit 4.13 \n",
      "Model's performance loss after weight fit 0.61\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 12 \n",
      "Reward : 3.52\n",
      "\n",
      "Episode 179 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 180\n",
      "No change in model performance :\n",
      "previous loss 0.6073930263519287\n",
      "current loss 0.5658913850784302\n",
      "\n",
      "No action performed\n",
      "Episode 180 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 181\n",
      "Current model loss 1.4346665143966675\n",
      "Model loss previously 0.5658913850784302\n",
      "Determining State...\n",
      "Number of states available 14\n",
      "The similarity score of target state 0 : [0.60937965 0.78634595 0.36982483 0.0626556  0.61221699]\n",
      "Determining action ...\n",
      "Model's current performance 0.78 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 1.43 \n",
      "Model's performance loss after weight fit 1.1\n",
      "Model's performance accuracy before weight fit 0.78 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0.32999999999999985\n",
      "\n",
      "Episode 181 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 182\n",
      "No change in model performance :\n",
      "previous loss 1.1036975383758545\n",
      "current loss 0.6403616666793823\n",
      "\n",
      "No action performed\n",
      "Episode 182 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 183\n",
      "Current model loss 1.5733399391174316\n",
      "Model loss previously 0.6403616666793823\n",
      "Determining State...\n",
      "Number of states available 14\n",
      "The similarity score of target state 2 : [0.42134991 0.96293804 0.93748805 0.70605956 0.6985023 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.57\n",
      "Model trained from scratch, new performance loss : 1.494598627090454\n",
      "Model weights for action 26 has been saved at Model_weights/model_action26.weights.h5\n",
      "Model reward for new action 26 : 0.07540137290954596\n",
      "\n",
      "Total number of actions : 27\n",
      "\n",
      "Model's performance loss before weight fit 1.57 \n",
      "Model's performance loss after weight fit 1.49\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.91\n",
      "\n",
      "Action determination done\n",
      "Action taken : 26 \n",
      "Reward : 0.07540137290954596\n",
      "\n",
      "Episode 183 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 184\n",
      "Current model loss 4.6784467697143555\n",
      "Model loss previously 1.494598627090454\n",
      "Determining State...\n",
      "Number of states available 14\n",
      "No appropriate state found in the existing list, creating new state\n",
      "New state 14 created\n",
      "Target state : 14\n",
      "Number of similar columns 4\n",
      "\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 4.68 \n",
      "Model's performance loss after weight fit 0.72\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.53\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 3.96\n",
      "\n",
      "Episode 184 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 185\n",
      "Current model loss 1.138048768043518\n",
      "Model loss previously 0.7192885279655457\n",
      "Determining State...\n",
      "Number of states available 15\n",
      "The similarity score of target state 2 : [0.85032895 0.65642639 0.47704899 0.82725238 0.15813252]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.14\n",
      "\n",
      "Target accuracy (0.80) and loss (0.46) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.44781750440597534\n",
      "Model weights for action 27 has been saved at Model_weights/model_action27.weights.h5\n",
      "Model reward for new action 27 : 0.6921824955940246\n",
      "\n",
      "Total number of actions : 28\n",
      "\n",
      "Model's performance loss before weight fit 1.14 \n",
      "Model's performance loss after weight fit 0.45\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.84\n",
      "\n",
      "Action determination done\n",
      "Action taken : 27 \n",
      "Reward : 0.6921824955940246\n",
      "\n",
      "Episode 185 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 186\n",
      "Current model loss 0.9990837574005127\n",
      "Model loss previously 0.44781750440597534\n",
      "Determining State...\n",
      "Number of states available 15\n",
      "The similarity score of target state 6 : [0.78843533 0.08506008 0.9987697  0.88992858 0.79301492]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "Model's performance loss before weight fit 1.0 \n",
      "Model's performance loss after weight fit 0.84\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.75\n",
      "\n",
      "Action determination done\n",
      "Action taken : 12 \n",
      "Reward : 0.16000000000000003\n",
      "\n",
      "Episode 186 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 187\n",
      "Current model loss 1.9342913627624512\n",
      "Model loss previously 0.8390172719955444\n",
      "Determining State...\n",
      "Number of states available 15\n",
      "The similarity score of target state 4 : [0.6109162  0.19895163 0.41619292 0.68533388 0.7528715 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 14 were loaded\n",
      "Model's performance loss before weight fit 1.93 \n",
      "Model's performance loss after weight fit 0.58\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.72\n",
      "\n",
      "Action determination done\n",
      "Action taken : 14 \n",
      "Reward : 1.35\n",
      "\n",
      "Episode 187 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 188\n",
      "Current model loss 0.5937159061431885\n",
      "Model loss previously 0.577211320400238\n",
      "Determining State...\n",
      "Number of states available 15\n",
      "The similarity score of target state 2 : [0.80866932 0.11774033 0.63241795 0.67274571 0.72841115]\n",
      "Determining action ...\n",
      "Model's current performance 0.75 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.59\n",
      "Model training failed, new performance 1.5024259090423584 is greater than the previous loss 0.59\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.59\n",
      "\n",
      "Target accuracy (0.80) and loss (0.24) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.23055896162986755\n",
      "Model weights for action 28 has been saved at Model_weights/model_action28.weights.h5\n",
      "Model reward for new action 28 : 0.3594410383701324\n",
      "\n",
      "Total number of actions : 29\n",
      "\n",
      "Model's performance loss before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.23\n",
      "Model's performance accuracy before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.88\n",
      "\n",
      "Action determination done\n",
      "Action taken : 28 \n",
      "Reward : 0.3594410383701324\n",
      "\n",
      "Episode 188 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 189\n",
      "Current model loss 1.0899145603179932\n",
      "Model loss previously 0.23055896162986755\n",
      "Determining State...\n",
      "Number of states available 15\n",
      "The similarity score of target state 0 : [0.79738273 0.62195657 0.99643763 0.67977379 0.21057751]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 11 were loaded\n",
      "Model's performance loss before weight fit 1.09 \n",
      "Model's performance loss after weight fit 1.25\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.78\n",
      "\n",
      "Action determination done\n",
      "Action taken : 11 \n",
      "Reward : -0.15999999999999992\n",
      "\n",
      "Episode 189 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 190\n",
      "No change in model performance :\n",
      "previous loss 1.24907386302948\n",
      "current loss 0.8766412734985352\n",
      "\n",
      "No action performed\n",
      "Episode 190 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 191\n",
      "Current model loss 4.8375678062438965\n",
      "Model loss previously 0.8766412734985352\n",
      "Determining State...\n",
      "Number of states available 15\n",
      "The similarity score of target state 4 : [0.71477303 0.02460812 0.77796265 0.8148154  0.9765067 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.56 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 15 were loaded\n",
      "Model's performance loss before weight fit 4.84 \n",
      "Model's performance loss after weight fit 1.45\n",
      "Model's performance accuracy before weight fit 0.56 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 15 \n",
      "Reward : 3.3899999999999997\n",
      "\n",
      "Episode 191 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 192\n",
      "No change in model performance :\n",
      "previous loss 1.4549522399902344\n",
      "current loss 0.8754676580429077\n",
      "\n",
      "No action performed\n",
      "Episode 192 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 193\n",
      "Current model loss 1.4850618839263916\n",
      "Model loss previously 0.8754676580429077\n",
      "Determining State...\n",
      "Number of states available 15\n",
      "The similarity score of target state 4 : [0.76324827 0.09197956 0.75443094 0.75808891 0.55557013]\n",
      "Determining action ...\n",
      "Model's current performance 0.78 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "Model's performance loss before weight fit 1.49 \n",
      "Model's performance loss after weight fit 0.95\n",
      "Model's performance accuracy before weight fit 0.78 \n",
      "Model's performance loss after weight fit 0.72\n",
      "\n",
      "Action determination done\n",
      "Action taken : 10 \n",
      "Reward : 0.54\n",
      "\n",
      "Episode 193 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 194\n",
      "Current model loss 2.413717746734619\n",
      "Model loss previously 0.9469543695449829\n",
      "Determining State...\n",
      "Number of states available 15\n",
      "The similarity score of target state 2 : [0.80092571 0.76398754 0.78772852 0.64613911 0.45598372]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 2.41 \n",
      "Model's performance loss after weight fit 0.53\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 1.8800000000000001\n",
      "\n",
      "Episode 194 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 195\n",
      "Current model loss 0.6692901253700256\n",
      "Model loss previously 0.5299868583679199\n",
      "Determining State...\n",
      "Number of states available 15\n",
      "The similarity score of target state 12 : [0.62394418 0.62372523 0.70652608 0.78076598 0.48392676]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 2 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 2\n",
      "\n",
      "Model's performance loss before weight fit 0.67 \n",
      "Model's performance loss after weight fit 0.51\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.78\n",
      "\n",
      "Action determination done\n",
      "Action taken : 2 \n",
      "Reward : 0.16000000000000003\n",
      "\n",
      "Episode 195 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 196\n",
      "No change in model performance :\n",
      "previous loss 0.5100012421607971\n",
      "current loss 0.5002037286758423\n",
      "\n",
      "No action performed\n",
      "Episode 196 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 197\n",
      "Current model loss 0.6093189120292664\n",
      "Model loss previously 0.5002037286758423\n",
      "Determining State...\n",
      "Number of states available 15\n",
      "The similarity score of target state 12 : [0.84836789 0.65937364 0.71981301 0.68410207 0.55590629]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 14 were loaded\n",
      "Model's performance loss before weight fit 0.61 \n",
      "Model's performance loss after weight fit 1.32\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.44\n",
      "\n",
      "Action determination done\n",
      "Action taken : 14 \n",
      "Reward : -0.7100000000000001\n",
      "\n",
      "Episode 197 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 198\n",
      "Current model loss 1.4513804912567139\n",
      "Model loss previously 1.3167543411254883\n",
      "Determining State...\n",
      "Number of states available 15\n",
      "The similarity score of target state 10 : [0.86632952 0.88700922 0.88373643 0.45316154 0.06110188]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 1.45 \n",
      "Model's performance loss after weight fit 1.13\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0.32000000000000006\n",
      "\n",
      "Episode 198 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 199\n",
      "No change in model performance :\n",
      "previous loss 1.12717604637146\n",
      "current loss 0.8428017497062683\n",
      "\n",
      "No action performed\n",
      "Episode 199 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 200\n",
      "No change in model performance :\n",
      "previous loss 0.8428017497062683\n",
      "current loss 0.5977957248687744\n",
      "\n",
      "No action performed\n",
      "Episode 200 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 201\n",
      "No change in model performance :\n",
      "previous loss 0.5977957248687744\n",
      "current loss 0.5914492607116699\n",
      "\n",
      "No action performed\n",
      "Episode 201 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 202\n",
      "Current model loss 0.6529699563980103\n",
      "Model loss previously 0.5914492607116699\n",
      "Determining State...\n",
      "Number of states available 15\n",
      "The similarity score of target state 1 : [0.0192466  0.70666107 0.75033407 0.09063332 0.9946558 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.65\n",
      "Model training failed, new performance 1.5929055213928223 is greater than the previous loss 0.65\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.65\n",
      "Model trained from scratch, new performance loss : 0.5580267310142517\n",
      "Model weights for action 29 has been saved at Model_weights/model_action29.weights.h5\n",
      "Model reward for new action 29 : 0.09197326898574831\n",
      "\n",
      "Total number of actions : 30\n",
      "\n",
      "Model's performance loss before weight fit 0.65 \n",
      "Model's performance loss after weight fit 0.56\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.94\n",
      "\n",
      "Action determination done\n",
      "Action taken : 29 \n",
      "Reward : 0.09197326898574831\n",
      "\n",
      "Episode 202 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 203\n",
      "Current model loss 0.8196153044700623\n",
      "Model loss previously 0.5580267310142517\n",
      "Determining State...\n",
      "Number of states available 15\n",
      "No appropriate state found in the existing list, creating new state\n",
      "New state 15 created\n",
      "Target state : 15\n",
      "Number of similar columns 3\n",
      "\n",
      "Determining action ...\n",
      "No significant change in performance accuracy, so no new action\n",
      "\n",
      "Model's performance loss before weight fit 0.82 \n",
      "Model's performance loss after weight fit 0.82\n",
      "Model's performance accuracy before weight fit 0.84 \n",
      "Model's performance loss after weight fit 0.84\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0\n",
      "\n",
      "Episode 203 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 204\n",
      "Current model loss 2.252196788787842\n",
      "Model loss previously 0.8196153044700623\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 2 : [0.82567434 0.8347923  0.89752866 0.94356053 0.21462916]\n",
      "Determining action ...\n",
      "Model's current performance 0.75 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 2.25 \n",
      "Model's performance loss after weight fit 0.69\n",
      "Model's performance accuracy before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.62\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 1.56\n",
      "\n",
      "Episode 204 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 205\n",
      "Current model loss 0.819770872592926\n",
      "Model loss previously 0.6862938404083252\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 5 : [0.72264376 0.57362278 0.98532008 0.65436445 0.00829041]\n",
      "Determining action ...\n",
      "Model's current performance 0.56 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 5 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 5\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.82\n",
      "\n",
      "Target accuracy (0.80) and loss (0.33) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.31905752420425415\n",
      "Model weights for action 30 has been saved at Model_weights/model_action30.weights.h5\n",
      "Model reward for new action 30 : 0.5009424757957458\n",
      "\n",
      "Total number of actions : 31\n",
      "\n",
      "Model's performance loss before weight fit 0.82 \n",
      "Model's performance loss after weight fit 0.32\n",
      "Model's performance accuracy before weight fit 0.56 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 30 \n",
      "Reward : 0.5009424757957458\n",
      "\n",
      "Episode 205 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 206\n",
      "Current model loss 1.9756845235824585\n",
      "Model loss previously 0.31905752420425415\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 4 : [0.90651288 0.8868048  0.76722864 0.65684662 0.84164401]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.98\n",
      "\n",
      "Target accuracy (0.80) and loss (0.79) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.7730134725570679\n",
      "Model weights for action 31 has been saved at Model_weights/model_action31.weights.h5\n",
      "Model reward for new action 31 : 1.2069865274429321\n",
      "\n",
      "Total number of actions : 32\n",
      "\n",
      "Model's performance loss before weight fit 1.98 \n",
      "Model's performance loss after weight fit 0.77\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.84\n",
      "\n",
      "Action determination done\n",
      "Action taken : 31 \n",
      "Reward : 1.2069865274429321\n",
      "\n",
      "Episode 206 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 207\n",
      "Current model loss 2.0123608112335205\n",
      "Model loss previously 0.7730134725570679\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 1 : [0.12453563 0.98985246 0.68329749 0.9232455  0.63672542]\n",
      "Determining action ...\n",
      "Model's current performance 0.75 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 2.01\n",
      "\n",
      "Target accuracy (0.80) and loss (0.80) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.7954815626144409\n",
      "Model weights for action 32 has been saved at Model_weights/model_action32.weights.h5\n",
      "Model reward for new action 32 : 1.2145184373855589\n",
      "\n",
      "Total number of actions : 33\n",
      "\n",
      "Model's performance loss before weight fit 2.01 \n",
      "Model's performance loss after weight fit 0.8\n",
      "Model's performance accuracy before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.84\n",
      "\n",
      "Action determination done\n",
      "Action taken : 32 \n",
      "Reward : 1.2145184373855589\n",
      "\n",
      "Episode 207 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 208\n",
      "Current model loss 1.417046070098877\n",
      "Model loss previously 0.7954815626144409\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 4 : [0.89367628 0.33800619 0.87438342 0.38856846 0.60554721]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 32 were loaded\n",
      "Model's performance loss before weight fit 1.42 \n",
      "Model's performance loss after weight fit 1.42\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 32 \n",
      "Reward : 0.0\n",
      "\n",
      "Episode 208 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 209\n",
      "No change in model performance :\n",
      "previous loss 1.417046070098877\n",
      "current loss 0.8978809118270874\n",
      "\n",
      "No action performed\n",
      "Episode 209 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 210\n",
      "No change in model performance :\n",
      "previous loss 0.8978809118270874\n",
      "current loss 0.1851775199174881\n",
      "\n",
      "No action performed\n",
      "Episode 210 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 211\n",
      "Current model loss 0.9930697679519653\n",
      "Model loss previously 0.1851775199174881\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 4 : [0.78729484 0.95888624 0.88754584 0.78059093 0.47501581]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.99\n",
      "\n",
      "Target accuracy (0.80) and loss (0.40) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.3286820650100708\n",
      "Model weights for action 33 has been saved at Model_weights/model_action33.weights.h5\n",
      "Model reward for new action 33 : 0.6613179349899292\n",
      "\n",
      "Total number of actions : 34\n",
      "\n",
      "Model's performance loss before weight fit 0.99 \n",
      "Model's performance loss after weight fit 0.33\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 33 \n",
      "Reward : 0.6613179349899292\n",
      "\n",
      "Episode 211 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 212\n",
      "Current model loss 0.6448075175285339\n",
      "Model loss previously 0.3286820650100708\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 1 : [0.59779925 0.77995466 0.93819871 0.32998347 0.86657505]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.64\n",
      "\n",
      "Target accuracy (0.80) and loss (0.26) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.24619245529174805\n",
      "Model weights for action 34 has been saved at Model_weights/model_action34.weights.h5\n",
      "Model reward for new action 34 : 0.39380754470825197\n",
      "\n",
      "Total number of actions : 35\n",
      "\n",
      "Model's performance loss before weight fit 0.64 \n",
      "Model's performance loss after weight fit 0.25\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.91\n",
      "\n",
      "Action determination done\n",
      "Action taken : 34 \n",
      "Reward : 0.39380754470825197\n",
      "\n",
      "Episode 212 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 213\n",
      "Current model loss 1.9511315822601318\n",
      "Model loss previously 0.24619245529174805\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 0 : [0.88012569 0.62027708 0.07629913 0.83449607 0.35674275]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 1.95 \n",
      "Model's performance loss after weight fit 0.71\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 1.24\n",
      "\n",
      "Episode 213 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 214\n",
      "Current model loss 1.1980700492858887\n",
      "Model loss previously 0.7099869251251221\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 1 : [0.9021501  0.36759093 0.86480302 0.36535523 0.81248365]\n",
      "Determining action ...\n",
      "Model's current performance 0.56 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 26 were loaded\n",
      "Model's performance loss before weight fit 1.2 \n",
      "Model's performance loss after weight fit 3.81\n",
      "Model's performance accuracy before weight fit 0.56 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 26 \n",
      "Reward : -2.6100000000000003\n",
      "\n",
      "Episode 214 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 215\n",
      "No change in model performance :\n",
      "previous loss 3.8055405616760254\n",
      "current loss 3.7017388343811035\n",
      "\n",
      "No action performed\n",
      "Episode 215 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 216\n",
      "No change in model performance :\n",
      "previous loss 3.7017388343811035\n",
      "current loss 1.7556259632110596\n",
      "\n",
      "No action performed\n",
      "Episode 216 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 217\n",
      "Current model loss 4.820000171661377\n",
      "Model loss previously 1.7556259632110596\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 11 : [0.87723313 0.88574293 0.94884202 0.39342788 0.61523738]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 13 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 13\n",
      "\n",
      "Model's performance loss before weight fit 4.82 \n",
      "Model's performance loss after weight fit 2.47\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 13 \n",
      "Reward : 2.35\n",
      "\n",
      "Episode 217 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 218\n",
      "No change in model performance :\n",
      "previous loss 2.4747915267944336\n",
      "current loss 1.8766816854476929\n",
      "\n",
      "No action performed\n",
      "Episode 218 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 219\n",
      "Current model loss 2.663848400115967\n",
      "Model loss previously 1.8766816854476929\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 0 : [0.87141823 0.67383783 0.12131297 0.68993078 0.04815658]\n",
      "Determining action ...\n",
      "Model's current performance 0.53 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "Model's performance loss before weight fit 2.66 \n",
      "Model's performance loss after weight fit 0.86\n",
      "Model's performance accuracy before weight fit 0.53 \n",
      "Model's performance loss after weight fit 0.47\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 1.8000000000000003\n",
      "\n",
      "Episode 219 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 220\n",
      "No change in model performance :\n",
      "previous loss 0.855836033821106\n",
      "current loss 0.530586838722229\n",
      "\n",
      "No action performed\n",
      "Episode 220 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 221\n",
      "Current model loss 0.7593872547149658\n",
      "Model loss previously 0.530586838722229\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 12 : [0.89750485 0.85290567 0.97948706 0.70257118 0.55200858]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 2 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 2\n",
      "\n",
      "Model's performance loss before weight fit 0.76 \n",
      "Model's performance loss after weight fit 0.72\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 2 \n",
      "Reward : 0.040000000000000036\n",
      "\n",
      "Episode 221 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 222\n",
      "No change in model performance :\n",
      "previous loss 0.7173200845718384\n",
      "current loss 0.4594820737838745\n",
      "\n",
      "No action performed\n",
      "Episode 222 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 223\n",
      "Current model loss 0.5414352416992188\n",
      "Model loss previously 0.4594820737838745\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 0 : [0.94036004 0.90122166 0.76712016 0.61524392 0.02624199]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 31 were loaded\n",
      "Model's performance loss before weight fit 0.54 \n",
      "Model's performance loss after weight fit 1.01\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 31 \n",
      "Reward : -0.47\n",
      "\n",
      "Episode 223 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 224\n",
      "Current model loss 1.4943513870239258\n",
      "Model loss previously 1.0142991542816162\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 1 : [0.38895783 0.91444693 0.79044389 0.99631388 0.61934155]\n",
      "Determining action ...\n",
      "Model's current performance 0.56 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.49\n",
      "\n",
      "Target accuracy (0.80) and loss (0.60) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.2842933237552643\n",
      "Model weights for action 35 has been saved at Model_weights/model_action35.weights.h5\n",
      "Model reward for new action 35 : 1.2057066762447357\n",
      "\n",
      "Total number of actions : 36\n",
      "\n",
      "Model's performance loss before weight fit 1.49 \n",
      "Model's performance loss after weight fit 0.28\n",
      "Model's performance accuracy before weight fit 0.56 \n",
      "Model's performance loss after weight fit 0.84\n",
      "\n",
      "Action determination done\n",
      "Action taken : 35 \n",
      "Reward : 1.2057066762447357\n",
      "\n",
      "Episode 224 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 225\n",
      "Current model loss 1.4965858459472656\n",
      "Model loss previously 0.2842933237552643\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 7 : [0.69695976 0.70377225 0.05097589 0.81996427 0.87688193]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "Model's performance loss before weight fit 1.5 \n",
      "Model's performance loss after weight fit 0.37\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 10 \n",
      "Reward : 1.13\n",
      "\n",
      "Episode 225 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 226\n",
      "Current model loss 0.7647560834884644\n",
      "Model loss previously 0.3667818307876587\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 1 : [0.9994578  0.74209266 0.608483   0.14257857 0.35559424]\n",
      "Determining action ...\n",
      "No significant change in performance accuracy, so no new action\n",
      "\n",
      "Model's performance loss before weight fit 0.76 \n",
      "Model's performance loss after weight fit 0.76\n",
      "Model's performance accuracy before weight fit 0.81 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0\n",
      "\n",
      "Episode 226 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 227\n",
      "Current model loss 0.8435036540031433\n",
      "Model loss previously 0.7647560834884644\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 6 : [0.79910813 0.07634265 0.82283249 0.83926776 0.89849525]\n",
      "Determining action ...\n",
      "Model's current performance 0.78 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.84\n",
      "Model training failed, new performance 1.0018901824951172 is greater than the previous loss 0.84\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.84\n",
      "Model training failed, new performance 1.0018901824951172 is greater than the previous loss 0.84\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.84\n",
      "Model trained from scratch, new performance loss : 0.5036906003952026\n",
      "Model weights for action 36 has been saved at Model_weights/model_action36.weights.h5\n",
      "Model reward for new action 36 : 0.33630939960479733\n",
      "\n",
      "Total number of actions : 37\n",
      "\n",
      "Model's performance loss before weight fit 0.84 \n",
      "Model's performance loss after weight fit 0.5\n",
      "Model's performance accuracy before weight fit 0.78 \n",
      "Model's performance loss after weight fit 0.97\n",
      "\n",
      "Action determination done\n",
      "Action taken : 36 \n",
      "Reward : 0.33630939960479733\n",
      "\n",
      "Episode 227 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 228\n",
      "Current model loss 2.79184627532959\n",
      "Model loss previously 0.5036906003952026\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 2 : [0.85253319 0.73876938 0.17340926 0.72582074 0.28465527]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 2.79 \n",
      "Model's performance loss after weight fit 0.68\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 2.11\n",
      "\n",
      "Episode 228 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 229\n",
      "No change in model performance :\n",
      "previous loss 0.677108645439148\n",
      "current loss 0.6201015710830688\n",
      "\n",
      "No action performed\n",
      "Episode 229 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 230\n",
      "Current model loss 1.3828068971633911\n",
      "Model loss previously 0.6201015710830688\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 3 : [0.79582721 0.92649603 0.96719048 0.94846688 0.32000522]\n",
      "Determining action ...\n",
      "Model's current performance 0.41 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.38\n",
      "Model training failed, new performance 1.5208674669265747 is greater than the previous loss 1.38\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.38\n",
      "\n",
      "Target accuracy (0.80) and loss (0.55) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.2402856945991516\n",
      "Model weights for action 37 has been saved at Model_weights/model_action37.weights.h5\n",
      "Model reward for new action 37 : 1.1397143054008483\n",
      "\n",
      "Total number of actions : 38\n",
      "\n",
      "Model's performance loss before weight fit 1.38 \n",
      "Model's performance loss after weight fit 0.24\n",
      "Model's performance accuracy before weight fit 0.41 \n",
      "Model's performance loss after weight fit 0.88\n",
      "\n",
      "Action determination done\n",
      "Action taken : 37 \n",
      "Reward : 1.1397143054008483\n",
      "\n",
      "Episode 230 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 231\n",
      "Current model loss 2.0204038619995117\n",
      "Model loss previously 0.2402856945991516\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 1 : [0.64449523 0.94339816 0.76021692 0.05224547 0.95739332]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 2.02\n",
      "\n",
      "Target accuracy (0.80) and loss (0.81) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.7753587961196899\n",
      "Model weights for action 38 has been saved at Model_weights/model_action38.weights.h5\n",
      "Model reward for new action 38 : 1.24464120388031\n",
      "\n",
      "Total number of actions : 39\n",
      "\n",
      "Model's performance loss before weight fit 2.02 \n",
      "Model's performance loss after weight fit 0.78\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 38 \n",
      "Reward : 1.24464120388031\n",
      "\n",
      "Episode 231 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 232\n",
      "Current model loss 1.5177146196365356\n",
      "Model loss previously 0.7753587961196899\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 2 : [0.52643411 0.78930684 0.98146843 0.94197672 0.91014231]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 1.52 \n",
      "Model's performance loss after weight fit 0.69\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.53\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0.8300000000000001\n",
      "\n",
      "Episode 232 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 233\n",
      "Current model loss 0.8944236040115356\n",
      "Model loss previously 0.6937739849090576\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 12 : [0.83168168 0.75867582 0.84327234 0.60149291 0.02380027]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 2 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 2\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.89\n",
      "\n",
      "Target accuracy (0.80) and loss (0.36) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.3505736291408539\n",
      "Model weights for action 39 has been saved at Model_weights/model_action39.weights.h5\n",
      "Model reward for new action 39 : 0.5394263708591461\n",
      "\n",
      "Total number of actions : 40\n",
      "\n",
      "Model's performance loss before weight fit 0.89 \n",
      "Model's performance loss after weight fit 0.35\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.84\n",
      "\n",
      "Action determination done\n",
      "Action taken : 39 \n",
      "Reward : 0.5394263708591461\n",
      "\n",
      "Episode 233 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 234\n",
      "Current model loss 1.545796513557434\n",
      "Model loss previously 0.3505736291408539\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 3 : [0.54933605 0.90142424 0.95930286 0.85043685 0.17055349]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "Model's performance loss before weight fit 1.55 \n",
      "Model's performance loss after weight fit 0.69\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 12 \n",
      "Reward : 0.8600000000000001\n",
      "\n",
      "Episode 234 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 235\n",
      "Current model loss 0.9958055019378662\n",
      "Model loss previously 0.6948052048683167\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 13 : [0.66099729 0.49134696 0.61498585 0.76957859 0.71201153]\n",
      "Determining action ...\n",
      "Model's current performance 0.78 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 5 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 5\n",
      "\n",
      "Model's performance loss before weight fit 1.0 \n",
      "Model's performance loss after weight fit 0.42\n",
      "Model's performance accuracy before weight fit 0.78 \n",
      "Model's performance loss after weight fit 0.78\n",
      "\n",
      "Action determination done\n",
      "Action taken : 5 \n",
      "Reward : 0.5800000000000001\n",
      "\n",
      "Episode 235 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 236\n",
      "Current model loss 1.0464354753494263\n",
      "Model loss previously 0.42324644327163696\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 2 : [0.89066452 0.8452987  0.89198094 0.72508857 0.03057796]\n",
      "Determining action ...\n",
      "Model's current performance 0.78 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 1.05 \n",
      "Model's performance loss after weight fit 0.56\n",
      "Model's performance accuracy before weight fit 0.78 \n",
      "Model's performance loss after weight fit 0.75\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0.49\n",
      "\n",
      "Episode 236 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 237\n",
      "No change in model performance :\n",
      "previous loss 0.5575360059738159\n",
      "current loss 0.5534753799438477\n",
      "\n",
      "No action performed\n",
      "Episode 237 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 238\n",
      "No change in model performance :\n",
      "previous loss 0.5534753799438477\n",
      "current loss 0.49025604128837585\n",
      "\n",
      "No action performed\n",
      "Episode 238 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 239\n",
      "Current model loss 0.7874577045440674\n",
      "Model loss previously 0.49025604128837585\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 12 : [0.57820649 0.66156337 0.76684569 0.67958848 0.92941288]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 2 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 2\n",
      "\n",
      "Model's performance loss before weight fit 0.79 \n",
      "Model's performance loss after weight fit 0.65\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 2 \n",
      "Reward : 0.14\n",
      "\n",
      "Episode 239 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 240\n",
      "Current model loss 1.7288621664047241\n",
      "Model loss previously 0.6464792490005493\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 6 : [0.9001656  0.62187726 0.01505103 0.80855007 0.97795107]\n",
      "Determining action ...\n",
      "Model's current performance 0.53 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 20 were loaded\n",
      "Model's performance loss before weight fit 1.73 \n",
      "Model's performance loss after weight fit 1.87\n",
      "Model's performance accuracy before weight fit 0.53 \n",
      "Model's performance loss after weight fit 0.72\n",
      "\n",
      "Action determination done\n",
      "Action taken : 20 \n",
      "Reward : -0.14000000000000012\n",
      "\n",
      "Episode 240 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 241\n",
      "Current model loss 2.322235107421875\n",
      "Model loss previously 1.8661134243011475\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 2 : [0.82277368 0.00154736 0.77979571 0.72762415 0.6819776 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 2.32 \n",
      "Model's performance loss after weight fit 1.24\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.5\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 1.0799999999999998\n",
      "\n",
      "Episode 241 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 242\n",
      "No change in model performance :\n",
      "previous loss 1.2431151866912842\n",
      "current loss 0.5772026777267456\n",
      "\n",
      "No action performed\n",
      "Episode 242 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 243\n",
      "Current model loss 1.1428968906402588\n",
      "Model loss previously 0.5772026777267456\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 0 : [0.60687473 0.34780687 0.82647502 0.66541356 0.00520994]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 27 were loaded\n",
      "Model's performance loss before weight fit 1.14 \n",
      "Model's performance loss after weight fit 0.6\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 27 \n",
      "Reward : 0.5399999999999999\n",
      "\n",
      "Episode 243 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 244\n",
      "Current model loss 1.496469497680664\n",
      "Model loss previously 0.5952153205871582\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 2 : [0.74639684 0.33629146 0.69723721 0.64859522 0.70843179]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 1.5 \n",
      "Model's performance loss after weight fit 0.58\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0.92\n",
      "\n",
      "Episode 244 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 245\n",
      "Current model loss 0.9487993717193604\n",
      "Model loss previously 0.5754565596580505\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 2 : [0.4793414  0.73687451 0.90233423 0.42343513 0.68861019]\n",
      "Determining action ...\n",
      "No significant change in performance accuracy, so no new action\n",
      "\n",
      "Model's performance loss before weight fit 0.95 \n",
      "Model's performance loss after weight fit 0.95\n",
      "Model's performance accuracy before weight fit 0.81 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0\n",
      "\n",
      "Episode 245 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 246\n",
      "Current model loss 1.1704115867614746\n",
      "Model loss previously 0.9487993717193604\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 13 : [0.76813674 0.80646942 0.69439802 0.37737457 0.97583264]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 5 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 5\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.17\n",
      "\n",
      "Target accuracy (0.80) and loss (0.47) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.3374200761318207\n",
      "Model weights for action 40 has been saved at Model_weights/model_action40.weights.h5\n",
      "Model reward for new action 40 : 0.8325799238681793\n",
      "\n",
      "Total number of actions : 41\n",
      "\n",
      "Model's performance loss before weight fit 1.17 \n",
      "Model's performance loss after weight fit 0.34\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 40 \n",
      "Reward : 0.8325799238681793\n",
      "\n",
      "Episode 246 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 247\n",
      "Current model loss 1.691826343536377\n",
      "Model loss previously 0.3374200761318207\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 1 : [0.0485772  0.66999194 0.609921   0.24232309 0.68319516]\n",
      "Determining action ...\n",
      "Model's current performance 0.56 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.69\n",
      "\n",
      "Target accuracy (0.80) and loss (0.68) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.670951783657074\n",
      "Model weights for action 41 has been saved at Model_weights/model_action41.weights.h5\n",
      "Model reward for new action 41 : 1.019048216342926\n",
      "\n",
      "Total number of actions : 42\n",
      "\n",
      "Model's performance loss before weight fit 1.69 \n",
      "Model's performance loss after weight fit 0.67\n",
      "Model's performance accuracy before weight fit 0.56 \n",
      "Model's performance loss after weight fit 0.94\n",
      "\n",
      "Action determination done\n",
      "Action taken : 41 \n",
      "Reward : 1.019048216342926\n",
      "\n",
      "Episode 247 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 248\n",
      "Current model loss 1.630944013595581\n",
      "Model loss previously 0.670951783657074\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 4 : [0.09761877 0.60349981 0.89370793 0.81731523 0.86835289]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 24 were loaded\n",
      "Model's performance loss before weight fit 1.63 \n",
      "Model's performance loss after weight fit 3.73\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.62\n",
      "\n",
      "Action determination done\n",
      "Action taken : 24 \n",
      "Reward : -2.1\n",
      "\n",
      "Episode 248 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 249\n",
      "No change in model performance :\n",
      "previous loss 3.7301785945892334\n",
      "current loss 2.356684923171997\n",
      "\n",
      "No action performed\n",
      "Episode 249 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 250\n",
      "No change in model performance :\n",
      "previous loss 2.356684923171997\n",
      "current loss 1.3147366046905518\n",
      "\n",
      "No action performed\n",
      "Episode 250 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 251\n",
      "Current model loss 1.6446250677108765\n",
      "Model loss previously 1.3147366046905518\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 3 : [0.73930713 0.93274244 0.52169246 0.75634126 0.08595101]\n",
      "Determining action ...\n",
      "No significant change in performance accuracy, so no new action\n",
      "\n",
      "Model's performance loss before weight fit 1.64 \n",
      "Model's performance loss after weight fit 1.64\n",
      "Model's performance accuracy before weight fit 0.88 \n",
      "Model's performance loss after weight fit 0.88\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0\n",
      "\n",
      "Episode 251 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 252\n",
      "Current model loss 3.2920875549316406\n",
      "Model loss previously 1.6446250677108765\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 2 : [0.74225269 0.08313772 0.72482712 0.81431912 0.95220543]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 15 were loaded\n",
      "Model's performance loss before weight fit 3.29 \n",
      "Model's performance loss after weight fit 0.84\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 15 \n",
      "Reward : 2.45\n",
      "\n",
      "Episode 252 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 253\n",
      "No change in model performance :\n",
      "previous loss 0.8402224779129028\n",
      "current loss 0.6098552942276001\n",
      "\n",
      "No action performed\n",
      "Episode 253 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 254\n",
      "No change in model performance :\n",
      "previous loss 0.6098552942276001\n",
      "current loss 0.49503234028816223\n",
      "\n",
      "No action performed\n",
      "Episode 254 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 255\n",
      "Current model loss 1.4933897256851196\n",
      "Model loss previously 0.49503234028816223\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 4 : [0.81670991 0.02242543 0.53116962 0.69992133 0.67876685]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "Model's performance loss before weight fit 1.49 \n",
      "Model's performance loss after weight fit 1.35\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.72\n",
      "\n",
      "Action determination done\n",
      "Action taken : 10 \n",
      "Reward : 0.1399999999999999\n",
      "\n",
      "Episode 255 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 256\n",
      "No change in model performance :\n",
      "previous loss 1.347132682800293\n",
      "current loss 0.8358744382858276\n",
      "\n",
      "No action performed\n",
      "Episode 256 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 257\n",
      "Current model loss 1.519378423690796\n",
      "Model loss previously 0.8358744382858276\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "The similarity score of target state 0 : [0.86634577 0.73744393 0.56914262 0.8469618  0.00217468]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 1.52 \n",
      "Model's performance loss after weight fit 0.46\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.78\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 1.06\n",
      "\n",
      "Episode 257 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 258\n",
      "Current model loss 0.48995241522789\n",
      "Model loss previously 0.4575624167919159\n",
      "Determining State...\n",
      "Number of states available 16\n",
      "No appropriate state found in the existing list, creating new state\n",
      "New state 16 created\n",
      "Target state : 16\n",
      "Number of similar columns 4\n",
      "\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.49\n",
      "Model training failed, new performance 1.0164076089859009 is greater than the previous loss 0.49\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.49\n",
      "Model training failed, new performance 0.5295671820640564 is greater than the previous loss 0.49\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.49\n",
      "Model training failed, new performance 0.5205757021903992 is greater than the previous loss 0.49\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.49\n",
      "Model training failed, new performance 0.5449462532997131 is greater than the previous loss 0.49\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.49\n",
      "Model training failed, new performance 0.5184573531150818 is greater than the previous loss 0.49\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.49\n",
      "Model training failed, new performance 0.4981996417045593 is greater than the previous loss 0.49\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.49\n",
      "Model training failed, new performance 0.5526751279830933 is greater than the previous loss 0.49\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.49\n",
      "Model training failed, new performance 0.5260459184646606 is greater than the previous loss 0.49\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.49\n",
      "\n",
      "Target accuracy (0.80) and loss (0.20) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.1854269802570343\n",
      "Model weights for action 42 has been saved at Model_weights/model_action42.weights.h5\n",
      "Model reward for new action 42 : 0.3045730197429657\n",
      "\n",
      "Total number of actions : 43\n",
      "\n",
      "Model's performance loss before weight fit 0.49 \n",
      "Model's performance loss after weight fit 0.19\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.91\n",
      "\n",
      "Action determination done\n",
      "Action taken : 42 \n",
      "Reward : 0.3045730197429657\n",
      "\n",
      "Episode 258 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 259\n",
      "Current model loss 2.4487175941467285\n",
      "Model loss previously 0.1854269802570343\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 4 : [0.28693927 0.81088037 0.83100523 0.48630104 0.72856544]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 19 were loaded\n",
      "Model's performance loss before weight fit 2.45 \n",
      "Model's performance loss after weight fit 3.33\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.62\n",
      "\n",
      "Action determination done\n",
      "Action taken : 19 \n",
      "Reward : -0.8799999999999999\n",
      "\n",
      "Episode 259 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 260\n",
      "No change in model performance :\n",
      "previous loss 3.32612681388855\n",
      "current loss 2.3982272148132324\n",
      "\n",
      "No action performed\n",
      "Episode 260 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 261\n",
      "No change in model performance :\n",
      "previous loss 2.3982272148132324\n",
      "current loss 1.4342533349990845\n",
      "\n",
      "No action performed\n",
      "Episode 261 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 262\n",
      "Current model loss 1.8972680568695068\n",
      "Model loss previously 1.4342533349990845\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 12 : [0.72137928 0.77711586 0.29166715 0.77541123 0.01158768]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 2 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 2\n",
      "\n",
      "Model's performance loss before weight fit 1.9 \n",
      "Model's performance loss after weight fit 0.75\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.5\n",
      "\n",
      "Action determination done\n",
      "Action taken : 2 \n",
      "Reward : 1.15\n",
      "\n",
      "Episode 262 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 263\n",
      "Current model loss 2.0549914836883545\n",
      "Model loss previously 0.7513480186462402\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 16 : [0.58547175 0.0104397  0.99650341 0.93927687 0.99054922]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 42 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 42\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 2.05\n",
      "\n",
      "Target accuracy (0.80) and loss (0.82) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.7056983113288879\n",
      "Model weights for action 43 has been saved at Model_weights/model_action43.weights.h5\n",
      "Model reward for new action 43 : 1.3443016886711119\n",
      "\n",
      "Total number of actions : 44\n",
      "\n",
      "Model's performance loss before weight fit 2.05 \n",
      "Model's performance loss after weight fit 0.71\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 43 \n",
      "Reward : 1.3443016886711119\n",
      "\n",
      "Episode 263 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 264\n",
      "Current model loss 0.9372022151947021\n",
      "Model loss previously 0.7056983113288879\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 6 : [0.31686595 0.63634794 0.89455264 0.86509902 0.68771879]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.94\n",
      "\n",
      "Target accuracy (0.80) and loss (0.38) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.3657958507537842\n",
      "Model weights for action 44 has been saved at Model_weights/model_action44.weights.h5\n",
      "Model reward for new action 44 : 0.5742041492462158\n",
      "\n",
      "Total number of actions : 45\n",
      "\n",
      "Model's performance loss before weight fit 0.94 \n",
      "Model's performance loss after weight fit 0.37\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 44 \n",
      "Reward : 0.5742041492462158\n",
      "\n",
      "Episode 264 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 265\n",
      "Current model loss 1.9171044826507568\n",
      "Model loss previously 0.3657958507537842\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 1 : [0.22364755 0.78553373 0.69569884 0.72581485 0.57589248]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "Model's performance loss before weight fit 1.92 \n",
      "Model's performance loss after weight fit 0.62\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 12 \n",
      "Reward : 1.2999999999999998\n",
      "\n",
      "Episode 265 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 266\n",
      "Current model loss 1.947393536567688\n",
      "Model loss previously 0.6193209290504456\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 1 : [0.65329999 0.60250977 0.87847502 0.28082973 0.10635759]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.95\n",
      "Model trained from scratch, new performance loss : 1.5373668670654297\n",
      "Model weights for action 45 has been saved at Model_weights/model_action45.weights.h5\n",
      "Model reward for new action 45 : 0.41263313293457027\n",
      "\n",
      "Total number of actions : 46\n",
      "\n",
      "Model's performance loss before weight fit 1.95 \n",
      "Model's performance loss after weight fit 1.54\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.88\n",
      "\n",
      "Action determination done\n",
      "Action taken : 45 \n",
      "Reward : 0.41263313293457027\n",
      "\n",
      "Episode 266 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 267\n",
      "Current model loss 2.6947829723358154\n",
      "Model loss previously 1.5373668670654297\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 12 : [0.7677645  0.85659452 0.8627406  0.12791605 0.65956928]\n",
      "Determining action ...\n",
      "Model's current performance 0.75 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 2 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 2\n",
      "\n",
      "Model's performance loss before weight fit 2.69 \n",
      "Model's performance loss after weight fit 1.11\n",
      "Model's performance accuracy before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.72\n",
      "\n",
      "Action determination done\n",
      "Action taken : 2 \n",
      "Reward : 1.5799999999999998\n",
      "\n",
      "Episode 267 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 268\n",
      "No change in model performance :\n",
      "previous loss 1.1086164712905884\n",
      "current loss 1.0160853862762451\n",
      "\n",
      "No action performed\n",
      "Episode 268 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 269\n",
      "No change in model performance :\n",
      "previous loss 1.0160853862762451\n",
      "current loss 0.6915825009346008\n",
      "\n",
      "No action performed\n",
      "Episode 269 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 270\n",
      "Current model loss 0.9921993017196655\n",
      "Model loss previously 0.6915825009346008\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 9 : [0.69674478 0.24087327 0.973204   0.68100856 0.78644779]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.99\n",
      "Model trained from scratch, new performance loss : 0.5351347923278809\n",
      "Model weights for action 46 has been saved at Model_weights/model_action46.weights.h5\n",
      "Model reward for new action 46 : 0.45486520767211913\n",
      "\n",
      "Total number of actions : 47\n",
      "\n",
      "Model's performance loss before weight fit 0.99 \n",
      "Model's performance loss after weight fit 0.54\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.94\n",
      "\n",
      "Action determination done\n",
      "Action taken : 46 \n",
      "Reward : 0.45486520767211913\n",
      "\n",
      "Episode 270 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 271\n",
      "Current model loss 2.4091339111328125\n",
      "Model loss previously 0.5351347923278809\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 13 : [0.91518063 0.99305784 0.72927706 0.67400582 0.67076158]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 5 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 5\n",
      "\n",
      "Model's performance loss before weight fit 2.41 \n",
      "Model's performance loss after weight fit 0.59\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.72\n",
      "\n",
      "Action determination done\n",
      "Action taken : 5 \n",
      "Reward : 1.8200000000000003\n",
      "\n",
      "Episode 271 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 272\n",
      "Current model loss 0.6967254877090454\n",
      "Model loss previously 0.5944958925247192\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 13 : [0.77591318 0.96438376 0.69356778 0.46137697 0.80933408]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 9 were loaded\n",
      "Model's performance loss before weight fit 0.7 \n",
      "Model's performance loss after weight fit 0.98\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 9 \n",
      "Reward : -0.28\n",
      "\n",
      "Episode 272 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 273\n",
      "Current model loss 1.9802372455596924\n",
      "Model loss previously 0.9829980731010437\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 9 : [0.81015692 0.74197968 0.01041833 0.95191055 0.2700011 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 5 were loaded\n",
      "Model's performance loss before weight fit 1.98 \n",
      "Model's performance loss after weight fit 1.2\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 5 \n",
      "Reward : 0.78\n",
      "\n",
      "Episode 273 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 274\n",
      "Current model loss 1.699976921081543\n",
      "Model loss previously 1.20151948928833\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 2 : [0.67947106 0.9525912  0.40844429 0.70033571 0.73661839]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 1.7 \n",
      "Model's performance loss after weight fit 0.87\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.41\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0.83\n",
      "\n",
      "Episode 274 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 275\n",
      "Current model loss 1.1790258884429932\n",
      "Model loss previously 0.8663120269775391\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 2 : [0.749287   0.58919235 0.71619574 0.74544133 0.05340189]\n",
      "Determining action ...\n",
      "Model's current performance 0.56 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.18\n",
      "Model training failed, new performance 3.5203423500061035 is greater than the previous loss 1.18\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.18\n",
      "Model trained from scratch, new performance loss : 0.4981996417045593\n",
      "Model weights for action 47 has been saved at Model_weights/model_action47.weights.h5\n",
      "Model reward for new action 47 : 0.6818003582954406\n",
      "\n",
      "Total number of actions : 48\n",
      "\n",
      "Model's performance loss before weight fit 1.18 \n",
      "Model's performance loss after weight fit 0.5\n",
      "Model's performance accuracy before weight fit 0.56 \n",
      "Model's performance loss after weight fit 0.97\n",
      "\n",
      "Action determination done\n",
      "Action taken : 47 \n",
      "Reward : 0.6818003582954406\n",
      "\n",
      "Episode 275 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 276\n",
      "Current model loss 3.303370237350464\n",
      "Model loss previously 0.4981996417045593\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 12 : [0.26692334 0.9506003  0.8216332  0.82586475 0.89932623]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 2 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 2\n",
      "\n",
      "Model's performance loss before weight fit 3.3 \n",
      "Model's performance loss after weight fit 0.57\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.75\n",
      "\n",
      "Action determination done\n",
      "Action taken : 2 \n",
      "Reward : 2.73\n",
      "\n",
      "Episode 276 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 277\n",
      "Current model loss 0.7134036421775818\n",
      "Model loss previously 0.5738918781280518\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 5 : [0.69795681 0.95398247 0.01244934 0.97999869 0.43687028]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 5 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 5\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.71\n",
      "Model training failed, new performance 2.5129613876342773 is greater than the previous loss 0.71\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.71\n",
      "Model training failed, new performance 2.024083375930786 is greater than the previous loss 0.71\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.71\n",
      "Model training failed, new performance 1.6517820358276367 is greater than the previous loss 0.71\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.71\n",
      "\n",
      "Target accuracy (0.80) and loss (0.28) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.2744591534137726\n",
      "Model weights for action 48 has been saved at Model_weights/model_action48.weights.h5\n",
      "Model reward for new action 48 : 0.4355408465862274\n",
      "\n",
      "Total number of actions : 49\n",
      "\n",
      "Model's performance loss before weight fit 0.71 \n",
      "Model's performance loss after weight fit 0.27\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.91\n",
      "\n",
      "Action determination done\n",
      "Action taken : 48 \n",
      "Reward : 0.4355408465862274\n",
      "\n",
      "Episode 277 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 278\n",
      "Current model loss 1.6731864213943481\n",
      "Model loss previously 0.2744591534137726\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 2 : [0.02964496 0.95233549 0.89057165 0.67925234 0.8828782 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 42 were loaded\n",
      "Model's performance loss before weight fit 1.67 \n",
      "Model's performance loss after weight fit 1.32\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.78\n",
      "\n",
      "Action determination done\n",
      "Action taken : 42 \n",
      "Reward : 0.34999999999999987\n",
      "\n",
      "Episode 278 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 279\n",
      "Current model loss 2.522244453430176\n",
      "Model loss previously 1.3182059526443481\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 3 : [0.72541398 0.90262861 0.9611893  0.35860795 0.98952828]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 48 were loaded\n",
      "Model's performance loss before weight fit 2.52 \n",
      "Model's performance loss after weight fit 2.28\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.53\n",
      "\n",
      "Action determination done\n",
      "Action taken : 48 \n",
      "Reward : 0.2400000000000002\n",
      "\n",
      "Episode 279 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 280\n",
      "No change in model performance :\n",
      "previous loss 2.276684522628784\n",
      "current loss 1.6160047054290771\n",
      "\n",
      "No action performed\n",
      "Episode 280 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 281\n",
      "No change in model performance :\n",
      "previous loss 1.6160047054290771\n",
      "current loss 1.614567518234253\n",
      "\n",
      "No action performed\n",
      "Episode 281 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 282\n",
      "No change in model performance :\n",
      "previous loss 1.614567518234253\n",
      "current loss 0.40439271926879883\n",
      "\n",
      "No action performed\n",
      "Episode 282 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 283\n",
      "Current model loss 1.1675881147384644\n",
      "Model loss previously 0.40439271926879883\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 10 : [0.67584794 0.91597979 0.67327658 0.42749494 0.48042986]\n",
      "Determining action ...\n",
      "Model's current performance 0.75 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 1.17 \n",
      "Model's performance loss after weight fit 0.64\n",
      "Model's performance accuracy before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0.5299999999999999\n",
      "\n",
      "Episode 283 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 284\n",
      "Current model loss 1.6267116069793701\n",
      "Model loss previously 0.6362055540084839\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 3 : [0.17886946 0.06100213 0.77907762 0.96907059 0.70547199]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.63\n",
      "Model training failed, new performance 2.0147619247436523 is greater than the previous loss 1.63\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.63\n",
      "Model training failed, new performance 2.0147619247436523 is greater than the previous loss 1.63\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.63\n",
      "Model training failed, new performance 2.5019795894622803 is greater than the previous loss 1.63\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.63\n",
      "\n",
      "Target accuracy (0.80) and loss (0.65) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.6445770263671875\n",
      "Model weights for action 49 has been saved at Model_weights/model_action49.weights.h5\n",
      "Model reward for new action 49 : 0.9854229736328124\n",
      "\n",
      "Total number of actions : 50\n",
      "\n",
      "Model's performance loss before weight fit 1.63 \n",
      "Model's performance loss after weight fit 0.64\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.94\n",
      "\n",
      "Action determination done\n",
      "Action taken : 49 \n",
      "Reward : 0.9854229736328124\n",
      "\n",
      "Episode 284 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 285\n",
      "Current model loss 2.0581960678100586\n",
      "Model loss previously 0.6445770263671875\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 1 : [0.77376517 0.46793647 0.58439363 0.7868119  0.95615843]\n",
      "Determining action ...\n",
      "Model's current performance 0.56 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 2.06\n",
      "\n",
      "Target accuracy (0.80) and loss (0.82) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.8156667947769165\n",
      "Model weights for action 50 has been saved at Model_weights/model_action50.weights.h5\n",
      "Model reward for new action 50 : 1.2443332052230835\n",
      "\n",
      "Total number of actions : 51\n",
      "\n",
      "Model's performance loss before weight fit 2.06 \n",
      "Model's performance loss after weight fit 0.82\n",
      "Model's performance accuracy before weight fit 0.56 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 50 \n",
      "Reward : 1.2443332052230835\n",
      "\n",
      "Episode 285 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 286\n",
      "Current model loss 1.5491409301757812\n",
      "Model loss previously 0.8156667947769165\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 0 : [0.23947205 0.6482131  0.81575777 0.95865322 0.22846629]\n",
      "Determining action ...\n",
      "Model's current performance 0.75 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 23 were loaded\n",
      "Model's performance loss before weight fit 1.55 \n",
      "Model's performance loss after weight fit 2.5\n",
      "Model's performance accuracy before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 23 \n",
      "Reward : -0.95\n",
      "\n",
      "Episode 286 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 287\n",
      "No change in model performance :\n",
      "previous loss 2.5012147426605225\n",
      "current loss 1.0434476137161255\n",
      "\n",
      "No action performed\n",
      "Episode 287 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 288\n",
      "No change in model performance :\n",
      "previous loss 1.0434476137161255\n",
      "current loss 0.9835701584815979\n",
      "\n",
      "No action performed\n",
      "Episode 288 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 289\n",
      "Current model loss 1.5436861515045166\n",
      "Model loss previously 0.9835701584815979\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 0 : [0.00370062 0.83721835 0.66151856 0.97220505 0.14538145]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 1.54 \n",
      "Model's performance loss after weight fit 0.58\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0.9600000000000001\n",
      "\n",
      "Episode 289 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 290\n",
      "Current model loss 0.6083927154541016\n",
      "Model loss previously 0.5817549228668213\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 1 : [0.10180402 0.82228065 0.85515589 0.22637266 0.72709672]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.61\n",
      "Model training failed, new performance 2.533747673034668 is greater than the previous loss 0.61\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.61\n",
      "Model training failed, new performance 1.502445101737976 is greater than the previous loss 0.61\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.61\n",
      "Model training failed, new performance 2.994688034057617 is greater than the previous loss 0.61\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.61\n",
      "\n",
      "Target accuracy (0.80) and loss (0.24) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.23891013860702515\n",
      "Model weights for action 51 has been saved at Model_weights/model_action51.weights.h5\n",
      "Model reward for new action 51 : 0.37108986139297484\n",
      "\n",
      "Total number of actions : 52\n",
      "\n",
      "Model's performance loss before weight fit 0.61 \n",
      "Model's performance loss after weight fit 0.24\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.84\n",
      "\n",
      "Action determination done\n",
      "Action taken : 51 \n",
      "Reward : 0.37108986139297484\n",
      "\n",
      "Episode 290 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 291\n",
      "Current model loss 2.5023488998413086\n",
      "Model loss previously 0.23891013860702515\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 1 : [0.34999444 0.16204682 0.97573635 0.67444641 0.78096477]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 25 were loaded\n",
      "Model's performance loss before weight fit 2.5 \n",
      "Model's performance loss after weight fit 3.72\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 25 \n",
      "Reward : -1.2200000000000002\n",
      "\n",
      "Episode 291 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 292\n",
      "No change in model performance :\n",
      "previous loss 3.7185611724853516\n",
      "current loss 2.6190731525421143\n",
      "\n",
      "No action performed\n",
      "Episode 292 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 293\n",
      "Current model loss 2.810624122619629\n",
      "Model loss previously 2.6190731525421143\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 2 : [0.73548027 0.28774087 0.79526772 0.85587165 0.56493095]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 2.81 \n",
      "Model's performance loss after weight fit 1.68\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.47\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 1.1300000000000001\n",
      "\n",
      "Episode 293 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 294\n",
      "No change in model performance :\n",
      "previous loss 1.6753185987472534\n",
      "current loss 0.8050846457481384\n",
      "\n",
      "No action performed\n",
      "Episode 294 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 295\n",
      "No change in model performance :\n",
      "previous loss 0.8050846457481384\n",
      "current loss 0.5638476610183716\n",
      "\n",
      "No action performed\n",
      "Episode 295 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 296\n",
      "Current model loss 0.5832314491271973\n",
      "Model loss previously 0.5638476610183716\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 2 : [0.89850897 0.72099508 0.64537398 0.25118105 0.77256403]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.58\n",
      "\n",
      "Target accuracy (0.80) and loss (0.23) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.2249952256679535\n",
      "Model weights for action 52 has been saved at Model_weights/model_action52.weights.h5\n",
      "Model reward for new action 52 : 0.35500477433204647\n",
      "\n",
      "Total number of actions : 53\n",
      "\n",
      "Model's performance loss before weight fit 0.58 \n",
      "Model's performance loss after weight fit 0.22\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.84\n",
      "\n",
      "Action determination done\n",
      "Action taken : 52 \n",
      "Reward : 0.35500477433204647\n",
      "\n",
      "Episode 296 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 297\n",
      "Current model loss 0.9610369205474854\n",
      "Model loss previously 0.2249952256679535\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 1 : [0.07219235 0.7681189  0.68297055 0.48746343 0.77971657]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.96\n",
      "Model training failed, new performance 1.9982891082763672 is greater than the previous loss 0.96\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.96\n",
      "Model trained from scratch, new performance loss : 0.5036906003952026\n",
      "Model weights for action 53 has been saved at Model_weights/model_action53.weights.h5\n",
      "Model reward for new action 53 : 0.4563093996047973\n",
      "\n",
      "Total number of actions : 54\n",
      "\n",
      "Model's performance loss before weight fit 0.96 \n",
      "Model's performance loss after weight fit 0.5\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.97\n",
      "\n",
      "Action determination done\n",
      "Action taken : 53 \n",
      "Reward : 0.4563093996047973\n",
      "\n",
      "Episode 297 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 298\n",
      "Current model loss 3.3777124881744385\n",
      "Model loss previously 0.5036906003952026\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 1 : [0.14343707 0.78993556 0.70275078 0.54825439 0.8336701 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "Model's performance loss before weight fit 3.38 \n",
      "Model's performance loss after weight fit 0.51\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 12 \n",
      "Reward : 2.87\n",
      "\n",
      "Episode 298 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 299\n",
      "Current model loss 2.251748561859131\n",
      "Model loss previously 0.5080791115760803\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 3 : [0.71678741 0.86526016 0.77265996 0.51113767 0.19725651]\n",
      "Determining action ...\n",
      "Model's current performance 0.75 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 39 were loaded\n",
      "Model's performance loss before weight fit 2.25 \n",
      "Model's performance loss after weight fit 1.59\n",
      "Model's performance accuracy before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.72\n",
      "\n",
      "Action determination done\n",
      "Action taken : 39 \n",
      "Reward : 0.6599999999999999\n",
      "\n",
      "Episode 299 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 300\n",
      "No change in model performance :\n",
      "previous loss 1.5914101600646973\n",
      "current loss 1.1027140617370605\n",
      "\n",
      "No action performed\n",
      "Episode 300 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 301\n",
      "Current model loss 1.9974360466003418\n",
      "Model loss previously 1.1027140617370605\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 4 : [0.4410655  0.69974033 0.98914503 0.93274147 0.48942282]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "Model's performance loss before weight fit 2.0 \n",
      "Model's performance loss after weight fit 0.96\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.72\n",
      "\n",
      "Action determination done\n",
      "Action taken : 10 \n",
      "Reward : 1.04\n",
      "\n",
      "Episode 301 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 302\n",
      "Current model loss 2.035482883453369\n",
      "Model loss previously 0.9582220315933228\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 2 : [0.66904408 0.85701845 0.83003167 0.26151704 0.7460544 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 21 were loaded\n",
      "Model's performance loss before weight fit 2.04 \n",
      "Model's performance loss after weight fit 4.43\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 21 \n",
      "Reward : -2.3899999999999997\n",
      "\n",
      "Episode 302 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 303\n",
      "No change in model performance :\n",
      "previous loss 4.426854610443115\n",
      "current loss 2.206106662750244\n",
      "\n",
      "No action performed\n",
      "Episode 303 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 304\n",
      "No change in model performance :\n",
      "previous loss 2.206106662750244\n",
      "current loss 1.4614899158477783\n",
      "\n",
      "No action performed\n",
      "Episode 304 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 305\n",
      "Current model loss 2.619274616241455\n",
      "Model loss previously 1.4614899158477783\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 3 : [0.95510974 0.86305971 0.13939546 0.88225182 0.05467442]\n",
      "Determining action ...\n",
      "Model's current performance 0.78 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "Model's performance loss before weight fit 2.62 \n",
      "Model's performance loss after weight fit 2.3\n",
      "Model's performance accuracy before weight fit 0.78 \n",
      "Model's performance loss after weight fit 0.72\n",
      "\n",
      "Action determination done\n",
      "Action taken : 12 \n",
      "Reward : 0.3200000000000003\n",
      "\n",
      "Episode 305 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 306\n",
      "Current model loss 2.465273380279541\n",
      "Model loss previously 2.295046091079712\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 4 : [0.68768821 0.26140697 0.96873725 0.51768794 0.74150554]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "Model's performance loss before weight fit 2.47 \n",
      "Model's performance loss after weight fit 1.7\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 10 \n",
      "Reward : 0.7700000000000002\n",
      "\n",
      "Episode 306 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 307\n",
      "No change in model performance :\n",
      "previous loss 1.7049012184143066\n",
      "current loss 1.074245572090149\n",
      "\n",
      "No action performed\n",
      "Episode 307 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 308\n",
      "Current model loss 1.4881540536880493\n",
      "Model loss previously 1.074245572090149\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 0 : [0.8294236  0.74559669 0.62128023 0.84646665 0.00590027]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 1.49 \n",
      "Model's performance loss after weight fit 0.6\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0.89\n",
      "\n",
      "Episode 308 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 309\n",
      "Current model loss 0.6644347906112671\n",
      "Model loss previously 0.6025869846343994\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 4 : [0.71379402 0.11439283 0.99644947 0.68224113 0.15005741]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.66\n",
      "Model trained from scratch, new performance loss : 0.5113083720207214\n",
      "Model weights for action 54 has been saved at Model_weights/model_action54.weights.h5\n",
      "Model reward for new action 54 : 0.1486916279792786\n",
      "\n",
      "Total number of actions : 55\n",
      "\n",
      "Model's performance loss before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.51\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.97\n",
      "\n",
      "Action determination done\n",
      "Action taken : 54 \n",
      "Reward : 0.1486916279792786\n",
      "\n",
      "Episode 309 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 310\n",
      "Current model loss 2.922769069671631\n",
      "Model loss previously 0.5113083720207214\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 0 : [0.94604047 0.9773926  0.84967312 0.40892222 0.065939  ]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 50 were loaded\n",
      "Model's performance loss before weight fit 2.92 \n",
      "Model's performance loss after weight fit 0.95\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.72\n",
      "\n",
      "Action determination done\n",
      "Action taken : 50 \n",
      "Reward : 1.97\n",
      "\n",
      "Episode 310 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 311\n",
      "Current model loss 1.9495046138763428\n",
      "Model loss previously 0.9514896869659424\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 0 : [0.56194764 0.91843701 0.80258352 0.93694301 0.00972151]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 1.95 \n",
      "Model's performance loss after weight fit 0.56\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.72\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 1.39\n",
      "\n",
      "Episode 311 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 312\n",
      "Current model loss 1.190366506576538\n",
      "Model loss previously 0.5644634366035461\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 0 : [5.51656246e-01 8.05267281e-01 9.34421876e-01 9.75650277e-01\n",
      " 2.12755605e-04]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.19\n",
      "Model trained from scratch, new performance loss : 0.5100692510604858\n",
      "Model weights for action 55 has been saved at Model_weights/model_action55.weights.h5\n",
      "Model reward for new action 55 : 0.6799307489395141\n",
      "\n",
      "Total number of actions : 56\n",
      "\n",
      "Model's performance loss before weight fit 1.19 \n",
      "Model's performance loss after weight fit 0.51\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.97\n",
      "\n",
      "Action determination done\n",
      "Action taken : 55 \n",
      "Reward : 0.6799307489395141\n",
      "\n",
      "Episode 312 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 313\n",
      "Current model loss 3.834118366241455\n",
      "Model loss previously 0.5100692510604858\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 6 : [0.77094512 0.29938886 0.9851044  0.68627894 0.79416271]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "Model's performance loss before weight fit 3.83 \n",
      "Model's performance loss after weight fit 1.41\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 12 \n",
      "Reward : 2.42\n",
      "\n",
      "Episode 313 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 314\n",
      "Current model loss 2.5420732498168945\n",
      "Model loss previously 1.4107930660247803\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 9 : [0.57271283 0.86567056 0.72209392 0.83239098 0.988564  ]\n",
      "Determining action ...\n",
      "Model's current performance 0.56 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 5 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 5\n",
      "\n",
      "Model's performance loss before weight fit 2.54 \n",
      "Model's performance loss after weight fit 1.09\n",
      "Model's performance accuracy before weight fit 0.56 \n",
      "Model's performance loss after weight fit 0.62\n",
      "\n",
      "Action determination done\n",
      "Action taken : 5 \n",
      "Reward : 1.45\n",
      "\n",
      "Episode 314 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 315\n",
      "No change in model performance :\n",
      "previous loss 1.0940203666687012\n",
      "current loss 0.4946272373199463\n",
      "\n",
      "No action performed\n",
      "Episode 315 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 316\n",
      "No change in model performance :\n",
      "previous loss 0.4946272373199463\n",
      "current loss 0.4804161787033081\n",
      "\n",
      "No action performed\n",
      "Episode 316 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 317\n",
      "Current model loss 0.8868880271911621\n",
      "Model loss previously 0.4804161787033081\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 0 : [0.43498557 0.80660213 0.20502697 0.73427235 0.69633937]\n",
      "Determining action ...\n",
      "No significant change in performance accuracy, so no new action\n",
      "\n",
      "Model's performance loss before weight fit 0.89 \n",
      "Model's performance loss after weight fit 0.89\n",
      "Model's performance accuracy before weight fit 0.81 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0\n",
      "\n",
      "Episode 317 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 318\n",
      "Current model loss 1.5727367401123047\n",
      "Model loss previously 0.8868880271911621\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 0 : [0.97660074 0.61624367 0.64519246 0.64558061 0.47066973]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 1.57 \n",
      "Model's performance loss after weight fit 0.74\n",
      "Model's performance accuracy before weight fit 0.59 \n",
      "Model's performance loss after weight fit 0.56\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0.8300000000000001\n",
      "\n",
      "Episode 318 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 319\n",
      "Current model loss 1.0137461423873901\n",
      "Model loss previously 0.7382237911224365\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 6 : [6.86986288e-01 2.29416436e-04 7.46471521e-01 8.86863847e-01\n",
      " 7.92180398e-01]\n",
      "Determining action ...\n",
      "Model's current performance 0.75 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "Model's performance loss before weight fit 1.01 \n",
      "Model's performance loss after weight fit 0.74\n",
      "Model's performance accuracy before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 12 \n",
      "Reward : 0.27\n",
      "\n",
      "Episode 319 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 320\n",
      "Current model loss 0.832126796245575\n",
      "Model loss previously 0.7382619380950928\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 1 : [0.0704776  0.67167164 0.60660824 0.27233152 0.85935482]\n",
      "Determining action ...\n",
      "Model's current performance 0.78 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.83\n",
      "Model training failed, new performance 1.0073810815811157 is greater than the previous loss 0.83\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.83\n",
      "Model trained from scratch, new performance loss : 0.5163984298706055\n",
      "Model weights for action 56 has been saved at Model_weights/model_action56.weights.h5\n",
      "Model reward for new action 56 : 0.3136015701293945\n",
      "\n",
      "Total number of actions : 57\n",
      "\n",
      "Model's performance loss before weight fit 0.83 \n",
      "Model's performance loss after weight fit 0.52\n",
      "Model's performance accuracy before weight fit 0.78 \n",
      "Model's performance loss after weight fit 0.97\n",
      "\n",
      "Action determination done\n",
      "Action taken : 56 \n",
      "Reward : 0.3136015701293945\n",
      "\n",
      "Episode 320 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 321\n",
      "Current model loss 5.611774444580078\n",
      "Model loss previously 0.5163984298706055\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 6 : [0.62338849 0.00197179 0.77867144 0.80625941 0.8141339 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.62 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "Model's performance loss before weight fit 5.61 \n",
      "Model's performance loss after weight fit 2.49\n",
      "Model's performance accuracy before weight fit 0.62 \n",
      "Model's performance loss after weight fit 0.59\n",
      "\n",
      "Action determination done\n",
      "Action taken : 12 \n",
      "Reward : 3.12\n",
      "\n",
      "Episode 321 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 322\n",
      "No change in model performance :\n",
      "previous loss 2.4916930198669434\n",
      "current loss 1.4633121490478516\n",
      "\n",
      "No action performed\n",
      "Episode 322 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 323\n",
      "Current model loss 2.3796911239624023\n",
      "Model loss previously 1.4633121490478516\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 1 : [0.90029314 0.55127547 0.53109454 0.84511657 0.63979295]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 12 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 12\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 2.38\n",
      "Model trained from scratch, new performance loss : 2.0062971115112305\n",
      "Model weights for action 57 has been saved at Model_weights/model_action57.weights.h5\n",
      "Model reward for new action 57 : 0.3737028884887694\n",
      "\n",
      "Total number of actions : 58\n",
      "\n",
      "Model's performance loss before weight fit 2.38 \n",
      "Model's performance loss after weight fit 2.01\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.88\n",
      "\n",
      "Action determination done\n",
      "Action taken : 57 \n",
      "Reward : 0.3737028884887694\n",
      "\n",
      "Episode 323 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 324\n",
      "Current model loss 3.5236833095550537\n",
      "Model loss previously 2.0062971115112305\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 4 : [0.61817544 0.45928527 0.83533697 0.65778693 0.76373594]\n",
      "Determining action ...\n",
      "Model's current performance 0.78 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 30 were loaded\n",
      "Model's performance loss before weight fit 3.52 \n",
      "Model's performance loss after weight fit 0.94\n",
      "Model's performance accuracy before weight fit 0.78 \n",
      "Model's performance loss after weight fit 0.72\n",
      "\n",
      "Action determination done\n",
      "Action taken : 30 \n",
      "Reward : 2.58\n",
      "\n",
      "Episode 324 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 325\n",
      "Current model loss 2.335315704345703\n",
      "Model loss previously 0.9444140195846558\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 10 : [0.87045192 0.05998265 0.84956079 0.77150317 0.57923208]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 2.34 \n",
      "Model's performance loss after weight fit 0.68\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.62\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 1.6599999999999997\n",
      "\n",
      "Episode 325 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 326\n",
      "No change in model performance :\n",
      "previous loss 0.6832840442657471\n",
      "current loss 0.5679761171340942\n",
      "\n",
      "No action performed\n",
      "Episode 326 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 327\n",
      "No change in model performance :\n",
      "previous loss 0.5679761171340942\n",
      "current loss 0.5239574313163757\n",
      "\n",
      "No action performed\n",
      "Episode 327 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 328\n",
      "Current model loss 0.7990670800209045\n",
      "Model loss previously 0.5239574313163757\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 2 : [0.68931583 0.78826903 0.90716582 0.9571786  0.76756801]\n",
      "Determining action ...\n",
      "Model's current performance 0.53 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.8\n",
      "\n",
      "Target accuracy (0.80) and loss (0.32) reached. Stopping training.\n",
      "Model trained from scratch, new performance loss : 0.3143980801105499\n",
      "Model weights for action 58 has been saved at Model_weights/model_action58.weights.h5\n",
      "Model reward for new action 58 : 0.4856019198894501\n",
      "\n",
      "Total number of actions : 59\n",
      "\n",
      "Model's performance loss before weight fit 0.8 \n",
      "Model's performance loss after weight fit 0.31\n",
      "Model's performance accuracy before weight fit 0.53 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 58 \n",
      "Reward : 0.4856019198894501\n",
      "\n",
      "Episode 328 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 329\n",
      "Current model loss 1.349506139755249\n",
      "Model loss previously 0.3143980801105499\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 7 : [0.73267675 0.91978035 0.35035998 0.90707864 0.6929205 ]\n",
      "Determining action ...\n",
      "Model's current performance 0.72 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "Model's performance loss before weight fit 1.35 \n",
      "Model's performance loss after weight fit 0.4\n",
      "Model's performance accuracy before weight fit 0.72 \n",
      "Model's performance loss after weight fit 0.81\n",
      "\n",
      "Action determination done\n",
      "Action taken : 10 \n",
      "Reward : 0.9500000000000001\n",
      "\n",
      "Episode 329 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 330\n",
      "Current model loss 3.3719747066497803\n",
      "Model loss previously 0.3959495723247528\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 12 : [0.79855447 0.06623996 0.67516786 0.84847313 0.16110367]\n",
      "Determining action ...\n",
      "Model's current performance 0.69 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 2 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 2\n",
      "\n",
      "Model's performance loss before weight fit 3.37 \n",
      "Model's performance loss after weight fit 0.64\n",
      "Model's performance accuracy before weight fit 0.69 \n",
      "Model's performance loss after weight fit 0.69\n",
      "\n",
      "Action determination done\n",
      "Action taken : 2 \n",
      "Reward : 2.73\n",
      "\n",
      "Episode 330 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 331\n",
      "Current model loss 0.9457576274871826\n",
      "Model loss previously 0.6395357251167297\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 10 : [0.97379083 0.69988969 0.79469235 0.81100503 0.80207599]\n",
      "Determining action ...\n",
      "Model's current performance 0.75 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.95\n",
      "Model training failed, new performance 2.5550122261047363 is greater than the previous loss 0.95\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 0.95\n",
      "Model trained from scratch, new performance loss : 0.5716268420219421\n",
      "Model weights for action 59 has been saved at Model_weights/model_action59.weights.h5\n",
      "Model reward for new action 59 : 0.3783731579780578\n",
      "\n",
      "Total number of actions : 60\n",
      "\n",
      "Model's performance loss before weight fit 0.95 \n",
      "Model's performance loss after weight fit 0.57\n",
      "Model's performance accuracy before weight fit 0.75 \n",
      "Model's performance loss after weight fit 0.97\n",
      "\n",
      "Action determination done\n",
      "Action taken : 59 \n",
      "Reward : 0.3783731579780578\n",
      "\n",
      "Episode 331 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 332\n",
      "Current model loss 2.2971088886260986\n",
      "Model loss previously 0.5716268420219421\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 12 : [0.86311404 0.9801797  0.01083716 0.11427971 0.90769395]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploration action taken, model training start...\n",
      "model weights 7 were loaded\n",
      "Model's performance loss before weight fit 2.3 \n",
      "Model's performance loss after weight fit 4.49\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.44\n",
      "\n",
      "Action determination done\n",
      "Action taken : 7 \n",
      "Reward : -2.1900000000000004\n",
      "\n",
      "Episode 332 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 333\n",
      "No change in model performance :\n",
      "previous loss 4.490985870361328\n",
      "current loss 2.969789981842041\n",
      "\n",
      "No action performed\n",
      "Episode 333 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 334\n",
      "No change in model performance :\n",
      "previous loss 2.969789981842041\n",
      "current loss 2.8277273178100586\n",
      "\n",
      "No action performed\n",
      "Episode 334 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 335\n",
      "Current model loss 2.926586389541626\n",
      "Model loss previously 2.8277273178100586\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 13 : [0.25800322 0.52188437 0.72335086 0.88384929 0.83111615]\n",
      "Determining action ...\n",
      "Model's current performance 0.66 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 5 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 5\n",
      "\n",
      "Model's performance loss before weight fit 2.93 \n",
      "Model's performance loss after weight fit 1.42\n",
      "Model's performance accuracy before weight fit 0.66 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 5 \n",
      "Reward : 1.5100000000000002\n",
      "\n",
      "Episode 335 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 336\n",
      "No change in model performance :\n",
      "previous loss 1.4212138652801514\n",
      "current loss 0.4141199588775635\n",
      "\n",
      "No action performed\n",
      "Episode 336 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 337\n",
      "Current model loss 1.5147757530212402\n",
      "Model loss previously 0.4141199588775635\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 0 : [0.65976419 0.91512198 0.64314856 0.73071739 0.15075135]\n",
      "Determining action ...\n",
      "Model's current performance 0.53 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 0 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 0\n",
      "\n",
      "Model's performance loss before weight fit 1.51 \n",
      "Model's performance loss after weight fit 1.07\n",
      "Model's performance accuracy before weight fit 0.53 \n",
      "Model's performance loss after weight fit 0.66\n",
      "\n",
      "Action determination done\n",
      "Action taken : 0 \n",
      "Reward : 0.43999999999999995\n",
      "\n",
      "Episode 337 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "No Drift_detected in episode 338\n",
      "No change in model performance :\n",
      "previous loss 1.0665490627288818\n",
      "current loss 0.45849448442459106\n",
      "\n",
      "No action performed\n",
      "Episode 338 done...\n",
      "\n",
      "====================================================================== \n",
      "\n",
      "Decline in model's performance in episode 339\n",
      "Current model loss 1.0057412385940552\n",
      "Model loss previously 0.45849448442459106\n",
      "Determining State...\n",
      "Number of states available 17\n",
      "The similarity score of target state 4 : [0.65597401 0.3281854  0.63816081 0.83738012 0.72450288]\n",
      "Determining action ...\n",
      "Model's current performance 0.59 was less than the threshold : 0.8\n",
      "Exploitation action taken, model training start...\n",
      "model weights 10 were loaded\n",
      "model <DNN_model name=dnn_model_2, built=True> was initialized using weights 10\n",
      "\n",
      "New action created due to inadequate performance in exploit\n",
      "\n",
      "Model Compiled for new action\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 21:13:23.219939: E external/local_xla/xla/service/slow_operation_alarm.cc:65] \n",
      "********************************\n",
      "[Compiling module a_inference_one_step_on_data_1216847__.917] Very slow compile? If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "********************************\n",
      "2025-03-08 21:15:41.933959: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 4m18.727407144s\n",
      "\n",
      "********************************\n",
      "[Compiling module a_inference_one_step_on_data_1216847__.917] Very slow compile? If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training failed, new performance 1.5055806636810303 is greater than the previous loss 1.01\n",
      "Model Compiled...\n",
      "Model Fitting...\n",
      "Target loss 1.01\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('linear_sudden_rotation_noise_and_redunce.csv')\n",
    "\n",
    "# Assuming the label is the last column and features are all others\n",
    "X = df.iloc[:, :-1].values  # Features (x1, x2, x3, x4, x5)\n",
    "y = df.iloc[:, -1].values   # Label (binary: 0 or 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "bX_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "batch_X = bX_train[0:0+32]\n",
    "\n",
    "obj = Reinforced_DNN(\n",
    "                     100,\n",
    "                     100,\n",
    "                     input_dim = batch_X.shape[1], \n",
    "                     activation = \"relu\", \n",
    "                     input_units = 12,\n",
    "                     learning_rate=0.1, \n",
    "                     discount_factor=0.9, \n",
    "                     exploration_rate=1.0, \n",
    "                     exploration_decay=0.995)\n",
    "\n",
    "mod, initial_history, final_history, improvement_history, drift_data  = obj.initialize_train_model(bX_train, \n",
    "                                                                                                   y_train, \n",
    "                                                                                                   n_episodes= 500, \n",
    "                                                                                                   batch_size=32, \n",
    "                                                                                                   performance_threshold = 0.80, \n",
    "                                                                                                   ks_pvalue = 0.01, \n",
    "                                                                                                   wil_p_value = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "534cec00-4d6d-4009-a9ac-468144ff2484",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Starting Evaluation...\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Number of states available 13\n",
      "Similar state not found, finding the next best option...\n",
      "Search with p_value 0.628...\n",
      "The similarity score of target state 12 : [0.20508211 0.66573182 0.34407946 0.6941915  0.82458315]\n",
      "\n",
      "Average loss of the model : 2.963916301727295\n",
      "Standard deviation loss of the model : 0.0\n",
      "Maximum loss of the model : 2.963916301727295\n",
      "Minimum loss of the model : 2.963916301727295\n",
      "\n",
      "Average accuracy of the model : 0.625\n",
      "Standard deviation accuracy of the model : 0.0\n",
      "Maximum accuracy of the model : 0.625\n",
      "Minimum accuracy of the model : 0.625\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obj.evaluate_model(X_test, y_test, n_episodes=250, wil_p_value = 0.785)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6fea73fb-8c62-4780-8c8f-b5379d2cf535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(drift_data)\n",
    "len(initial_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e081500-f858-4b97-a068-e7d00dc28110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACSuUlEQVR4nO3dd3xT9foH8E/Ske696R4UOthQ9pbpFnCvK6Bet/68iuPqdYHKFbfgQr0uUFFUZC9ZZRdKaUtbuvegu02b5Pz++Pak6UiaNDmZz/v16ss0OTnnG1PaJ9/v830eEcdxHAghhBBCLJzY1AMghBBCCDEECmoIIYQQYhUoqCGEEEKIVaCghhBCCCFWgYIaQgghhFgFCmoIIYQQYhUoqCGEEEKIVaCghhBCCCFWwd7UA9BEoVCgrKwM7u7uEIlEph4OIYQQQrTAcRyampoQEhICsdh48ydmHdSUlZUhLCzM1MMghBBCyCAUFxcjNDTUaNcz66DG3d0dAJCdnY2goCCDn7+lpQUhISEAWADl6upqcdewhtdgTej9Nh/W8jqERj9T5sOa/j81NjYiLCxM+XfcWMw6qOGXnNzd3eHh4WHw89vZ2Slve3h4CPIDJPQ1rOE1WBN6v82HtbwOodHPlPmwxv9Pxk4doURhQgghhFgFCmoIIYQQYhUoqCGEEEKIVRA0qCktLcUdd9wBX19fODs7Izk5GadOnRLykoQQQgixUYIlCl+5cgVTpkzBrFmzsH37dvj7+yMnJwfe3t5CXZIQQgghNkywoObNN99EWFgYNm7cqLwvKipKqMsRQgghxMYJtvz0+++/Y9y4cVi6dCkCAgIwevRofPbZZxqfI5VK0djY2OOLEEIIIUQbggU1ly9fxieffIK4uDjs3LkTDz74IB599FF8/fXXap+zevVqeHp6Kr+omjAhhBBCtCVYUKNQKDBmzBi88cYbGD16NFauXIkVK1Zg/fr1ap+zatUqNDQ0KL+Ki4uFGh4hhBBCrIxgQU1wcDASEhJ63Dd8+HAUFRWpfY5EIoGHh0ePL0IIIYQQbQgW1EyZMgXZ2dk97rt06RIiIiKEuiQhhBBCbJhgQc0TTzyB1NRUvPHGG8jNzcX333+PTz/9FA899JBQlySEEEKIDRMsqBk/fjx+/fVX/PDDD0hKSsKrr76Kd999F7fffrtQlySEGJpcbuoREEKI1gTt0n311Vfj6quvFvIShBAhbd4MLF9u6lEQQohWqPcTIUS9/ftNPQJCCNEaBTWEkJ5qarpvHzpkunEQQoiOKKghhPSkumuxuBgoKDDZUAghRBcU1BBCerp0qef3Bw6YZBiEEKIrCmoIIT31qi9FQQ0hxFJQUEMI6Skrq+f3+/cDHGeasRBCiA4oqCGE9KS6/GRnBxQVUV4NIcQiUFBDCOnW2sqCGN64cey/tARFCLEAFNQQQrr1ThKeNo39l4IaQogFoKCGENItM7Pn96pBDeXVEELMHAU1hJBuvZOEJ04E7O0pr4YQYhEoqCGEdOs9U+PqCkyYwG7TEhQhxMxRUEMI6dZ7pgYAZs5k/6WghhBi5iioIYQwcnnfRGGgZ1BDeTWEEDNGQQ0hhCkoAKRSQCLpef/kyZRXQwixCBTUEEIYPp8mLq7n/ZRXQwixEBTUEEIYPqiJj+/7GOXVEEIsAAU1hBCGTxLWFNRQHyhCiBmjoIYQwvAzNUOH9n1s8mTAwQEoLgby8407LkII0RIFNYQQNvuiaaaG8moIIRaAghpCCFBVBVy5AohEQGxs/8dQXg0hxMxRUEMI6Z6liYoCnJ37P4bq1RBCzBwFNYSQ7nyaYcPUHzNpEuXVEELMGgU1hJDumZrhw9UfQ3k1hBAzR0ENIaR7pkZTUANQXg0hxKxRUEMI6Z6p0bT8BFBeDSHErFFQQ4ita25mfZ2AgYMayqshhJgxCmoIsXXZ2ey//v6Ar6/mYymvhhBixiioIcTWaZMkrIryagghZoqCGkJsnTbbuVVRXg0hxExRUEOIrdN1pka1D9Tly8KNixBCdERBDSG2TteZGhcXICWF3aYlKEKIGaGghhBbJpMBOTnstrYzNQDl1RBCzBIFNYTYssuXgc5ONvsSFqb98yivhhBihiioIcSW8fk08fGAWIdfB3y9mpISyqshhJgNiwhqpJ1yUw+BEOukbXuE3iivhhBihiwiqDlbfMXUQyBdWjtkph4CMSRdk4RVUV4NIcTMWERQc6aIghpzsTWtzNRDIIak63ZuVZRXQwgxMxYR1JwurDf1EGxaW0f38l96SYMJR0IMiuP0m6mhvBpCiJmxiKDmYmkjLXuYUFZFdyBzobTedAMhhlVRATQ2sgThuDjdn095NYQQM2MRQY1MweF0IS1BmUp6SaPydm51C5raO004GmIw/CxNdDQgkQzuHJRXQwgxIxYR1ABA6uVaUw/BZl0o7Z6p4TggvZSWoKyCPvk0PMqrIYSYEQsKaupMPQSbdaGsZxBzrpiCGqugTz4NTzWvJi/PMOMihJBBspig5lxxPeXVmEBDWyfya1p73JdGW+ytgyFmaiivhhBiRiwiqAnydKK8GhPJ6GepiWZqrIQhZmoAYNYs9l8KagghJmYRQc3YCG8AlFdjCud6beEWi4CKxnZUNLSbaETEIJqagNJSdlufmRqA8moIIWbDIoKaMcqghvJqjO18SX2P72MD3AAAacX1fQ8mloNfegoKAry89DvXxImAoyMLkiivhhBiQhYR1IwLZ0EN5dUY3/leMzUjwzwBAOd6BTvEwhhq6QmgvBpCiNmwiKAm2MsJQ7ycKa/GyGqapSitb4NI1H1f8hAvACzAJBbMEEnCqqheDSHEDFhEUCMSiZAS7QOA8mqMiV96ivJ1Ud6XHOrZ9VgD5ArKn7BYhpypASivhhBiFiwiqAGAidG+ACivxpj4XU787AwAxAW4w8XRDs1SGS5XN5toZERvhp6pobwaQogZsJygJooFNZRXYzz8TE3SEA/lfXZiEZKGsNkaSha2UJ2dQG4uu22omRrKqyGEmAGLCWrCfJwRQvVqjIbjOGWScFLXkhNvVJgXAApqLFZeHiCTAa6uQGio4c5LeTWEEBOzmKBGJBKpLEFRXo3QSuvbUNvSAXuxCMOCPHo8xgc1tAPKQqnm06hmgeuL8moIISZmMUENQHk1xsTP0sQHucPJwa7HYyO7gpqs8ia0d8qNPTSiL0Pn0/BU82r45S1CCDEiowU1a9asgUgkwuOPPz7oc/BBDeXVCI+fhRkR6tXnsRBPJ/i5SSBTcMgoo5YJFsfQO594lFdDCDExowQ1J0+exIYNGzBixAi9zkN5NcaT3jVTM7JXPg3AlgK782ooqLE4fFBj6JkagPJqCCEmJXhQ09zcjNtvvx2fffYZvL299ToX5dUYh0LBKYOa/mZqAGAUX1mYkoUtC8cJt/wE9GxuaeK8GqqjRIjtETyoeeihh7B48WLMnTt3wGOlUikaGxt7fPXGBzXHKa9GMPm1LWiSyiCxFyMu0K3fY0bSDijLVFoKNDcDdnZATIzhz8/n1ZSVmTyvZvOpYuVtqYxyvwixBYIGNT/++CPOnDmD1atXa3X86tWr4enpqfwKCwsDAFS3ViuPUebVlFBejVD4+jSJIR5wsOv/R4SfwSmqa0VdS4eRRkb0xs/SxMay4MPQnJ1ZYAOYdAmqqqkd63ZfUn6fVd73AxIhxPoIFtQUFxfjsccew3fffQcnJyetnrNq1So0NDQov4qL2Setc+XnlMfweTWdcg5nCuuFGLrN4ysJq1t6AgBPZwdE+7uy42lrt+UQKklYlRnk1by+LRNN7d0feij3ixDbIFhQc/r0aVRVVWHMmDGwt7eHvb09Dh48iPfffx/29vaQy/tOB0skEnh4ePT4AoCL1ReVx1BejfD4mRq+I7c6o7qCnrSiemEHRAxHyHwanonr1RzOqcHWtDKIVUrw0DIpIbZBsKBmzpw5SE9PR1pamvJr3LhxuP3225GWlgY7O7uBT9Ilsyazx/cU1AinU65ARhmbqtc0UwMAo8LZ4zRTY0GMMVNjwrya9k45Xtx6AQBwW0q48v5zxbRbkhBbYC/Uid3d3ZGUlNTjPldXV/j6+va5fyAXay72+L53Xo2Lo2Avw+ZcqmyCVKaAu8QeUb6uGo8d2RX0nCuuB8dxEBmyOi0RhjFmavi8mr//ZrM1cXHCXauX9QfzkF/TggB3CR6ZEwc+m6+8QYqKhnYEeWq3FE4IsUwWUVE4ty4X7bJ25feUVyMcvpJwcqgnxGLNQcqwYHc42olxpbUTRXWtxhge0UdDA1Bezm7Hxwt7LRPk1eTXtODj/axD+L+vSYCHk0OPx88W0WwNIdbOqEHNgQMH8O677+r8PI7jkFndvQRFeTXCOa+hknBvEns7JISwvCfKWbAA/CxNSAjgqTlfSm9GzqvhOA4v/nYBHXIFpg/1x+Lk4D7HnKGghhCrZxEzNQBwvvJ8j+8pqBEGv/Opv0rC/VE2t6TdJebPGPk0PCPn1fx+rgyHc2vgaC/Gq9cl9rsUeoYS2gmxehYf1FC9GsNp75Qju7IJADCiK1gZCL9DipKFLYCQ7RF6U61Xs3+/oJdqaOvEq3+y1/bIrFhEqMkFSy9tQIdMIehYCCGmZTFBzbnKcz2+p7waw7tY3gi5goOfmyNCtEyoHBXGWl9cKG1Ap5z+YJg1YyQJqzJSXs3andmoaZYi2t8VK2dE93uMt6sDOmQKasBqKgqV3w3HjpluHMTqWVRQw6mszVNejeGd78qLGRHqpfVOpkhfF3g42UMqUyC7oknA0RG9GXP5CTBKXk1acT2+PV4IAHjt+iRI7PsvFcHv1KMlKBO5qLKD9ZFHgA6qQk6EYRlBjQioaa1BZUtlj7spqDGs88omltonkYpEIuoDZQmkUuDyZXbbWDM1kyYBEgnbcZWTY/DTy+QKPP9rOjgOuHH0EEyO8VN7LJ/7RTugTOTo0e7bWVnAW2+ZbizEqllEUBPtxaaUKa9GWOeUO5902xkzmoIa85ebC8jlgLs7ENx3Z5AgnJwE7QP1v9RCZJQ1wsPJHs8t1hyo8YnvZ2mmxjRUgxoAeO014NKl/o8lRA8WEdQk+CcA6BvUUF6N4TS1d+JyTQsA7bZzqxqp3AFVb9hBEcNRzacxZpFEgfJqKhra8d9d7I/iswuHw89NovH45FAviEVAaX0bKhvbNR5LDIzjgCNHur+fO5fNHN5/v0naaBDrZhlBjV//QQ3l1RhOemkDOA4Y4uU84B+I3vggKLe6GU3tnQKMjujN2Pk0PIHyal798yKapTKMDvfCLePDBjzeVWKP+CBWU+lMIS1BGVVhYXfRRwB49122O+7AAeCrr0w0KGKtLCKoGe7PppZ7BzUA5dUYymDyaXj+7hIM8XIGxwHpJbS7xCwZe+cTb+JEg+fV7M+uwrb0ctiJRXj9+uQBK1/zxnT1KqMifEZ26FDP7yMjgVdeYbefegqoqjL6kIj1soigJtE/EQDr1t0p7zkTkBLtA4DyavSlSyXh/vDNLdOoXo15MtVMjYHzato75fh3V8PKf0yJVFa01saYcFZ+gHZAGdnhw33ve/xxYNQo4MoV4MknjT0iYsUsIqgZ4jEEHhIPdCo6kV2b3eOxcB8XBFNejd50rSTc2yiV5pbEzCgUppupAQyaV/PhvlwU17Uh2NMJj88dqtNzx0SwoIaK8BlZ75kaALC3Bz77DBCLge++A3buNP64iFWyiKBGJBJhROAIAJRXI4TaZilK69sAAEmDDGpoW7cZKykBWlvZH5Lo/ovTCcpAeTW5VU3Y8DdrWPnytYlwldjr9PxIXxd4u7AifBfLGwc9DqKDmpruWcLexo0DHn2U3X7wQfYzSoieLCKoAYARASyoOVdxrs9jE7uWoCioGRw+nyba37VPZ2NtJQ3xgJ1YhMpGKSoaaHeJWeH/qMTFAQ6De3/1YoC8Go7j8PyvF9Ap5zB3eADmJQTqfA6RSITR/BIUJQsbB7/rSV1X+FdfBcLDgfx84D//Md64iNWynKCGn6mpUp8sfK6kHm0dcqOOyxrw9WlGDjKfBgBcHO0xNNAdAM3WmB1TLj0BPfNqBtkHasuZUhzPr4Ozgx1evrb/hpXaoGRhI+OXniZP7v9xNzfgo4/Y7f/+F0hLM8qwLEFDG+0kHQzLC2r62QHVI6+GflnpLF2PnU+qRnU1t6SgxsyYKklYlR55NfWtHXj9L/YaHpsbh1Bvl0EPg08WpiJ8RjJQUAMAV18NLF3KikOuWMH+S/BSV0I80Y3FBDVJAUkAgLKmMtS01vR4zJzzasq7clXMFcdxOKcMarz0OtcoKsJnnkw9UwPolVfz5o4s1LV0YGigG+6bGqXXMEaGURE+o2lpAc6cYbc1BTUA8N57gKcncOpU98yNDTqa2/23bWdGJbX1GASLCWrcJe6I9mZJjumV6X0eN9e8mo/25ypvKxTmVz2zvKEdNc1S2ItFSNRhe2x/+GTh9NIGyM3wtdosc5ip4fNqKip0Ko9/urAOP5woBgC8fkMyHOz0+5VFRfiM6PhxQCYDQkNZ3owmwcHAm2+y2889BxQVCT8+MyOTK7Bme8+k6tXbs3o0ciYDs5igBtC8BMXP1KQVm09eTWVjO/44111J82yx+f0S5evTDA10h5ND/x2OtRUX4A4XRzs0S2XIq242wOiI3urquoubmTKocXJiDS4BrZegOuUKPP8rm4K/eVwYxkf6GGQolFdjJPzS07Rp2rXmWLECmDKFzfA8/LDNtVD4/kQRcqpalN9L7MU4kV+HvZlUnFAXlhXUBFhWXs2Xh/PRIe+uh7Ezo8KEo+nfOQPl0wCAnViE5CGUV2NW+KWn0FCWlGlKOubVbDySj6yKJni7OODZhYYLyEZTXo1x8EHN1KnaHS8WA59+ynbo/fEHsGWLcGMzM/WtHXhnd88ZzLsmRwBgy68yOdVV0pZFBTUjg0YC6H8HlLnl1TS0deK74z2nUHdlVJrdEpS+lYR7o7waM2MO+TQ8HfJqSuvbsG432/793KLh8HZ1NNgw+Jma81SETzidnUBqKrs9bZr2z0tIAJ59lt1+5BGgvt7gQzNH7+7JQX1rJ+ICuj943Dc1Gl4uDsipasbPp0tMODrLYlFBDb/8dKHqAuSKvktM5pRX821qIZqlsh4/pJWNUpw1oz/2CgWnc8+ngdZ3qQifmTGHfBpeSorWeTUv/56Btk45JkT5YMnYUIMOI8rPlYrwCS0tjS0jeXkBiYm6Pfe554ChQ1ldo1WrhBidWcmpbML/UgsBAKsWdf879XR2wCOz4wAA6/ZcojZAWrKooCbaOxouDi5ol7Ujp65vES9zyatp75Rj45ECAMDy6T13a/yVXt7PM0yjoLYFTe0ySOzFiA9y1+o5WzI1TwnzMzVZFU1o7zSP3Cabxgc15jBTo2Veza6MCuy+WAl7sQivX5806Jo06lARPiPgl56mTGHLSrpwcgI2bGC316/vLuBnhTiOwyt/XoRcweGqhEBMivHr8fgdE8MR6u2MykYpvjycb6JRWhaLCmrEIjGSA5IBmHdezc+nS1DTLMUQL2csTAru8dj29HKzyWbnZ2kSQjw07ipR3UJ/oOCAxnMGezrB310CuYJDRhl17DY5fvnJHGZqgAHzalqkMrz8ewYAYOX0aMQFahds64qShQXGN7HUZelJ1cyZwD/+wW6vXAl0dBhkWOZmX1YVDuXUwNFOjOcX9f3gIbG3w9PzWTXm9Qcvo7ZZauwhWhyLCmoAzTugzCGvRiZX4NO/LwMAlk+L6hEsuDraoayh3WyWZrStJLz38l7l7aPFRzUeKxKJlOejREwTa29n5ecB85ipAQbMq3l/bw7KGtoR6u2snHoXAhXhExDH6R/UAMDbbwP+/sDFi8BbbxlmbGakQ6bAa9vYTOq9UyMR6efa73HXjAhB8hBPNEtl+GBfbr/HkG5WFdQAps+r2X6hAkV1rfB2ccDN48N6PDYjPgCA+SxBaZtPs/vybuXt7NrsPsUPexvd9SmY31lFTCQnh3Xo9vICAnXvlSQIDXk1WRWN+Lxriv3V65Lg7KhfiQFNRlARPuFkZwPV1ex9Hjt28Ofx8QHefZfdfu01neobWYJvjhUgv6YFfm4SPDwrVu1xYrEIq7p2/32bWoiCmha1xxKrDGpMl1fDcRzWH2RdhO+eHAkXx55dhOd3NeH7K73C5EtQMrlCuTykaeeTglNgz+U9Pe47XHRY47n5mRraAWViqknCBs5LGTTVvBqVPlAKBWtYKVdwWJgUhFnDAgQdhpuku1cZVW01MH6Whg9g9XHrrcD8+YBUCtx/v9XUrqlpluK9PSwv9F/z4+E+QCPhybF+mDHUHzIFh7d3ZRtjiBbL4oIaPqemsKEQDe19ZwJMmVdzOLcGGWWNcHaww92TIvs8Pm2oP5wd7FBa36acJTGVnKpmtHcq4C6xR7SaaU8AOF12us/MzKHCQxrPndw181NU10prwKZkTtu5VfWTV7P5VDFOF16Bq6Md/n1NglGGMSaiK1mYlqAMS7Xonr5EIuCTTwBnZ/bz8tVX+p/TDPx31yU0SWVIGuKh9e6+ZxcOg0gEbDtfTh8YNbC4oMbb2RthHmxZJ72qb7sEU+bVfHKAzdLcMiGs37oazo52mN31CfSvC6ZdguLr0yQN8YRYrP5T/Pbc7X3uO1SkOajxdHZAjL9r13VoCcpkzGk7t6peeTW1zVKs3s4CsCfnxSPY09kowxhDO6CEoWvRvYFERQH/+Q+7/X//110h20JllDXgx5Oshtm/r07U+PtX1fBgD9w4mgVAb/yVafLZfnNlcUENYJ55NedL6nE0rxb2YhGWT4tWe9yiZLYb6i8T74JSVhIO05xP019Qc6b8DJo7NLdBoHo1ZsBcZ2r4ZYnKSiA7G2/8lYWGtk4kBHvg7kkRRhsGFeETQGkpS04XiwduYqmLJ54ARo1ibT+efNJw5zUyjuPwyh8XwXHA1SOCMSFKt9YfT80bCkd7MY7n12F/tmUHd0KxyKBmZGBXZWEzyqvhc2muHRmCIV7qP2nOGuYPJwcxiuvakFFmusJf57XY+VTTWoPjJcd73BfmEQY5J0dqSarG84+ioMa0FAqWsAmY30yNSl7N5Z/+xC9nSiASAa/fkAR7PRtW6oKK8AmAz6cZORLw0K9Bbg/29qyFglgMfPcdsHOn4c5tRDsuVOB4fh0k9mKs6mcL90BCvJxx75RIAMCa7VnUOLgfFhnUDDRTY+y8msvVzdh+gfV1un9GjMZjXRztMatrF9Q2E+2Cau+UI6u8CYDmnU+78naBA4dE/+6KoFPCpwAYOK9G2S6hpJ6mSU2hqAhoawMcHdn0vbmZNQsAULjlLwDA7SnhyoJ4xkJF+ARg6KUnVePHs9YJAPDgg0Brq+GvIaD2Tjle/4stCd8/PVrjh19N/jkzFl4uDrhU2YxfqH1CHxYf1Ci4vtPGxs6r+ezQZXAcMGdYgFaVefklKFMV4sssb4RMwcHH1VHjPyx+6WlezDzlfZPD2JTyQHk1w4I84GgnRn1rJ4rqLOuXj1Xg82ni4tinXHPTlVeTlHMWfq4OeHq+aWaTRncF31SEz0AMmSTcn1dfBcLC2BIXn2djIb44nI+SK20I8nDCAzM1f/jVxNPZQbkF/J3dl0xaPd8cWWRQE+cbB4mdBC2dLci/0n/paGPl1VQ1tuOX06UAoPUP6uxhAZDYi1FQ22qSaW/V+jTqStArOAV25rIp3h5BTSgLalJLUtEhV1/l09FejIQQNv1MS1AmYE7tEfpRMWwk2uwl8G+pxwZxFjydNW9pFQq/A4qK8BlAfT2Q3rV5Q6igxt0d+Ogjdvu//2U9pixAZWM7PtrPCuc9u3BYn3IfurpzUgSGeDmjorEdXx6h9gmqLDKosRfbIzGALYmoW4JKiTJOXs0XR/LRIVdgXIQ3xkdql/TlKrHHzHh/AMD29ArBxqbOOS06c58uO43q1mp4SDwwMXSi8v54v3j4ufihTdaG02WnNV6H8mpMyFyThLv892AB1qfcBAAYs/o5kxVWG6lShK+KivDp5+hRVkcmNhYIChLuOtdcAyxZAsjlrIWC3PxnKt7akY3WDjlGh3vhulEhep+vR/uEA3moa7HONhKDYZFBDTBwXk2ErwuCPITNq2ls78T3qWxr3gMD5NL0ZspdUPxMzUgN+TT80tPc6LlwsOv+FC0SiTA1nK2XD7QEpcyroaDG+Mx1OzeAi2WN+PlMCT6YfDOaJk6FqKUFWLaMtXUwMtUifLQEpSch82l6e/99wNMTOHmye+bGTKUV1+OXMyz35aVrErVv0KrQvCPv2pEhSAzxQJNUhg/29W3wbKssN6gJ6ApqqvoPalheDZs5OS7QEtS3qYVoksowNNBNWX9GW7OHBcDRXozLNS3IrmwSZHz9aZbKkFfNtmNrmqnhg5qFsQv7PDYtnE0tDxTU8Nu6L5Q10pZZYzPjmZrV2zPBccCiUaFw/2UT6+9z7pzJtupSET4DMUS/J20FBwNr1rDbzz8PFBcLf81BYFu4WYPWG8cMUX7QU6tRJR3hlltYJWU1WPsE9u/729RCFNVS7iJgyUHNADM1AFSShesMfv32Tjm+PFwAALh/eozWBZR47k4OmB7HlqD+Om+8XVDpJQ3gOCCkq5t2f1S3ci+IXdDncT6oOVJ0pN9EbV6krws8ndmW2ewK4wVuNq+mhn0BwNChph1LLwcvVSu7Ej+zYBgQEgL873/swU8+AX76yehjoiJ8BtDeDpw4wW4bI6gB2NLT5MlAczPw0ENm2ULh93NlOFNUDxdHO/bzrklpKTCvO38Rf/0F3HijxhnMqXF+mBbnh045tU/gWXxQk1eXp7YQnJD1aracKUVNsxQhnk64dpBrpItHsHXnvy4YL6/mvBb5NPxW7uSAZIR69C3hPTp4NFwdXHGl/QoyqjLUnkckEnUX4eu6LjECfpYmIgJwVd8Cw9jkCg5vdHUlvntyBMJ8XNgD8+cDzz7Lbi9fDuTlGXVco6kIn/5OngQ6OoCAAJZTYwxiMatd4+AA/PEHsGWLca6rpdYOGVb/xf4tPjQrFoEeTuoPzshgtZsuXOi+z8mJBTbXXcfKM6jBt0/441yZ8ve7LbPYoMbf1R9BbkHgwKn9w8rn1XTIFQZtWidXcPj0b/aLd/m0aDgMsmDYnOGBcLQTI7eqGZeMtAR1vnTgSsKalp4Alqit7dbuUV15O2k0tW88ZppP8/PpYmRXNnVtSY3r+eCrrwJTprDp95tv1jjtbmjRfq7woiJ8+lFdejJm89TEROCZZ9jtRx4BGsynLcv6g5dR0diOUG9n3DdVQ62oAwfYz35xMSvBwNuyhX0o2bULuPpqoKX/7tyJIZ64YdQQAMDqv7Jsvi6YxQY1wMCVhVXzagy5tXvHhQoU1LbCy8UBt0wIG/R5PJwcMC3ODwBrUmYMA1USVt3KvShukdrz6JpXc44+QRiPGebTtHbI8N9dbIfTI7Nj4enSawu3vT3www+Ajw9w+nT3HyojEIlEyno11LF7kISuT6PJ88+zYKC8HFi1yvjX70fJlVZs6Koy/9yi4XBysOv/wB9+YDOVDQ0ssNmzp/ux6dOBHTsANzdg3z5g0SKgqf8Pv092tU84drkWBy5VG/rlWBSLDmr4JahzlefUHmPovBqO45QtEe6aFKl3vYGFfCE+IzS4rGvpQHEdm8ZMGtL/TI3qVm5+NqY/0yK6gprCQxo/GfBBTV51MxrbOwc5cqITM5yp+ezvfFQ1SRHu44I71fV3Cgvr7sL83nvAb78Za3jdeTU0o6g7uRw4coTdNsbOp96cnNgyFAB88gk4ftbIhNZsz4JUpkBKlA8WJvWzvZ3jgLfeAm67jS3b3XQTC2h8fXseN3UqsHs3aznx99/AggU9k4m7hHq74J7Jkezaf9l2+wSrCGq0SRY2VF7NkdxapJc2wMlBrPwh0sdVCYFwsBPhUmUzcquEXYLiZ2mi/VzVFjtTt5W7t5QhKXAQO6C0qRQF9QVqj/NzkyDU2xkcx5KUiRGYWeG9qsZ2bOharn1mwTBI7NV8agVYDRJ+F9S99wKFhUYYocoOKEoW1t2FC+wPrZsb6/lkCjNnov2OuwAA1YtvwLnPfjDNOACcyK/Dn+fLIRIB/74moe8WbrkcePjh7tnIJ54ANm9mwVl/Jk5kAY+XF6sFNG8eK3TYy0MzY+Hp7IDsyiZsOWO77ROsJqhRN1tg6LwafpbmlvHh8HF11Pt8ns4OmBrLlqD+ErgQn2olYXUGyqfhOTs4Y1zIOADaL0FRET4jaG3tDgTMZKZm3Z5LysJji5K1KMq2ejUwYQL7xX3LLUCn8DN8VIRPD/zS0+TJJm3J8ek1D6DAKxgBjTUYufI2nJqyEDV5RUYdg0LB4ZU/WY7nLePDkBjS63dtayublfn4Y5Z79M477Es8wJ/i8ePZEpSPD3D8ODB3LutYrsLTxQEPzWL10t7ZfQntneZflFAIFh3UDPMbBnuxPRqkDShu7L9OgSHzatJLGnA4twZ2YpHmxC8dLVQpxCekgXY+DbSVuzdlXs0AzS1HUxE+47l0iU1t+/iw+i8mll3RhE0n2b/NFxYP167wmKMj8OOPrLhaairLmRAYFeHTgzGL7qnR2N6JzzIaseje97Fz3q2Qi8QYd3QHHJISceKFt8ANUMjOUH4+XYILpY1wl9jjqXnxPR+srgZmzwa2bgUkEjY788QT2p989Ghg/37Az4/lnc2Z0126octdkyIxxMsZ5Q3t2HikQP8XZIEsOqhxtHPEcD82xW6MejX8LM21I0O6t6MawLyEQNiLRciqaFIWxjM0juNwboCZmoG2cvemzKvRYabG1jPzBaeaJGzMXShqrN6eCQUHLEwKwtgI7dqIAGCdxb/8kt1++222tVVgoymvRnccZ9yie2p8f7wITVIZQkL9cdX273D5z33IDY2DZ3szJrz+DC4OG4eiY2cEHUNTeyfe2slqxTw6Jw5+bip1wHJz2UzW8eOAtzdbTlqyRPeLjBjBdksFBrK+V7NnA1VVyoedHOzw1DxWm+rjA7m4YoPtEyw6qAGMl1eTX9OiTOa9f0a01s9r7Ry4yqOXiyMmdy1BbRdotqaisR3VTVLYiUV9p0S7aLv0xJsSNgUiiJBdm43K5kq1xyWFeMJOLEJVkxQVNLUvLDNKEj6cU4MD2dWwF4sGLjzWnxtvZLkHAHDXXUCJsHkCY7rq1dAOKB3k5wNlZaxWzIQJJhlCe6ccXxxmTR0fmMEKocYtmoHI3AtI/ecqtDpIkJhzFkHTUnDs3sfR0SrM76AP9+eiplmKKD9X3K2ab3n8OKtBk5sLREayvBh9ZrUSE1lgExzMGojOmgVUdKcuXD9qCIYHe6CpXYYPu5po2hKbCGoMkVfz6d+XoeBYe4NhQR5aP2/j2Y3K25qq7y7uyjUQKq/mXDGbpYkLcIOzY99ETW23cqvydvZGUkASAOBwkfodB86OdojvmtqnJSiBmcl2brmCw+t/sQDrzkkRiPQbZBHAt99m0+61tWyniExmwFH2xCcLny+hInxa45eexo4FXAw3e62LX86UoLqJFUJVbRZpL3HExI/eQP3xMzifNAmOchkmffUeyqKHI+vn7QYdQ2FtCzZ2VZh/YfFwONp3/WndupUFHTU17P/RsWOG+cAxbBhw8CAQGgpcvAjMmMEqEoNvn8Cu8c2xAhTX2Vb7BJsIavTNq6lqalc2JNO1ceXOvJ3K2/vz96s97qqEINiJRbhY3oiCmv6LLOljoPo02m7l7k3XejVnKagRlpnM1Px6thSZ5Y1wd7LHo7PjBn6COk5OLPfA3Z39Af3Pfww3yF74InxSmQKZVIRPO6asTwNAJldgw8HLAIAV0/svhBoyOgHJ5w7j9OqPUOfqicjKAgxbugjH5y9DQ7lharq8vi0THXIFpsX5dfcB/PhjNtvY1gYsXMhmVwzZvTwujgU24eEsl27GDGUPrOlD/ZXtE9baWPsEqwlqsmuz0S5TP62oT17NxiMF6JApMCbcC+MjvbV+XnNHc48/9l+c/ULtsT6ujpgcw8b4lwA1a5Q7n9RUEtZ2K3dv2ubVjOq6Ls3UCEguZ7/cAJPO1LR1yLG2K7fg4Vmx8NZ3l2BsbHcdktdf71mgzIBUi/BRsrCWTJxP89eFChTVtcLH1RG3jA9Xe5xILMbYZ/8Ju6wsnJh9AwAgZddP6Bw6DGf++5leicRHcmuw62Il7MQi/PvqBIg4jrX9eOgh1ml7+XLg99/ZlndDi45m9Wuiolh7kRkzgIICAFAu+W5NK7OpchoWH9QEuwXDz8UPCk6Bi9UX1R432LyaxvZOfHuMbZF9cGas9m3jAey9vBed8u7tqNtytqG8SX3AsjBJmF1QHMcNOFOjaz4Nj5+pSatIQ6NU/afbUWEsGEwvabDpwlCCKihg7QUkEtb3yUS+OMzKww/xcu6ZW6CPW25hDQw5Drj99h45BIZERfh0UFUFZHfNAkyZYvTLcxyHTw6wzRv3TI7sd1m9N8/QIEzYuwUXv/sNxf5h8Guuw5j/W4lzY2ei4kKOzmOQyRV45Q/2d+fOiRGI83IE7rwTePNNdsCrr7KAXMit7hERbMYmNpblOM2YAeTlIWmIJ67vWo5bvT3TZjZpWHxQIxKJuisLV6ivLDzYvBo+qz4uwA1z+GlFLf2V03PHhlwhx1dpX6k9fn5iIMQi4EJpo0HbyBfWtqKxXQZHezHig9z7PK7rVm5VQzyGINo7GgpOgWPFx9QeFxvgBhdHO7R0yJFbJcwOL5vH59PExwN2A/+CF0J1k1T5h+ZfC+LVl4cfjHffBZKT2R/T229nM1MGNpo6dmuPn6VJTGQlBIzswKVqZJY3wtXRDnepq1KtRsJt18E/LxOpt/8THWJ7jEo7BPexI5H6+EuQd2qft/XDSdbPzMvFAU+M82cVf7//ngUxX30FvPCCcXYhhoWxwCY+HigqYoFNTg6emhcPRzsxjubV4qCNtE+w+KAGAEYECJNXo5pVv3J6NMRi7X84OY7DX7l9t6F+duYztQnDvm4S5YySIZeg+L5LCcEe/a4567qVuzdt8mrsxCIkD6ElKEGZQT7Ne3svoaVDjpGhnrhmxOC616vl7Mzya1xcWCGyN97QeHhDu+5T7iPDPCGiInzaMfHSEx8835YSDi8X3Zc4ndxdMfHbj1C+/ygyY0bAtaMNE997BXmxI5C3+8iAz29o7cQ7Xfkqzye7wXPebJY34+7OShDcfbfOY9JLSAi7fkICSxqeMQNhVUXKgG/Ndtton2AdQQ2fLFylPqgBdM+r+fVsKaqbpAj2dMJ1XV1QtXW+8jxKGkvgZN9d+tpD4oH8+nzsuaw+J2CRAIX4+HyakWrq0wx26YmnbbLwqK4ts2nU3FIYJm6PkFvVhB9OsETF5xYN1+lDgNaGDQM++YTdfvll9ulUjd+zf1fevlilfmlalbuTg3KnHi1BDcCEScKnC+twIr8ODnYi3DdV+xIb/YmYPh7xWWdw/JnX0SRxwdCiTETMn45jy1agrV5965p3917CldZOLJBVYMnDS4GMDLbN+u+/gauu0mtMgxYUxAr0JSezBp8zZuDRQCk8nOyRVdGEX8+WmmZcRmRVQc25inMa1w11yauRKzh8+jfLqr9valT3Fj0t8UtPMyNnKu+7Lfk2AMCG0xvUPm9+YhDEIhaIGGornqZKwqpbuRfGDTKo6UoWPl5yHFKZVO1xo7qun0Z/LITBLz+ZaKaG/yR4VUIgUqJ9B37CYN11F3DPPSwJ89ZbWaXWfvyS+Yvy9pbMLVqfnl+Cono1GjQ3A2fPstsmqCTMz9LcNCYUQZ5qeibpQGxvh5Q1z0F6Lh1nJsyBPafApJ8+x5WYeKR/ubnP8blVTfjfsUJMKUjDh+sfh6isjC3DpaYCo0bpPR69BASwmcxRo4CqKngsmocXw1hu5zu7sq2+fYJVBDUJ/gkQi8SobatFRbP6BEJd8mp2ZVQgv6YFns4OuHWC+qx6dbblbAPQM0fl3lH3AmCfINUlDPu7SzAhii2TGaJzt0yuwIVSlsA7sp+dT/xWbndHd0wJG1yyX5xPHAJcAyCVS3Gq7JTa4/ht3dmVTQZpLkpUcJxJZ2qO5dViT2YV7MQiPLvQCEHVhx+y4K28nAU5vXav1LbWYn9BdwmFLVlbtE6U5Ivw0Q4oDVJTWU5TeDj7MqLsiibsyayCSMTSAgzJLz4aY47vQdqH36DC0x8hdeVIvu9mnJp2Neryu4s/vvpnJq49vwdf//wS7FuagZkz2XKckf9fqOXnB+zdC4wbB9TUYMm/7sbM5mKUNbTjq6MFph6doAQNalavXo3x48fD3d0dAQEBuP7665Gdbfg9884Ozhjqy0pDGyKvhuM4fNLVEuHuSRFwleiWuV7XVodjJSxpdn7MfOX9iQGJmBw2GTKFDBvTNqp7OhYrl6D03+GRW92Mtk453CT2iPbru6WQX3q6KuYqnbZyqxKJRFotQQV7OiHAXQK5gkNGme1sMTSK6mrgyhWWlDh0qFEvrVBweKOr0N7tKeGI8Rdg62pvrq7dnY137GBF+lT8mvUr5IruwPlS7SWkV6VrdWoqwqcFEy498e1qFiUFI1qgn7VRD90Jt9xspF5zBxQQYdzhbRAnJuDkf9ZhX2YFkr76EO9sWwd7uZzNFu7YwbpomxMfH2D3biAlBaK6Onz6zbMYUX4JH+237vYJggY1Bw8exEMPPYTU1FTs3r0bnZ2dmDdvHlpaDF9cTpsifIBKXk2++ryaY3m1OF/SACcH8aC2pO7M3QkFp0BSQBLCPMN6PLZyzEoAmhOG5ycFQSRiy2Sl9W06X1/V+a5KwklDPPrNcdA3n4anTVAjEomoY7dQ+FmayEiWUGtEv58rQ3ppA9wk9nhsjh6F9nSVnAx88AG7/fzzrPx8l80ZfZcM+ruvP9F+rvB0piJ8GpmoiWVxXSt+P1cGAHhwpm6FUHXl5ueNib//D7l/7EFeSCy82pow/uUnETt5NJ4+9D920DPPAN9+y8oomCMvL2DXLmDKFDg2NeCHzS8iLi8dH1lx+wRBg5odO3bgnnvuQWJiIkaOHImvvvoKRUVFOH36tMGvpdwBNUCyML/Wn1ZUr3ZtkZ+lWTYuDL5uuv+w8ktPi2L7thtYlrgMXk5eKKgvUJswHODuhPGRXUtQeiYMn9OQT6PPVu7e+LyaI0VHenxC7m0UBTXCMFF7hPZOOd7uKrT3z1kxg/r3opf77mOflOVyVsumthbVLdXYl7+vz6GbMjZptQQlEokwmpag1OvsZMtPgNFnaj47dBlyBYdpcX5IGtL/xgdDG3r1bITnXUDqA8+gzV6C8PoKyEVitK17D1izBhCbeRaHhwebSZoxA67tLfhm879xcdM2q22fYNR3o6GBzRr4qKlpIJVK0djY2ONLW9rO1ET6uiDQQ4IOuQJpxX1/YV0obcChnBrYiUVYMU339Vq5Qo4duTsAAIuHLu7zuLODM+4ccScAzQnDi5L4XlD6BTXnNXTm1ncrt6qRgSPh7uiOBmmDxml+Pqg5RzugDMtE27k3HilAaX0bQjyd8I8pUUa9NgC23LZhAys8VlwM3HsvtmT+Ajknx8igkcrDnOydkFuXi7SKNK1OS0X4NDhzhpX+9/ExahBd3STFppNsd53QszS9OThJMPGTNahLPY0T19yBy19tgvPjjxp1DHpxcwO2bQM3Zw7cOtrw+aYXsfXd70w9KkEYLahRKBR4/PHHMWXKFCQlJfV7zOrVq+Hp6an8CgsL6/e4/vC/wDKrM9EhV79eyPJq2GzNify+QQ2/Xnv1iGCE+ejeoO1E6QnUttXCU+KptofSyrFsCUpTwvDCrryaM0X1KG8Y3BKUVCZHVkVXknA/MzWGWnoCADuxnfL1HipUvwSV3BVcFde1obZZ/U4poiMTzNTUNkvxcdc09v/NN3ChPV24u7P8GkdH4I8/sHnHOwCAJcOXKA/hZyK1XYIaQzug1OOXnqZMMeosxVdH8yGVKTAyzAuThNxdp8GQsYmY8Pv/EHfXkoEPNjeurhD98QeaZsyBS6cUy1c/jGNLlqMmt8DUIzMoo/1EPvTQQ7hw4QJ+/PFHtcesWrUKDQ0Nyq/iruZc2gjzCIOnxBOdik5k1WRpPJYPak4W9MyrKaxtUc6M6Nq4kscvPc2PnQ97cf8JxkkBSQMmDAd6OGFcV8Li9kEmDGeWN6FTzsHbxQGh3j3zLAyxlbs3bfJqPJwcEOPPOjbTbI0BmWCm5oN9uWiSypAY4oHrdazjZHCjRwPr1qHSFTjQycrd3zDsBuXDNw67EYD2S1B8Eb6SK22oaqIifD2YoOheU3snvulqV/PPmTE6tashKpyd4b7jT2SOmwEnWQcm/fIF3IcNxfGFt6AsLdPUozMIowQ1Dz/8MP7880/s378foaHqlzkkEgk8PDx6fGlLtV2CtsnCfBIt79O/L0PBATPj/TE8WPtrq+Lr0yyO67v0pEqbhGG+EN9gt3ar1qfp/UvAEFu5e1NtbqnpDwffByqtmHZAGURzMyuNDhhtpuZydTO+TWV/ZJ4XqtCerh58EL/cPhoKMTCh2hGRIi/lQwviFsDFwQX59fk4XT5wTl+PInyF9QIN2AIpFCYJar47XoSmdhliA9xw1fBAo13XKjk5YdjxfUj7+BtkRSVBIu9Eyo5NCBiThJPTr0bh3ydNPUK9CBrUcByHhx9+GL/++iv27duHqChh19x1zasRdXR/AqtubMdPp1kdgsHO0pQ1leFsxVmIIBow8VY1YXh33u5+j1mYzPJqThVeQeUgSrZrqiRsiK3cvU0YMgGOdo6oaK5A3pU8tcfxHbspWdhA+M7cfn6Ar3Gm5d/ckQWZgsPsYQGYHOtnlGsOSCTCpvFsRnLZmQ7WJbmLi4MLrhl6DQBg04VNWp2OivD1IysLqK1lO+zGjDHKJVXb1TwwI8Y8AmgLJxKLMerBOxGfew4Z32/F+cQU2HMKjD+0DREzJuDs2Fm49GffZHtLIGhQ89BDD+Hbb7/F999/D3d3d1RUVKCiogJtbfptU1ZH26CGz6tZcby7yuj5l99Gh0yB0eFeSIkaXHO27TksUBg/ZDwCXDU3v1RNGP70zKf9HhPs6Ywx4V7gOGDHBd2XoDRVEjZkPg3Pyd4JE4ZMAKA5r4bf1n2uuN5mOscKyshF907k12FnRiXEImCVMQrtaamsqQyHSll9qKWX7IGtW3s8vixxGQBg88XNWv3c0Q6ofvD5NCkpLIfJCH45U4LqJilCPJ1w7UgD9xOzcSKxGIm3XosRF1KRs+0AzoyfDQVEGH3mAIZeMwfpCRNw4X+/glNYTr0mQYOaTz75BA0NDZg5cyaCg4OVX5s2afdJSVfaBjUAMF9RjZUnuoOa6Z+txciybDwwY/DrtXw+zUBLTzxtEob5JahtOu6CapHKlN2wR/SqJGzIrdy9aZNXMyzIA472YjS0daLQgN3IbZYR2yNwHIfXuwrt3TIhHHGBfbu+m8ovF38BBw6TQich/IW3+zy+MHYh3BzdUNRQhBOlJwY8H58sTEX4VBh56UkmV2DDQdauZsX0aJ3b1RDtxS2agTEn9qL40AmcnHENOsV2SM48iaS7bsSlmGSkffgNFDLzrwQv+PJTf1/33HOPINdLCmC7qsqby1HdoqHNulyO2e+8AAeVXBYHTo5P/3gTV/kPbgeHVCbF7stsGWlRXN/6NOrGO1DCML8L6mRBnU4JixdKG6Dg+Cq+PXujGHIrd2/aBDWO9mIkhrCcJVqCMgAjztT8eb4c54rr4epoh8fnGrHQnhY2ZbAPS8sSlwGPPQYsUvl32NYGZwdnXBt/bY9jNaEifP0wciXhvy5UoKiuFd4uDrh5vPa7YcngRUwdh/EHfkfN2Qs4vuhWtNs7Ir7gIkY9cjeKwmJx6vUPIJOab0Viqwp73RzdEOPN8mE0lkT/6CM4nT6JZsfuHUH5XkEIrK+C+M47WCEvHR0uOozmjmYEugZiTLD2a833j70fgPqE4SFezhgZxpagduqwBKWpPo0QS0+8yWGTIYIIuXW5Gvtw8VvMKagxACNt55bK5HhzB7vWAzNi+gTLplTSWIIjxUcAAEsTlrL6NevXdx/w+usAgGUJbAnqp4s/qU3Q54nF3UX4KK8GrA5QYSHbxj1xouCX4zhO2bjynslRcHHUrV0N0U/wiGFI2fY9mrNycGzZCjRJXBBZUYBxLzyKqpBIHP/X62hvMnx3AH1ZVVADaLEEVVgIPPccAGDnzd2JhK/e8jw4Z2dWUvrVV3W+rrKKcNwiiEXa/29dmrB0wIThxV0Jw7osQamrJCzEVm5Vnk6eyppBmvJq+D8WtK1bTzJZd6KwwMtP3xwtRMmVNgR6SLB8EIUphfRTxk8AgKnhUzHEo2t7uWqRz/feA06dwvzY+fCQeKCksQTHio8NeF4qwqeCX3oaPZrVBhLYwUvVyCxvhIujHe6eHCH49Uj//GLCMWnTp1DkFyD1vidxxcUTIXXlSHn7BTSHhCP1n6vQXGM+Qb/VBTUjA9kf1H6DGo4DHnwQaGkBpk6F/N57lQ9Nu34mRBu6Kvy+8gqwfbtO11UNanShTcLwwiS2BHUivw7VTdoVrOve+eTV434htnL3ps0SFD+ujLJGylfQR34+K1vv7Cxoh+ArLR34YB+r//LUvHg4O5qo0J4amy+yonr8TEwfHAfcdx+cFGJcF38de44Whfi6gxrz+aVtMkZeevq4a5bmtgnh8HIxTlIyUc8z2B8TP/8vnEqLkfr4S6jw9Idfcx0mfrIG8rBwHLvzYdQX6VcB3xCsLqjhZ2rOVZ7r++APP7BgxdER+OwzTI71Vz60dHwYcOedwAMPsF+Ad9wBFBRodc3culxcqr0Ee7E9roq+Sucx8wnDW7O29pswHObjghGhnlBwwM6MgZegrrR0oKirr0dyr/4oQmzl7k2boCbC1wVeLg7okCmUVY/JIPD5NPHxglZ3/WBfLhrbZRgW5I6bxhg2D0tfhfWFSC1JhQgiLElQU+nVxwc4fx546y3cnHgzAO2WoKgInwojNrE8XViHE/l1cLATmd2soK1z9nLHxHUvw6esCCdeXIti/zB4tjdj0rcfwTE2GqnX342qTPUlPYRmtUFNRlUGZApZ9wM1NSx5EABefBEYNgyhKm0Q3CRd67XvvguMGwfU1QFLlwLSgWdG+IJ7U8OnwtNJ9yZrfMKwnJOrTRjWpRDf+VI2SxPp6wJPl56Bi5D5NDy+CN+5inNoaO+/wJ5IJFLO1pyjvJrBM0I+TWFtC/6XWgAAeH7xcNiZWZ2Qny6ypafpEdMR7B7c/0Fvd+2GevVVXNUxBJ4ST5Q3l+Nw0WGN53Z3csDQACrChytXgAsX2G0jBDV8Ls2No0MR5Gk+uVukm6OLEya88hRCSi/jzNpPkRsaB5fOdkzc+g28kobh1HV3mmRcVhfURHlHwdXBFVK5FDm1Od0PPPUUC2ySkoB//Uv9CSQS4Oef2Se7U6eAxx8f8JraVhHWZKCE4UVdS1DH8moH7Jl0vitI6J1PI+RWblVBbkGI9YkFB06ZvNkfvl7NWQpqBs8I7RHe2pGNTjmH6UP9MS3Of+AnGBm/jMTPwPRr2TJg8WKgowOOKx7EDfHX93iuJmMivADYeLLwka5/x0OHAoHCVvTNrmjCnswqiETA/TNolsbc2TnYY8xTKxBTmIXzn/2Ai3Gj4KiQYdyB300yHqsLasQiMZIDkwGo5NXs2gV88w3bEfH55wMXjYqIAL77rnsHxTffqD20paMFBwoOANAvqBkoYTjc1wVJQzyg4IBdFys1nuucmp1PQm7l7k25BKUhWZivLEwzNXoQeDv32aIr2JZeDrEIeG6R+RTa4+VfycfJspMQi8S4cfiN6g/k/y27uwOpqbg5j336//niz5ArNO92HE15NUZdeuKbCi9MCkK0v5vg1yOGIRKLMWL5LUi4dBaZm7chPSnFJOOwuqAGAEYEqOyAamkB7mezIHj0UVYJUxsLFgD//je7/cADQHr/W8T35u+FVC5FpFckhvkN/pe+s4Mz7hpxF4CBE4b/GmAXFF9JmJ8J4Rlj6YmnS7JwXnULGts7BR+T1eE4wQvvvdW1hXvp2DAMCxpcPzQh8TMtMyNnItBtgBmE0FDlMtSc/3wDH0cvVLZU4u/CvzU+TbUIX6fcRpPajVR0r7iuFb+fKwMAPDgjVtBrEeEMX7oIyUd2meTa1hnU8Nu6q86zwKSggO0Mee013U704ovAvHlAWxtw001AQ9/8ENWlJ307xw6UMMzn1RzNq8WVlv6LH1U2tqOqSQqxCMoCd4ABt3J//TXbRjwAPq/mZNlJtMv6T7D0dZMgzIfVCurdXJRoobKS/UyKxUCcMIXw0oob4OxghyfnDRXk/Pridz1pXHpStWIFMGMGHJrbcGMhy6kbaAnK5ovwtbUBJ7uaHAoc1Hx+6DLkCg7T4vyQ3E+NLUIGYt1BTdEplvgLsKlnNx2nMu3s2DJUWBiQkwPcey/7dNyF4zidWyNokhiQiClhU9QmDEf5uWJ4sAfkCg67Lva/C4pfyhka6N6jWJVeW7n3qTQ2e+ghIDER2LSJdexVI8Y7BsFuweiQd2gsSa9MFqZ6NbrLzmb/jYoCnIRLplw5PRqBHuaXrJlbl4sz5WdgJ7LTvPSkSixmS9BOTli2m80I/JL5S89NBX2e0l2E70yhDS5BnTjBygYEBQHRwuW41DRL8ePJYgDAg4NsKkyIVQY1fE5NUXsF6h0VwG23AQsHOTvh58cShx0cgF9/Bf77X+VD6VXpKGksgbO9M2ZGzjTAyLtna9QlDPOF+P5K7z+oUVdJmF96mhs9V7et3BUVwPLl3d/7+rJib7fcAowdC/z1V49AjycSiZSzNZrzarwAUGXhQeGDGgPn0zSpLAX6uTti5XTzTNbkZ1jmRM+Bn4sOncJjY4FXX8WsAsCvVYTq1mplXpw6o8NsuAif6tKTnrPRmnx1pABSmQIjw7wwKcY43eaJ9bHKoMbLyQvh8AIApMd5dM/WDNaECawiKQA8+yzwN1uD55eeZkfNhrODs7pn62SghGG+F9SR3BrUt/ZdglJXSZgPanQqDiiXs3o9VVXd9124APznPyzhMi2N7SiZNk35/0SVNnk1qkENdezWEV9J2EBBTVVTO97ckYU5/z2ovO/R2XFwlZhneXo+qFFbcE+Txx+H/djxuOki13Uuzb2g+B1QNpksbISie03tnfj6WAEANkuj71I+sV1WGdTg0iWMzGFr3+dWXgf4G2Ab6gMPALffzv7Q33wzUF4+6CrCmqgmDG84vaHP4zH+bhgW5A6ZgsPuXrugOI5DemnfSsKD3sq9Zg2wdy+rVstzd2d5Svn5wNNPs2WPI0eAGTNYcvXp08pD+aDmaPFRtTtMEkM8YScWobpJivIGGy9upit+pkbPJOG86mas2nIeU9fsxycH8tDU3r0Us2SseRXa42XXZONc5TnYi+1xw/AbdD+BvT3wxRdYlsV+Bf5y7kd0ytUnq48K87LNInxyOXD0KLstYFDz/fEiNLXLEOPvinkJwm4ZJ9bN+oIahQJYuRIjytnSzfkIiWHOKxIBGzawfJKKCly5/UYcLWb/2A2RT6OKX4L6Pft3jQnDvXdBFde1or61E452YsQHdfdmGdRW7kOHund/9TfT5esLvPUWkJfHWk/Y2wM7d7LChUuWAJmZSApIgqfEE00dTf1XeAbg7GiH+EA2VtrarSM9l5/OFF3B/f87hbnvHMQPJ4rRIVdgTLgXPrx1tPIYc/3EzM/SXBV9FXycfQY4Wo3kZMy47TkENAN18mbsO/eb2kNttgjfuXNAUxPg4QEkJwtyifZOOT4/nA+ANUoVm1lxR2JZrC+o+eIL4OBBjLjCatGcr9TQrVtXrq7AL78A7u7YWZ0KBadAon8iIrwM22xtoIThRV15NYdza9DQ1v3pMr2MzU4ND/GAo333W6vzVu6aGuDWW1mAeNddbIZKnZAQ4OOP2R/YO+9kwd8vvwBJSbD7x32Y4sc6lmvMq+lKwqS8Gh2VsURXXWZqFAoOezMrsWz9Mdz48VHszKgExwFzhwfi5wcmYcs/p2COBXxS3tS1XLQscRBLTyrsnnsBSypYvsym71ZpPFZZhK/Yhpag+HyayZPZxgkBbDlTiuomKUI8nXDdqCGCXIPYDusKasrK2JIIgBG3PQGAJfMO1N9FJ/HxwJdfYlvXDtpFnDC1FDQlDMcGuGNooBs65Rz2Z3Xnu1zg69OoJAnrvJWb44B77gFKS9lr/egj7QYcHc2KFJ4/D9xwAwuIvv4a0/7H8jMOXeq/AzkAjOpaKqOgZhACAwFv7wEP65Ap8NOpYsx/92/c9/UpnChgfXWWjQvFnien4/O7x2Fc5CBnPIwsoyoDGdUZcBA74Pph1+t3MokEy257HQDwq0MeOv7cqvZQvgjfWVuaqRE4n0au4LDhb1Zsb/m06B4fxggZDOv6CXrkEVa3Y/x4xD72HzjZO6G1sxWXr1w26GXkN96AHcksz2TxR7u6EzYNaMCE4a5CfKoNLi+Uspka1SRhnbdyr1sHbNvG2kVs3qz7NvikJGDLFuD4ceCqqzAtnwVkhy5sA7fqWdZTqxe+SGB6aQPkCkoW1skAszRN7Z347O/LmP7Wfjz983nkVDXDXWKP+2dE49C/ZuOtJSMRG+Cu8Rzmhu/1ND92PrycvPQ+39T5KxGscEW9M7DnjeVAY/+1aJRF+ErrbaMIH8cJXkn4r/RyFNa2wtvFAbdMCBPkGsS2WE9Q8+uv7I+pvT3w2Wewd5Ag0T8RgEq7BAM5WXYSNeI2eHbaYXJ2V2G+lhaDXmOghOHFI7oK8eXWKu+7WM4HNd0zNTpt5T5xAnjmGXb73XeBESMGO3y2Y2zXLozbuAMSuQhVrsClz95kMzqvvw40NysPjQ1wg6ujHVo75Mipahr8NW2Rmnyaqka2k2nymn14/a9MVDS2I8BdgmcXDsORVbOxauFwi2wUyHFc99LTYHY99cNObIclY1nzvU2BNcCq/pehov1c4eFkj/ZOGynCl5fHCjw6OrJ/zwbGcZyyceU9k6N61NUiZLCsI6ipr2dF4QDWrHLkSAAqRfgMHNRsu8R2Pc0buhAO/oFsm/ODD/Zbr0UfmhKG4wLcEOPvig6VT4ytHXK4ONohRqVfitb5NPX1bFeXTMa6k/OtJfQkmTMfKVFdW7snD2EzaS+8wIKb994D2tthJxYpq4dSsrCOes3U5FU349lfzmPqm907mWL8XfHWTSNw6JlZeGBGDDycdKhTZGYuVF1AVk0WJHYSXDfsOoOdd9koljf22zBAuuHjfksUsCJ8XfVqbKEIHz9LM368IMUdD16qxsXyRrg42uHuyYbNSyS2yzqCmmefBcrLWQfZF19U3i1UUPNXbldrhBFLgB9/ZFVK//c/4NP+ezYNlmrC8Jdnv+zxmEgkwuKuXVCqkoawLdJAz63cGvNpOI4V2CsoYNVpP/vMoEW2lEX47p0NfP89EBMDVFezDuhDhwJffIFRISwQS6N2CbrpmqlR3cn040m2k2lchDc+u2scdj8xA8vGh0FiL0yipzHxszQLYhfAQ2K4XlSTwyZjiPsQNDoBO2PB/j20tfU5bky4DRXhE3jpiZ+luW1COLxcBmgyTIiWLD+o+ftvttUaYEGFyicKIYKa8qZynCk/A6Cr5svMmcDq1ezBRx/t7pFiIJoShhf2E9SoJglrvZX7k0/YjiUHB9b+wNOwPVe6i/AdZruqMjPZezZkCFBcDCxfjkceuR6LMw/hXGHfnBui3mE73z47ma5KYDuZfn5wMq5KCLSaLbIcxym3cmvd60lLYpEYSxOWAgA2j3NmbVFefrnPcTZVhE/AJpanC6/geD5LVr9vWpTBz09sl2UvYra3swZ1ALByJSsAp4IPavKu5KG5oxlujvq3seeXc8aHjO/uCvz006xA1datrEbLmTOsjosBLE1Yisd2PIbChkLsztuN+bHzlY8NC3JHlJ8LilWOV00S1mrpKS0NeILtFMNbb7GpZgObHDYZYpEY+fX5KG0sxRCPIez9uvNOFlC98QZcCy7jo4I3kX7iFxSmbELE5DEGH4cxlNd3f7p/5ufzcHJxgb1YBDuxqOu/Ytjbsduq33c/3vc4dp8YdmIROttbledvc5Dgjl3lgEgEBzsRbhwdihXToywu8Vdb5yrPIacuB072Trh66NUGP//NSTfj3ePvYms80GYPOK9dy5Zix41THtO7CF+Au+XlJWmlooIFdiIR285tYPwszY2jQxHsaZhq7IQAlh7UvPYa23kUHAy8+Wafh/1c/BDiHoKypjKkV6ZjUtgkvS/ZbwNLkQj46iv2yy8vj7UW2LaNLUvpiU8Yfv/E+9hwekOPoEYkEmFeYiBUV//5SsJabeVuagKWLQM6OoBrrwUee0zv8fbHXeKO0UGjcbr8NA4VHcItSbewB5ydgSefBJYvB7duHdpWv4Xkily0zpyCky+uwfgXhRmPUHZmVOD/vu9u3vn7uTKIHQ37R0/R0V3NNtd7CNydHHD7xAjcOyXSLJtOGtKmC2zpaVHcIrhLDB+4pQxJQbhnOIoairDjnqm44fPDwH33AadOsVlMdBfhy65swtmiesxPDDL4OMwCP0uTlKRVyQBd5FQ2YU9mJUQiYOUM8+wrRiyX5QY15893BzIffQR4efV72IjAEShrKsP5yvN6BzUd8g7l9uo+rRG8vNgSzsSJwI4dLODiK/LqaeXYlXj/xPvKhOFg9+5lp3mJQXiBH4KLA8J82KeeAbdycxxLbs7JYV3IN24UtFndtPBpLKgpVAlqeB4eEL30ElpvvQv51y5FYvZpjP/34zi5bx8St3wDF2/DLocZWnunHKv/ysTXxwqh6OguhvjMgnjYSZwhV3CQyTnIFQrIFBzkCg6dvb7v+V9F1+Pd38vkHORyBcKyTuHdrvM7Jw7D0VWz4W7Bib/a4jgOmy8Ks/TEE4lEWJqwFP899l9snumPG3717f4988ILyuNGh3shu7IJZ4quWH9QI8DS0xeHWPXghUlBPTY1EGIIlhnUyOUskU8mY4XeblDf+2VEwAjsyN1hkLyaw0WH0dTRhADXAIwNGdv3gJEjgfXrWfG6l18GUlIMkmTHJwwfKT6CL89+ieenP698bHhQd7Jk4hBPZVn7Abdyf/UV8N13rEroDz8APsIWXpsWMQ3vHn9XY3NLv6FR8E5PxbHlT2HC/z7E+AO/o3D4SCh++AFRs/SfZRNCblUzHvnhrHKL7z+mRuI/69hj90yJgqurq/4XaW9nCekffICWM2eUQU3sbTfA1QYCGgA4XX4al69chouDi8Hbkqi6OfFm/PfYf/FH4S60vvsBXO78B/Dqq8CNNwIJCQBYsvCPJ4utuwifgEX3/kwvB+wleGBGjMHPTYhlJgp/8AFLyPXwAD78UOOhymThKv2DGn4r98LYhRCL1Pyvu/tulufDccBtt7FEWAO4fyzbYt07YVi1N8/UmO48Ho35NBcvdm+Bf+01YIoWRfn0NDWcBXcXqi7gSpv6JEs7B3tM+vo9ZP1vC6rdfRBRWYjgeTNx4vk3wSnMp+AZx3H46VQxrvngMDLLG+Hr6oiN947H0/P1ay7ZQ0kJ8PzzbCbt3ntZrpajyi6RW2813LXMHJ8gfPXQq+HqaIBAUY1xIeMQ5RWFls4W/DXajXWh7+hgy1By1pSVTxa22iJ8jY0s1w4QZOeTXMFhaqxfj/w/QgzF8oKaggL2ix4A3n6b9R7SQHUHFKdnHZl+82n68/77wJgxrHruHXfodU3ekoQl8HLyQmFDIXbl7er3mDsnRQIYYCt3ayvLo2lrA+bNY3V9jCDANQDxvvHgwOFI8ZEBj0+8/TrYnUvD+aRJcJJ1YMIbz+L0tMVoqqod8LlCa5bK8MSmNDz983m0dcoxOcYX2x+bhlnxAfqfnK/iumwZEBkJvPEG68UVFsZ22QlQvdrcqe56MlTBPXVEIpGyn9Tmiz+xmVd3dyA1VfkBKtrPzbqL8KWmsjYnkZFAqDBd2v85k2ZpiDAsK6jhOOCBB9gf5unT2RLUAOL94uEgdkCjtBFFDUWDvnReXR6ya7NhJ7LDvJh5mg92cgJ+/pkl2J0+PehrqlKtMPzp6f7r4fD1aTRu5X7sMSAjAwgKYr2aDJDMrC3l1m4NzS1V+USFIensIaTe/y/IRGKMO7oDDQkjkbvjoJDD1Ci9pAFXv38Iv6WVwU4swtPz4/G/+1IQoG+Sblsb8OWXLBiePh346Sc2MzBjBvtZunyZ1WPy8zPMC7EgJ0pPoLChEK4Ortr1L9MTH9T8eelPNAd4sQ9PAPDcc0B+vvUX4RNg6Umh0v4keYgHJsUYZncoIb1ZVlDz3XfAzp2sL9Gnn2r1B9nRzhHD/VmBMn3yav7KYQX3poZPhaeTFomrUVGsIJ+qzs7+j9WSpgrDqtQuPX3/PfD55ywh+LvvWDNEI1IW4dOQV9Ob2N4OE9e/idyft6HCKwChtaUIv3oujj/5H6MuR3Echy8O5+PGT46goLYVQ7ycsWnlRDw0K1YZTA5KUREryx8WxpY40tJYULx8OXDuHHDgAGvDYW+Z6W+GwM/SXBt/LVwcXAS/3uig0YjxjkGbrI0tOa9YwYLL1lZWioDjlEX4zlpjBWwDBjXZFU1Ysz0Lc985oLxvxbSYHsvmhBiS5QQ1fAVagO0qio/X+qmGKMKnrCKsS5Li4sU9l3fGjWNNIgf5x1hThWGe2q3cOTndrQ9efBGYPXtQY9AHP1NzquwUWjtbBzi6p2E3LoBz+jmcHTMDjnIZUta9jLQJc9BQWjXwk/VU19KB5V+fwqt/XkSnnMP8xED89ei0wXe15jjg4EEWrERFAWvWALW1QEQE22lTUsKqOuvTe8tKKDiFctcTP4MiNJFIpNxhtSljE/vw9PnnLNjcswfYuNF6i/BJpawZLTDofJryhjZsOJiHhe8dwvx3/8b6g3kob5AqH58z3ADLtISoYTlBzZNPsl/8ycms2J0ORgTolyzc0tGC/fn7AQCLh+q480JlKyjy8lh/pQkT2C/HQVCXMMzrdyu3VMqu29zMPnEaaKu5riK9IjHEfQg6FZ3KnB9deIYGYdTJfUh97N/oENtj9OkDaEkeieytfbuYG8qxvFosfO9v7M2qgqO9GK9en4T1d4yFp8sgdh21trJgZeRIVol6yxYW4M6axRqy5uWxINhAhRutQWpJKkoaS+Du6M4qeBsJH0D9lfMXmqRNQGws2wUFAE8+iVF2rRCJgOK6NlQ3STWcycKkpbHddn5+A3aAV9XY3onNJ4tx66epmLxmH1Zvz0JmeSMc7ES4KiEQ7948SnmstVS4JubJMoKa/fuBb7/t/sTkoNsfFH1navbl74NULkWEZwSG+/XfFVkt1SWyVasANzeWZ3PVVezr1CmdTrckYQm8nbzVJgz3u5X76aeBs2fZLyp+G7cJiESiQS1B9TiHWIyJ7/4Hhb/vQqlPMEKuVCD6xoVI/ecqKGRyg41VJlfgnd2XcNvnqahslCLG3xVbH5qCOydG6D51XlDAgpXQULZ8kZ7OCg/efz+7vW8fcP31JntfzBm/9HTdsOvgZG+84oIjAkdgqO9QSOVS/HHpD3bn44+zitsNDXB/8jHE+bNdWFY1W3P0KPvv1KkD1q2SyuTYmVGBf353GuNe24N//XIexy7XguOACZE+eP2GJJx8fi4+u2sc5idZaT0fYnYsI6jhl3Aee4zNcuhoZBDr2n2p9hLaOvs2qRsIn0+zOG6xfmvBzz/PPo0/+igLzPbsYb8kly3TeleLs4Mz7hqpPmG4Tz7Nr7+yLfAASwweMmTw4zeA7j5QgwtqeHGLZ8H94nmcTrkKDgo5Jn6yBuljp+NKYZneYyyrb8Ntnx3H+3tzwHHAzePC8McjUzE8WMcGigcOsBpKMTEs2fTKFbbctHYtUFrKdtYkJek9Xmul4BT46eJPAITf9dRbnyUogOU1ffEF++/Wrbi7lH0gsaqg5kjXzkQ1S08KBYcT+XVYtSUdE17fi/v/dxp/pVegQ6ZAXIAbnp4fj0P/moXND0zC7SkR1KiSGJ1lBDWlpWx7IT/9q6NA10D4u/hDwSmQUZ2h03M5jlNu5e5TRXgwAgKA994DsrNZ7yORiO10SUhgn9zLBv6jrC5huM9W7oIC4B//YA/+61/AQuF3jgxkesR0AMCx4mOQKWR6ncsj0A9jju7A8Wdeh9TOASPPH0XniJG4uGnboM+5+2IlFr1/CCcK6uAmscf7t47Gm0tGwMVRi0RdjmNBK+/qq4HffmNLTHPnst5gOTnAU08ZvPS8NTpSdARlTWXwlHgOvONQAPwS1I7cHWho7+oen5zMdkEBuOmrN+HV1mhdRfhSU9l/eyUJX6pswls7sjDtrf1YtuEYfjhRhIa2TgR6SLBiWhS2PToVu56YjodmxSLMR/hkbkLUsYygBmCfagdZnVUkEg16CSqjOgPFjcVwsnfCrKhZg7p+v6Ki2MxJWhpLKJbL2Y6u2Fi2THVF/ae/BP8ETA2fCjknx//Ode+w2nt5b/dWbudA4JZbgPp61rrhtdcMN3Y9JPgnwNvJGy2dLThbflbv84nEYqSseQ6lOw+gyD8MAY01iL/1Why770nIO7UPmto75Xj59wys+OYU6ls7MTLUE9senYprR2qogySXsx1KH3zAZtuGDGH5MjwXF9aKIiMD2L2b9deiJSat8TMk1w+7HhJ7idGvnxSQhAT/BHTIO7A1e2v3A889ByQmwqmuBi/u/cy6ivDV17Of29GjUdHQjk//zsOi9w5h3rq/8fGBPJTWt8FNYo+lY0Px3fIUHH12Dp5fnIDEEE/a0UTMgmUENTfdBMyfP/BxGgw2qOGrCM+Omi3MdtIRI4A//wT+/pt1w21rY7thYmJY1+y2/pfLVo5hszUb0zYq79t9mSXMLoxdyJa6jh9nPal+/FHnPCShiEViZXVhfZegVEXPmQzfzPM4Of1q2HEKTPpyHS6OnIya3IIBn5tX3YwbPz6Kr46yY1dOj8ZPD0xGhG+vIFoqZdPza9awQNTXFxg1ii0n/vQTUF7ec+v1pUvAxx8ry+sT7ckVcvx88WcAwvV60ga/7MXn9gBgJSW++AKcWIybMvZjYtYJZJU3mWiEhleZMAq3f30ak9bsxRt/ZeFieSPsxSLMHR6ID28bjVMvzMXbS0diSqyffuUMCBGAZRS/ePllvU8x6KCGX3qKNcDSkybTprEmcn/8wT4JZmQAzzzDqhO//DLrJ6XyB3NJwhI8tuMxFDd2t2HYc5ntqFpY6w28vYrd+eWXbKuwGZkWPg1/XPoDh4oO4clJTxrsvK6+Xhh/8A+c/M86JL6+CsmZJ1EzegzSP/gMyffc1O9zfjldghe3XkBrhxy+ro5Yu2xkd2XgpiaWOHnoEPs6cYLtDFHl5saC0WnT2FdiIuDvzx5T02SVDOxQ0SFUtlTC28kbc6LnmGwcyxKX4eWDL2NX3i5cabsCb+euZcOUFIgefxx45x28vvMjHMy8EcmhyYKPR6Hg0CFXoFPOmp529rrdIWPfyxQcOmWKrmP7HscfK1NwaG5q7nGNHyQROJLLKnePi/DG9aOHYHFyMLxdKT+GmD/LCGoMsMW1d7sEbaZKr7RdwdFithtA563cgyESsSWKxYvZbq9//5sVZ1uxgiWXvv46a6wnEikTht879J7y6TWtNXB3dcOUR7sqoD7yiMZmn6bC74A6XHRY6/dCF+NfegKFc6ZBsXQZoiry4XPvUhzb/QDGf/ku7CXsF3OzVIYXf7uAX8+WAgAmx/jivdkh8D93GFjfFcScPdu3ppC/f3cAM20aW25SnZ1paTHoa7FVmy6wpacbht0ARzvT/TEd7j8cyQHJSK9Kx29Zv+He0fd2P/jKK6j/4ScMKS/GbfO6awop0P3zzKn8bKs2aeHv51SOVb3J388fJxeJUeHuh2LPQBR7BaLYMxAlnoHK7+ud3AfcraSOoqNnoF6SNBb/N28orhs1hPJjTOhI0RHMG278XDJLZxlBjQEk+CdALBKjtq0W5c3lCHHX3DMKYO0G5JwcCf4JiPSKFH6QPDs71hjz5puBTz5hwUx2NrBkCdsttWYNMHs2Vo5d2SOoAYC5pRI4VNeycvt8eXczMyZ4DJztnVHTWoOsmixlxWdDipg6Du3Z53F8yb1I2f0zJn3/CS6eOAq/rT+jytMfD393GrLL+VhSehH3KkqQ8Ns5iFZm9z1RVFTPIGbo0EH/8SDakSlk+CXzFwDAzUmmW3riLUtchvSqdGy+uLlnUOPqioYP18Nl2XVwlHfnb4lVwxd1/eYG0YYupq4EMXUl/T7W7OiCMu8glPsEocInGFV+waj2C0Gtfwhq/IeAc3GFg70IDnbirq/u21xnO97hhyUW4+23V0Lk7q77AIneVHMkF3+/GF8s+UK525Vox2aCGid7J8T7xiOzJhPnK89rFdQYbelJHScn4IknWPn8tWuBd95h3cnnzAHmzUPCmjWYFDYJx3BM+ZSFqbWsAd+mTWzt3ww52jliYuhE7C/Yj0NFhwQJagDAycMNKbt+wqk3P8Gwf/8fEnLP4cq4sSiMHIkfii8iuLmf5pjJyd0BzNSpgjX0I+odKDiA6tZq+Dr7YlakAZPzB2lZ4jK8uP9F7Lm8B7WttfB16Z45jrhxEdqqa1Fbz3ZHcQrVgKZrlk/lPtWmulyP+xU9ntJ1Z/fNDimcykrhWFwIh6JC2BUWQFxYAFF+PlBRAbeOVgytvIyhlZf7fxH+/ixAj4piO0n521FRaPELVwY1olGjKKAxAQWnwAv7XsDqfauV98kUMtz9293Iqc3Bf2b9B2KRZaTAmprNBDUAW4Lig5qBqpMqOIWy5otRlp408fAAXnkFeOghtotpwwZg1y5g1y78495xKiENsDAX3buozNi08GnKoIbfoi6Ucc88iJJZU1Bx01LEllzC4kyWoMzZ20M0blx3EDNlCuAzyNYHxGD4pNybht/UXUDShIb6DsWooFFIq0jDr1m/YvmYno10nb094OytYw2jwRirJmenrY2Vb8jP7/+rvp61mamuZnlhmkyZYuhRkwG0dbbh7t/uVtZk4v3fpP/D2tNr8dqh15BTl4Ovrv/KqAUoLZXNBTWbMjbhXOW5AY89WXoSNa018JB4dLcbMLXAQLZ9+IknWP+m77/H9d+cwoquhxOrgNCbV7Ct3GZOWVlYy47d+gqdMALSrLM4vGoNfDpbMXzpIogmTmTbV4nZ6JR3YkvmFgDG6/WkjWUJy5BWkYbNGZv7BDUm5+wMDB/OvvpTX8+CG3WBj+oOy3mUw2FMlc2VuO7H63C89DgcxA746JqPsPIN9iHv5VkvIzE0ESv/WIlNGZtQ1FCErbdshb+rv4lHbd5saj5rZCCrIaLNDii+ivC8mHlm8Wmxh+ho1u7g7Fk4z75Kefe1dX7Au++ablw6mBg6EXYiOxQ2FKKoocgo15S4umDq+68g4ZO1EM2eTQGNGdqXvw+1bbXwd/HHjMgZph6OEh9g7cvfh+qWahOPRkdeXsDo0WzTwJNPsg9Gf/7Jdli2tPQsGDnL9Mt9tiKjKgMTv5iI46XH4e3kjd137sZtybf1OOaeUfdg15274OXkhWMlx5DyeQoyqzNNNGLLYFNBDb8DKqsmC1KZ5iZ0fD6NTl25jW3UKNYGocvTL++2mD/Ubo5uGBM8BoDxZmuI+eOXnpYkLIG92HwmkmN8YjA2eCzknFw5k2QVRCI2A0yManfebkz+cjIK6gsQ6xOL1OWpaoP4mZEzkXpfKmK8Y5Bfn49JX0zC3st7jTxiy2FTQU2oRyi8nLwgU8iQVZOl9rjypnKcLj8NAEbtDKwvx+g4Uw9BJ4bqA0WsQ4e8A79msSDdnJaeeH16QREyCJ+d/gwLv1uIRmkjpoVPQ+p9qRjqO1Tjc+L94pG6PBVTwqagQdqABd8twBdnvjDSiC2LTQU12rZL2JG7AwAwLmQcgtyou6xQ+D5QFNQQgBWPvNJ+BUFuQcqA15wsTVwKADhYeBAVzRUmHg2xNApOgad3PY2Vf66EnJPjjhF3YPedu3vsptPEz8UPe+/ai9uSb4NMIcPyP5bj2T3PQsFZSYsOA7GpoAYARgQMHNSYfCu3jeDbJVysvoja1n62V1sYuUKOnzK6dzAUXCkw3WAskHLpafgS2InNr0dWpFckJgyZAAWnsK4lKCK41s5WLNm8BGuPrQUAvDLzFXxz/Tc69zST2Evw7Q3f4qUZLwEA3jzyJpb9tAytna0GH7Olsr2ghp+pqeo/qOmQd2BX3i4AZrCV28r5uvgiwZ/1RTpcdNjEoxk8mUKG785/h6RPknDv1u7ibMnrk3HT5puUlZOJelKZFL9l/QbAPJeeeLQERXRV3lSOGV/NwK9Zv8LRzhHf3/g9Xpzx4qArqYtEIrw882V8e8O3cLRzxC+Zv2DW17No9rCL7QY1amZqjhQdQVNHE/xd/DEuZJwxh2aTLDmvRqaQ4Ztz3yDhowTc8esdyKrJgpeTl/JxjuOwJXMLpm2chgmfT8B3579Dh7zDdAM2Y7vydqFB2oAQ9xBMCTeTEgr9WJKwBABLbi9rKjPxaIi5O195Himfp+BU2Sn4ufhh3137cGvyrQY59+0jbseeO/fA19kXJ0pPIOXzFFyoumCQc1symwtqEgMSIYIIFc0VqGqp6vM4v/S0MG4hVXA0AksMajrlnfjy7JeI/zCeVfysy4Gvsy/emP0GLj50UXncieUnsGLMCjjZO+FU2Snc8esdiHovCqsPrbaK5TZD2nyRLT0tTVhq1v/uwj3DMSl0Ejhwyi7ihPRne852TPlyCoobixHvG4/U+1INHrBPi5iG1OUs0biooQiTv5iMnbk7DXoNS2O+vz0E4ubohhifGACsTkBvfH0as97KbUX4Inxnys+gpcO8m0F2yDvw2enPMPTDobjv9/tw+cpl+Ln44c25byL/sXysmrYKHpLuyrIJAQn49JpPUfR4EV6d9SqC3IJQ1lSG5/Y9h7B1YXjgzwc07sKzFe2ydmzN2grAvJeeePwSFJ8DREhvH534CFf/cDWaO5oxK3IWjt13TPl3x9BifWJx7L5jmBk5E00dTVj8/WKsP7VekGtZApsLaoDuJaj0qvQe9+dfyUdmTSbsRHaYF0OVNY0h3DMc4Z7hkClkSC1JNfVw+iWVSbH+1HrEfRCHlX+uREF9AQJcA7D2qrUoeKwA/5ryL7hL1PfL8Xf1xwvTX0DBYwX45vpvMDpoNNpkbdhwegOGfzQci75bhF15u2w272ZH7g40dTQhzCMME0Mnmno4A1qSsAQiiHCk+AhKGvtvMElsk1whx+M7HsfD2x+GglPg3lH3YscdO+Dt7C3odX2cfbDzjp24e+TdkHNyPLjtQTy18ynIFXJBr2uObDKo4SsL915/5JeepoRP6ZEbQYRlrktQ7bJ2fHTiI8R+EIsHtz2IooYiBLkFYd38dch/LB9PTX4Kro6uWp9PYi/BnSPvxOmVp3Hg7gO4Lv46iCDC9tztmP/tfCR/kozPz3yOts62gU9mRfikW3NfeuIN8Rii3LmnutuN2LbmjmbcsOkGvHf8PQDAG7PfwBfXfgFHO0ejXN/RzhEbr9uI12a9BgB4J/Ud3LT5JrOfATc08/8NIgB+pqZ3UENLT6ZhbkFNW2cb3j/+PmLej8HD2x9GSWMJQtxD8P6C93H50ct4fOLjcHEYfOVmkUiEGZEz8Nstv+HSI5fw6IRH4ebohozqDKz4YwXC3w3Hi/teRHlTuQFflXlq7WzFH9l/AABuTrrZxKPRHr9MxucCEdtW0liCaRun4Y9Lf8DJ3gmbl2zGqmmrBr3DabBEIhGen/48frzpR0jsJNiavRXTv5puU0ntNh3UZNZ099Bo7WzF/oL9AIBFcVSfxpj4vJpjxcdMujuotbMV646tQ/T70Xhsx2MoaypDqEcoPlr0EfIezcMjKY/A2cHZoNeM9YnFewvfQ/ETxVh71VqEe4ajprUGrx16DRHvRuDu3+5GWkWaQa9pTrbnbEdLZwsiPCMwPmS8qYejtZuG3wQRREgtSUVhfaGph6MXW132NJSz5WeR8nkK0irSEOAagP1371cWajSVm5Nuxv6798PfxR9nys8g5fMUnKsYuJGzNRA8qPnoo48QGRkJJycnpKSk4MSJE0JfckCRXpFwc3RDp7xTed/BgoNol7Uj3DMcif6JJhyd7RnuNxy+zr5ok7XhTPkZo1+/paMFa4+uRdR7UXhy15OoaK5AuGc41i9ej9xHcvHP8f+Ek72ToGPwcvLCU5OfQt6jefhp6U+YHDYZnYpOfHPuG4zeMBozv5qJrVlbrW6NnF96Wpa4zOifavUR7B6s7NXz00XLWIKqba3FseJj+ObcN3hh3wtY9tMyjN4wGoFru3s/nSg1/e9nS/JH9h+YtnEayprKkOCfgOPLj5tNXtiksElIXZ6K4X7DUdJYgqkbp2LbpW2mHpbgBO0Yt2nTJjz55JNYv349UlJS8O6772L+/PnIzs5GQECAkJfWSCwSIzkgGceajynv25nHtsEtjltsUb9crYFIJMLU8KnYmr0VhwoPGe2XQpO0CR+f/Bhrj61FTWsNACDKKwrPT3sed46802hr4arsxfZYkrAESxKW4ETpCaxLXYefMn7CwcKDOFh4EFEuUUYfk1BaOlrw56U/AXTvKLIkyxKW4UDBAWzO2Iz/m/x/ph4OAJbXkVObg0u1l3Cp9hJy6rpvX2m/0v+Tuj/b4bes3zBrKHXqHgjHcXjv+Ht4cueT4MDhquirsHnpZrPLxYz2jsbR+45iyeYl2Ju/F9f+eC3enf8uHkl5xNRDE4ygQc0777yDFStW4N57WZXV9evXY9u2bfjyyy/x7LPPCnnpAY0IHIFjl7uDGr7fEy09mcb0iOksqCk6hKenPC3otRqljfjwxIf477H/oq6tDgAQ4x2DF6a/gNuTb4eDnYOg19fWhCET8MNNP+CtuW/ho5MfYcPpDcivz1c+/nfh31iYsNCEI9TPn5f+RJusDdHe0cqO7ZbkpoSb8PD2h3Gy7CQuX7mMaO9oo1xXKpMi70oeC1r4AKaO3S5v1pyHFeoRiqG+QxHnE6f8b6hTKMa8wf7/Hyw8aIyXYNFkChke2/4YPj71MQBg5ZiV+HDRh2bze6M3LycvbL99O/657Z/4/OzneHTHo8ipy8G6+evMsh2JvgQLajo6OnD69GmsWrVKeZ9YLMbcuXNx7Nixfp8jlUohlUqV3zc2NgIA0tPTUV5u2KRJrytegMopS7JL4OjsCO96b5w5Y7glkLa27p0saWlpcHY2bE6G0Oc31jX8G/yBMmBfzT7cVnubwc/Pk8qk2HV5F5qlzQCAcK9wLB+9HPNj58NeYY/0c+kDnEEzof5fLfNZhmtmXoNf0n/BOqwDAHy49UMEtgcO8EzdGeP9BoANuzYAZcCMwBk4e/aswc9vjNcxFmNxsuwkbvvwNkGDmg5ZB0qbS1FYXzhgArmXkxcivCJYuQSPcIR7hSPCMwKhnqFwtu/1/6AFaK3p7ht07uw57D+6H55OngYdv7F+pn7L/A25V3IFOTcvqyYLZ8vZz+vjEx/HHSF36P17gyfk/6cHhjwAlxoXvH/8fXzw2wc4cvwI4v3iDXb+3jrbOgc+SAicQEpLSzkA3NGjR3vc//TTT3MTJkzo9zkvvfQSB4C+6Iu+6Iu+6Iu+rOCroaFBqDCjX4IuP+lq1apVePLJJ5XfNzY2IiwsDDt37oSfn59Br9UkbcLMz2YCG7vuuBf418x/GXxbaVtbG6ZOZTUtDh8+LMhMjZDnN9Y1AFZV+Fhx/7N4hjTMbxhmRs4UZOrVmO+300onHFp5yOC1XYzxfhc3FOP6H6+Hg50DjvzjiEW+FwBbitiUsQn1bfUGP7cqsUiMEPcQhHuGI8IrAt5O3gbL/VP9/4R7gaUjl+LZaYZNDzDGe/F12tesFINPDGZEzDD4+Xl2IjvMjZmLWJ9Yg5/bWL9rc+tysSdvD+SccBsPOto68O2T3wp2fnUEC2r8/PxgZ2eHysrKHvdXVlYiKCio3+dIJBJIJH1bsScnJyM4ONjgYwz7OwzFKGbfBAP3X3O/waeQW1q6Cx+NGjUKrq7aF2szh/Mb6xoAMAZjsBzLBTm3sRjz/W73a4dfjB8ivSIFu4ZQ73dRVhEQAiQFJWH8OGG2chvr53bCuAmCnNdYVP8/IRhIt0/HmDGGzXEyxnvxTMYzQAjw6IJH8WjKowY/vzEY83ftsrnCtiRpbGw0SVAj2JZuR0dHjB07Fnv37lXep1AosHfvXkyaNEmoy+okOTBZeXuo71CjJfoRYij99S+zBHzhy6SAJBOPhPSWVZNlccXa2jrbcKiQFe+8KvoqE4+GmJKgdWqefPJJfPbZZ/j666+RmZmJBx98EC0tLcrdUKaW5N/9C3VB7AITjoSQweldFdtSUFBjnkYFjQIA7MvfZ9qB6Ohw0WFI5VIMcR+CYX7DTD0cYkKC5tTcfPPNqK6uxr///W9UVFRg1KhR2LFjBwIDDb9jYzBUf6HOj5lvwpEQMjgXqi07qEkOSB7gSGJMMyNmIq0uDfvy9+GOEXeYejha2315NwDgqpirqM6YjRO8ovDDDz+MwsJCSKVSHD9+HCkpKUJfUmuqtTEmhZnHkhghurDE5acOeQeya7MB0EyNuZkZORMAsDd/r0W1T1AGNbT0ZPNssvcTL9I7UnnbFNVjCdHXxeqLFtc64VLtJcgUMnhIPBDqEWrq4RAVk8ImwUHsgKKGIly+ctnUw9FKVUuVsj/a3Oi5ph0MMTmbDmoIsWRO9k6Qyll1WUuimk9DSwXmxdXRVdmmxFLyavZeZptRRgaORICr6drvEPNAQQ0hFopPiLS0JShlUONPS0/maHbUbABsCcoS0NITUUVBDSEWKsE/AYDl7YCinU/mbU7UHABspsbc82o4juuRJEwIBTWEWKhE/0QAlrcDioIa85YSmgJne2dUt1Yjo9q8ZwGza7NR0lgCiZ0E08KnmXo4xAxQUEOIheJnaixp+amlo0WZgEpBjXlytHPEtAgWIPD5KuZqdx6bpZkaPhXODsK0FCCWhYIaQizUcL/hANin1Q55h4lHo52L1RfBgUOAawD8Xf1NPRyihnIJqsC8k4Upn4b0RkENIRZqiMcQeEg8IFPIcKn2kqmHoxVaerIMfLLwgYIDkClkJh5N/zrlnThQcAAA5dOQbhTUEGKhRCKRMjiwlCUo2vlkGUYHjYaXkxcapY04U37G1MPp1/HS42jqaIKfi5+yvQMhFNQQYsGUycIWsgOKT2pWbSZLzI+d2E5ZXdhc69Xw+TRzouZALKI/ZYShnwRCLBg/U2MpO6Bo+clyzI5kS1BmG9RQPg3pBwU1hFgwZVBjATM1dW11KGsqA9C9c4uYrznRLFn4cNFhSGVSE4+mp4b2BpwoPQGA8mlITxTUEGLB+OWnvLo8tHW2mXg0mvF5PxGeEfCQeJh4NGQgw/2GI9A1EG2yNqSWpJp6OD3sL9gPOSfHUN+hCPcMN/VwiBmhoIYQCxbgGgA/Fz9w4JBZk2nq4WhES0+WRSQSmW3LBD6fZm4UNbAkPVFQQ4gFU90BZe5LUBTUWB7VlgnmhFojEHUoqCHEwvFLUOa+rZtPZqagxnLwMzXHS4+juaPZxKNhCusLkVOXAzuRHWZFzjL1cIiZoaCGEAtnCTugOI6jmRoLFOUdhUivSMgUMhwqPGTq4QDonqWZMGQCPJ08TTwaYm4oqCHEwlnC8lNFcwXq2uogFokxzG+YqYdDdGBuS1C0lZtoQkENIRaOX34qaihCo7TRxKPpX3pVOgAgzicOTvZOJh4N0QW/BGUOfaAUnELZZJPyaUh/KKghxMJ5O3sjxD0EAGsYaY5o6cly8UHN2fKzqGurM+lYzpafRW1bLdwd3ZEyJMWkYyHmiYIaQqyAuS9BUVBjuYLcgpDgnwAOnLKBpKnwS08zI2fCwc7BpGMh5omCGkKsgLnvgOKDmuQA6vlkicylZQLl05CBUFBDiBUw5x1QCk6BjGoWbNFMjWXiWyaYsghfa2crDhcdBkD5NEQ9CmoIsQLmvPxUUF+A1s5WSOwkiPGJMfVwyCDMiJgBEUTIqslS9u8ytkOFh9Ah70CoRyjifeNNMgZi/iioIcQK8A0iK5orUNtaa+LR9MQHWsP9h8NebG/i0ZDB8Hb2xpjgMQBMtwSluvQkEolMMgZi/iioIcQKuDm6IdIrEgCUSz3mgpKErYOp69VQPg3RBgU1hFgJc12CUgY1/hTUWDLV5pYcxxn12pXNlThfeR5Ad34PIf2hoIYQK8EHDWYb1NBMjUWbGj4VDmIHFDUU4fKVy0a99p7LewAAo4JGIcA1wKjXJpaFghpCrERiQNe2bjNafuqUdyKrJgsABTWWztXRFRNDJwIw/hIULT0RbVFQQ4iVUF1+MvbygDqXai+hU9EJN0c3hHuGm3o4RE+maJnAcRwFNURrFNQQYiWG+Q2DWCRGXVsdKporTD0cAD2XnmjHiuVTTRY2VuCcWZOJsqYySOwkmBo+1SjXJJaLghpCrISTvRNifWIBmM8SFCUJW5eU0BQ42zujqqXKaD9ju/PYLM20iGlwdnA2yjWJ5aKghhArYm47oPgKx5RPYx0c7RwxLWIaAOPl1dDSE9EFBTWEWBFz2wGl7PkUSD2frAW/BGWMlgkd8g5lE00Kaog2KKghxIqY0w6o1s5W5NXlAaCZGmvCJwsfKDgAmUIm6LVSS1LR0tkCfxd/jAwaKei1iHWgoIYQK2JOO6AyqzPBgYO/iz/VFrEio4NGw8vJC43SRpwpPyPotfh8mjnRcyAW0Z8rMjD6KSHEisT5xMFB7IDmjmYUNRSZdCxUdM862YntMDNyJgDh82oon4boioIaQqyIg50D4v1YB2NTL0FRUGO9Zkd21asRMKi50nYFJ8tOAqCghmiPghpCrIy57ICinU/Wi8+rOVx0GFKZVJBr7C/YDwWnQLxvPMI8wwS5BrE+FNQQYmXMZQcUzdRYrwT/BAS6BqJN1obUklRBrsH3e6JZGqILCmoIsTLmsAPqStsVlDSWsPH4J5psHEQYIpGou2WCQEtQynyaGApqiPYoqCHEyvAzIxerL0KukJtkDHxAFeYRBk8nT5OMgQhLyHo1BfUFyK3LhZ2oOymZEG1QUEOIlYnyioKzvTPaZe24fOWyScZAS0/Wj5+pOV56HM0dzQY9N7+Ve2LoRHhIPAx6bmLdKKghxMrYie0w3H84ANMtQVFQY/2ivKMQ6RUJmUKGw0WHDXpu2spNBouCGkKskKl3QCnbIwRQewRrplyCumy4JSi5Qq5c0qJ8GqIrCmoIsUKm3AHFcRzN1NgIZbJwgeGShc9WnEVdWx08JB6YMGSCwc5LbAMFNYRYIVPO1FS2VKK2rRZikRjD/IYZ/frEeGZFzgIAnC1ngYgh8Pk0syJnwV5sb5BzEttBQQ0hVojf1p1dm40OeYdRr80HUrE+sXB2cDbqtYlxBbsHI8E/ARw4ZTdtfVE+DdEHBTWEWKEwjzC4O7pDppAhpzbHqNempSfbYsiWCa2drThSfAQA5dOQwaGghhArJBKJTLYEpQxq/CmosQV8Xo0h6tX8Xfg3OuQdCPcMR5xPnN7nI7aHghpCrBRfydfY27pppsa2zIycCRFEyKrJQllTmV7n4vNproq+CiKRyBDDIzaGghpCrJQpZmoUnIKCGhvj7eyNMcFjAAD78/frdS7KpyH6oqCGECtliqCmsL4QLZ0tcLRzRKxPrNGuS0zLEC0TKporkF6VDhFEmBM9x1BDIzaGghpCrBS/AyrvSh7aOtuMck0+gBrmNwwOdg5GuSYxPdW8Go7jBnUOviv36ODR8HPxM9jYiG2hoIYQKxXoGghfZ18oOAWyarKMck1aerJNU8OnwkHsgKKGIuTX5w/qHLT0RAyBghpCrJQpdkBdqKadT7bI1dEVE0MnAhhcywSO43okCRMyWIIENQUFBbjvvvsQFRUFZ2dnxMTE4KWXXkJHh3GLgBFi64y9A0rZ8ymQej7ZGn1aJlysvojy5nI42TthSvgUQw+N2BBBgpqsrCwoFAps2LABGRkZWLduHdavX4/nnntOiMsRQtQw5kxNp7xTucxFy0+2RxnU5O/TOa+GX3qaHjEdTvZOBh8bsR2CNNZYsGABFixYoPw+Ojoa2dnZ+OSTT7B27VohLkkI6Ycxg5rculx0yDvg5uiGcM9wwa9HzMvE0IlwtndGVUsVMqozdApsKZ+GGIrRcmoaGhrg4+Oj8RipVIrGxsYeX4SQweN3QBU2FKJJ2iTotfjAKdE/EWIRpevZGkc7R0yLmAZAt5YJHfIOHCw4CICCGqI/o/zmyc3NxQcffID7779f43GrV6+Gp6en8issLMwYwyPEavk4+yDYLRgAy1sQEu18IoOpV3Os+BhaOlsQ4BpAuVhEbzoFNc8++yxEIpHGr6ysnltHS0tLsWDBAixduhQrVqzQeP5Vq1ahoaFB+VVcXKz7KyKE9GCsJSjlzicKamwWn1dzoOAAZAqZVs/hl57mRs+lGT6iN51yap566incc889Go+Jjo5W3i4rK8OsWbMwefJkfPrppwOeXyKRQCKR6DIkQsgAEv0TsfvybsGDmvTKdAAU1Niy0UGj4eXkhfr2epwtP4vxQ8YP+BzKpyGGpFNQ4+/vD39/f62OLS0txaxZszB27Fhs3LgRYjFF4ISYAh9kCLmtu62zDbl1uT2uR2yPndgOMyNn4res37A3f++AQc2Vtis4VXYKAAU1xDAEiTRKS0sxc+ZMhIeHY+3ataiurkZFRQUqKiqEuBwhRANjLD9l1mSCAwdfZ18EugYKdh1i/mZHdm/tHsi+/H1QcAoM9xuOIR5DhB4asQGCbOnevXs3cnNzkZubi9DQ0B6PDbYvCCFkcBL8EwAA5c3lqGurg4+z5l2Ig6GaJCwSiQx+fmI5+Lyaw0WHIZVJIbFXn1JAS0/E0ASZqbnnnnvAcVy/X4QQ43KXuCPCMwIAkFElzBIU7XwivAT/BAS6BqJN1obUklSNxyqDmhgKaohhUKILITZA6CUoZXuEANqSa+tEIlGP6sLqXL5yGZevXIa92B4zImYYa3jEylFQQ4gNMFZQQzM1BOhegtJUr4ZvYDkpdBLcJe5GGRexfhTUEGIDhGxs2dDegOJGVlOKr2BMbBtfhO946XE0dzT3ewzl0xAhUFBDiA1QnakxdG4bHyiFeoTCy8nLoOcmlinKOwqRXpGQKWQ4XHS4z+NyhVy5NEX5NMSQKKghxAYM8xsGsUiM2rZaVLZUGvTctPRE+qNsmXC57xLU6fLTuNJ+BZ4ST4wLGWfsoRErRkENITbA2cEZMd4xAAy/A0oZ1PhTUEO6KZOFC/omC/P5NLOjZsNeLEhlEWKjKKghxEYIlSycXkXtEUhfsyJnAQDOlp9FXVtdj8con4YIhYIaQmyEEEENx3HU84n0K9g9GAn+CeDA4VDhIeX9zR3NOFp8FADl0xDDo6CGEBshxA6oqpYq1LbVQgQRhvsPN9h5iXXgWyYcLDyovO9I0RF0KjoR6RWpXBIlxFAoqCHERgixA4qf9YnxiYGLg4tBzkmsB59Xc6DggPI+5a6n6KuopQYxOApqCLERcb5xcBA7oKmjSVlXRl+084loMjNyJkQQ4VLtJeV9qkENIYZGQQ0hNsLRzhFDfYcCMFxeDe18Ipp4O3tjTPCYHvdl1mRChO5WCoQYEgU1hNgQfkbFUNu6L1R39XwKpJ5PpH/9BS9jQ8bC18XXBKMh1o6CGkJsiDKvplr/mRqO42j5iQyIL8KnipaeiFAoqCHEhvA7oAyx/FTUUITmjmY4iB0Q5xOn9/mIdZoaPrVPgT0KaohQKKghxIbwMyqZ1ZmQK+R6nYsPjIb5DYODnYPeYyPWydXRFROGTFB+7+zgjMlhk004ImLNKKghxIZEe0fDyd4JbbI25Nfn63UuWnoi2poRMUN5e0rYFEjsJSYcDbFmFNQQYkPsxHYY7seK5Om7BEXtEYi2ZkR2BzW064kIiYIaQmyMoXZA0UwN0Zbq8tPcqLkmHAmxdhTUEGJjDLEDSqaQIbMms8f5CFHH0c5ReTshIMGEIyHWjoIaQmyMIRpb5tblokPeARcHF0R6RRpoZIQQoh8KagixMfy27uyabHTKOwd1Dj4gSvRPhFhEv0YIIeaBfhsRYmPCPcPh5uiGTkUncupyBnUOyqchhJgjCmoIsTEikUjvJSj+eckB1B6BEGI+KKghxAbxS1CD3QFFMzWEEHNEQQ0hNkifHVDtsnblshUFNYQQc0JBDSE2SJ/lp6yaLCg4BXycfRDkFmTooRFCyKBRUEOIDeKXn3LrctEua9fpuapLTyKRyOBjI4SQwaKghhAbFOQWBB9nHyg4BbJqsnR6bnplV3sEf1p6IoSYFwpqCLFB+uyA4vNwKJ+GEGJuKKghxEbxS1A6BzW084kQYqYoqCHERikbW1Zrv627UdqIooYiAEBiQKIg4yKEkMGioIYQGzWY5Se+rk2Iewh8nH0EGRchhAwWBTWE2Ch++amgvgDNHc1aPYeWnggh5oyCGkJslK+Lr7LOzMXqi1o9RxnU0M4nQogZoqCGEBum6xIUv/MpOZB6PhFCzA8FNYTYMF13QNHyEyHEnFFQQ4gN02UHVFVLFapaqiCCCMP9hgs9NEII0RkFNYTYMF2Wn/idT9He0XB1dBV0XIQQMhgU1BBiwxL8EwAAZU1luNJ2ReOx6VVd7RFo6YkQYqYoqCHEhnlIPBDuGQ5g4CUoyqchhJg7CmoIsXHaLkFRUEMIMXcU1BBi4/iaM5qCGo7jKKghhJg9CmoIsXF8DydNy0/FjcVo6miCvdgeQ32HGmtohBCiEwpqCLFx/MxLemU6OI7r9xh+libeNx6Odo5GGxshhOiCghpCbNxwv+EQQYTatlpUtVT1ewwtPRFCLAEFNYTYOGcHZ8T4xABQn1dDQQ0hxBJQUEMIGbCyMB/UJAdQzydCiPmioIYQonEHlFwhV3bxppkaQog5o6CGEKLcAdVfUJN3JQ9SuRTO9s6I8o4y9tAIIURrFNQQQnosP/XeAZVeydojJAYkQiyiXxmEEPNFv6EIIRjqOxT2Yns0ShtR2lja4zFKEiaEWAoKagghcLRzVBbV4/NneBequ4IafwpqCCHmjYIaQgiA7pmYzJrMHvfTTA0hxFJQUEMIAdA9E6O6rbtd1o6c2hz2OAU1hBAzJ3hQI5VKMWrUKIhEIqSlpQl9OULIIPE7oFSXn3JqcyDn5PBy8kKIe4iphkYIIVoRPKj517/+hZAQ+mVIiLnjZ2KyarKU92VUZSgfE4lEJhkXIYRoS9CgZvv27di1axfWrl0r5GUIIQYQ4x0DiZ0E7bJ25X3KonuUJEwIsQD2Qp24srISK1aswG+//QYXFxetniOVSiGVSpXfNzY2CjU8QkgvdmI7DPcfjrSiNOV9F2tYUJMcSO0RCCHmT5CZGo7jcM899+CBBx7AuHHjtH7e6tWr4enpqfwKCwsTYniEEDV6JwNTewRCiCXRKah59tlnIRKJNH5lZWXhgw8+QFNTE1atWqXTYFatWoWGhgblV3FxsU7PJ4Top/cyU1FDEQAg0T/RFMMhhBCd6LT89NRTT+Gee+7ReEx0dDT27duHY8eOQSKR9Hhs3LhxuP322/H111/3+1yJRNLnOYQQ4+lvRibYLRi+Lr4mGA0hhOhGp6DG398f/v7+Ax73/vvv47XXXlN+X1ZWhvnz52PTpk1ISUnRfZSEEKPgt3WroqUnQoilECRRODw8vMf3bm5uAICYmBiEhoYKcUlCiAGEe4bD1dEVLWhR3kdBDSHEUlBFYUKIklgkxnC/4T3uo6CGEGIpBNvSrSoyMhIcxxnjUoQQPQ33G45TOKX8noIaQoiloJkaQkgPCf4JGr8nhBBzRUENIaQH1SAmwjMCbo5uJhwNIYRoj4IaQkgPqkENzdIQQiwJBTWEkB6C3IKUtymoIYRYEgpqCCE9qHbjHhs81oQjIYQQ3VBQQwhR65r4a0w9BEII0RoFNYQQtVRnbQghxNxRUEMIIYQQq0BBDSGEEEKsAgU1hBBCCLEKFNQQQgghxCpQUEMIIYQQq0BBDSGEEEKsAgU1hBBCCLEKFNQQQgghxCpQUEMIIYQQq0BBDSGEEEKsAgU1hBBCCLEKFNQQQgghxCpQUEMIIYQQq2Bv6gFownEcAKCpqQmurq4GP39LS4vydmNjI+RyucVdwxpegzWh99t8WMvrEBr9TJkPa/r/1NjYCKD777ixiDhjX1EHly9fRkxMjKmHQQghhJBByMvLQ3R0tNGuZ9YzNT4+PgCAoqIieHp6mng0xtPY2IiwsDAUFxfDw8PD1MMxGnrd9LptAb1uet22oKGhAeHh4cq/48Zi1kGNWMxSfjw9PW3qh4Hn4eFBr9uG0Ou2LfS6bYutvm7+77jRrmfUqxFCCCGECISCGkIIIYRYBbMOaiQSCV566SVIJBJTD8Wo6HXT67YF9LrpddsCet3Gfd1mvfuJEEIIIURbZj1TQwghhBCiLQpqCCGEEGIVKKghhBBCiFWgoIYQQgghVkGwoObvv//GNddcg5CQEIhEIvz22289Huc4Dv/+978RHBwMZ2dnzJ07Fzk5OT2Oqaurw+233w4PDw94eXnhvvvuQ3Nzs8brtre346GHHoKvry/c3Nxw0003obKy0tAvTy19X3dBQQHuu+8+REVFwdnZGTExMXjppZfQ0dGh8bozZ86ESCTq8fXAAw8I8RL7ZYj3OzIyss9rWLNmjcbrWvr7feDAgT6vmf86efKk2uua+/u9ZcsWzJs3D76+vhCJREhLS+tzjsG8d9r8HAlJ39ddV1eHRx55BPHx8XB2dkZ4eDgeffRRNDQ0aLzuPffc0+f9XrBggYFfnXqGeL8H8zNr6e93QUGB2n/fP/30k9rrmvP73dnZiWeeeQbJyclwdXVFSEgI7rrrLpSVlfU4h6n+fgsW1LS0tGDkyJH46KOP+n38rbfewvvvv4/169fj+PHjcHV1xfz589He3q485vbbb0dGRgZ2796NP//8E3///TdWrlyp8bpPPPEE/vjjD/z00084ePAgysrKcOONNxr0tWmi7+vOysqCQqHAhg0bkJGRgXXr1mH9+vV47rnnBrz2ihUrUF5ervx66623DPraNDHE+w0Ar7zySo/X8Mgjj2i8rqW/35MnT+7xesvLy7F8+XJERUVh3LhxGq9tzu93S0sLpk6dijfffFPtOQbz3mn7cyQUfV93WVkZysrKsHbtWly4cAFfffUVduzYgfvuu2/Aay9YsKDH+/3DDz/o9Vp0YYj3G9D9Z9bS3++wsLA+/77/85//wM3NDQsXLtR4bXN9v1tbW3HmzBm8+OKLOHPmDLZs2YLs7Gxce+21PY4z2d9vzggAcL/++qvye4VCwQUFBXFvv/228r76+npOIpFwP/zwA8dxHHfx4kUOAHfy5EnlMdu3b+dEIhFXWlra73Xq6+s5BwcH7qefflLel5mZyQHgjh07ZuBXNbDBvO7+vPXWW1xUVJTGa82YMYN77LHH9B2yQQz2dUdERHDr1q3T+jrW+H53dHRw/v7+3CuvvKLxWub8fqvKz8/nAHBnz57tcf9g3rvB/vsRymBed382b97MOTo6cp2dnWqPufvuu7nrrrtucAM1sMG+bl1/Zq31/R41ahT3j3/8Q+MxlvJ+806cOMEB4AoLCzmOM+3fb5Pk1OTn56OiogJz585V3ufp6YmUlBQcO3YMAHDs2DF4eXn1+LQ6d+5ciMViHD9+vN/znj59Gp2dnT3OO2zYMISHhyvPa0ravO7+NDQ0aNUU7LvvvoOfnx+SkpKwatUqtLa2GmTc+tLlda9Zswa+vr4YPXo03n77bchkMrXntcb3+/fff0dtbS3uvffeAc9vru+3Ngbz3g3234+5a2hogIeHB+ztNbfiO3DgAAICAhAfH48HH3wQtbW1Rhqh4ejyM2uN7/fp06eRlpam1cycJb3fDQ0NEIlE8PLyAmDav98maWhZUVEBAAgMDOxxf2BgoPKxiooKBAQE9Hjc3t4ePj4+ymP6O6+jo6Pyf2x/5zUlbV53b7m5ufjggw+wdu1ajee+7bbbEBERgZCQEJw/fx7PPPMMsrOzsWXLFsMMXg/avu5HH30UY8aMgY+PD44ePYpVq1ahvLwc77zzjtrzWtv7/cUXX2D+/PkIDQ3VeG5zfr+1MZj3bjD/P81dTU0NXn311QGn5RcsWIAbb7wRUVFRyMvLw3PPPYeFCxfi2LFjsLOzM9Jo9aPrz6w1vt9ffPEFhg8fjsmTJ2s8zpLe7/b2djzzzDO49dZblQ07Tfn326y7dNu60tJSLFiwAEuXLsWKFSs0Hqv6SzE5ORnBwcGYM2cO8vLyEBMTI/RQDeLJJ59U3h4xYgQcHR1x//33Y/Xq1TZRYrykpAQ7d+7E5s2bBzzWGt5vW9fY2IjFixcjISEBL7/8ssZjb7nlFuXt5ORkjBgxAjExMThw4ADmzJkj8EgNw9Z/Ztva2vD999/jxRdfHPBYS3m/Ozs7sWzZMnAch08++cTUwwFgoi3dQUFBANAnq7myslL5WFBQEKqqqno8LpPJUFdXpzymv/N2dHSgvr5e7XlNSZvXzSsrK8OsWbMwefJkfPrppzpfKyUlBQCb6TE1XV63qpSUFMhkMhQUFKg9r7W83wCwceNG+Pr69km404Y5vd/aGMx7N9ifI3PU1NSEBQsWwN3dHb/++iscHBx0en50dDT8/Pws5v3uz0A/s9b0fgPAzz//jNbWVtx11106P9cc328+oCksLMTu3buVszSAaf9+mySoiYqKQlBQEPbu3au8r7GxEcePH8ekSZMAAJMmTUJ9fT1Onz6tPGbfvn1QKBTKfwy9jR07Fg4ODj3Om52djaKiIuV5TUmb1w2wGZqZM2di7Nix2LhxI8Ri3d8mfmthcHCw3uPWl7avu7e0tDSIxeI+05g8a3m/AbZ1dePGjbjrrrt0/gMHmNf7rY3BvHeD/TkyN42NjZg3bx4cHR3x+++/w8nJSedzlJSUoLa21mLe7/4M9DNrLe8374svvsC1114Lf39/nZ9rbu83H9Dk5ORgz5498PX17fG4Sf9+a51SrKOmpibu7Nmz3NmzZzkA3DvvvMOdPXtWmR29Zs0azsvLi9u6dSt3/vx57rrrruOioqK4trY25TkWLFjAjR49mjt+/Dh3+PBhLi4ujrv11luVj5eUlHDx8fHc8ePHlfc98MADXHh4OLdv3z7u1KlT3KRJk7hJkyYJ9TIN/rpLSkq42NhYbs6cOVxJSQlXXl6u/FL3unNzc7lXXnmFO3XqFJefn89t3bqVi46O5qZPn24xr/vo0aPcunXruLS0NC4vL4/79ttvOX9/f+6uu+5S+7o5zvLfb96ePXs4AFxmZmafa1ji+11bW8udPXuW27ZtGweA+/HHH7mzZ8/2+DnW5r2Lj4/ntmzZovxe2/+f5vq6GxoauJSUFC45OZnLzc3t8e9bJpP1+7qbmpq4//u//+OOHTvG5efnc3v27OHGjBnDxcXFce3t7RbxurX9mbW295uXk5PDiUQibvv27f1ex5Le746ODu7aa6/lQkNDubS0tB4/w1KpVHkOU/39Fiyo2b9/Pwegz9fdd9/NcRzbrvfiiy9ygYGBnEQi4ebMmcNlZ2f3OEdtbS136623cm5ubpyHhwd37733ck1NTcrH+W10+/fvV97X1tbG/fOf/+S8vb05FxcX7oYbbujzAyYkfV/3xo0b+32+avzZ+3UXFRVx06dP53x8fDiJRMLFxsZyTz/9NNfQ0GAxr/v06dNcSkoK5+npyTk5OXHDhw/n3njjjR7/iK3x/ebdeuut3OTJk/u9hiW+3+p+jl966SXlObR57wBwGzduVH6v7f9Poej7utU9HwCXn5/f7+tubW3l5s2bx/n7+3MODg5cREQEt2LFCq6iosJiXre2P7PW9n7zVq1axYWFhXFyubzf61jS+83/PurvS/V3s6n+fos4juPUzeIQQgghhFgK6v1ECCGEEKtAQQ0hhBBCrAIFNYQQQgixChTUEEIIIcQqUFBDCCGEEKtAQQ0hhBBCrAIFNYQQQgixChTUEEIIIcQqUFBDCCGEEKtAQQ0hhBBCrAIFNYQQQgixChTUEEIIIcQq/D9W9+l0FSjGcwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(initial_history)\n",
    "ax.plot(final_history, color = \"red\")\n",
    "ax.plot(improvement_history, color = \"green\")\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "for point in drift_data:\n",
    "    plt.axvline(point, color = \"black\")\n",
    "ax.set_xlim(100,120)  # Expand the x-axis range\n",
    "# ax.set_ylim(-2, 2)  # Expand the y-axis range\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15187835-4a25-48b3-ab22-855c5f516332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_72433_row0_col0, #T_72433_row0_col3, #T_72433_row0_col5, #T_72433_row0_col7, #T_72433_row0_col15, #T_72433_row0_col17, #T_72433_row1_col1, #T_72433_row2_col7, #T_72433_row2_col9, #T_72433_row2_col11, #T_72433_row3_col0, #T_72433_row3_col3, #T_72433_row3_col4, #T_72433_row3_col6, #T_72433_row3_col7, #T_72433_row3_col11, #T_72433_row3_col12, #T_72433_row3_col18, #T_72433_row4_col7, #T_72433_row4_col19, #T_72433_row5_col0, #T_72433_row5_col7, #T_72433_row6_col3, #T_72433_row6_col9, #T_72433_row7_col16, #T_72433_row8_col0, #T_72433_row8_col12, #T_72433_row8_col14, #T_72433_row10_col0 {\n",
       "  background-color: green;\n",
       "}\n",
       "#T_72433_row0_col2, #T_72433_row1_col11, #T_72433_row2_col0, #T_72433_row3_col5, #T_72433_row4_col11, #T_72433_row5_col5, #T_72433_row6_col0, #T_72433_row7_col0, #T_72433_row8_col1, #T_72433_row9_col0, #T_72433_row9_col1, #T_72433_row9_col2, #T_72433_row9_col3, #T_72433_row9_col4, #T_72433_row9_col5, #T_72433_row9_col6, #T_72433_row9_col7, #T_72433_row9_col8, #T_72433_row9_col10, #T_72433_row9_col11, #T_72433_row9_col12, #T_72433_row9_col13, #T_72433_row9_col14, #T_72433_row9_col15, #T_72433_row9_col16, #T_72433_row9_col17, #T_72433_row9_col18, #T_72433_row9_col19, #T_72433_row9_col20, #T_72433_row10_col20 {\n",
       "  background-color: blue;\n",
       "}\n",
       "#T_72433_row0_col4, #T_72433_row0_col6, #T_72433_row0_col14, #T_72433_row1_col9, #T_72433_row2_col2, #T_72433_row2_col4, #T_72433_row2_col15, #T_72433_row3_col10, #T_72433_row3_col13, #T_72433_row5_col2, #T_72433_row5_col6, #T_72433_row5_col8, #T_72433_row8_col10, #T_72433_row9_col9 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_72433\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_72433_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_72433_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_72433_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_72433_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_72433_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "      <th id=\"T_72433_level0_col5\" class=\"col_heading level0 col5\" >5</th>\n",
       "      <th id=\"T_72433_level0_col6\" class=\"col_heading level0 col6\" >6</th>\n",
       "      <th id=\"T_72433_level0_col7\" class=\"col_heading level0 col7\" >7</th>\n",
       "      <th id=\"T_72433_level0_col8\" class=\"col_heading level0 col8\" >8</th>\n",
       "      <th id=\"T_72433_level0_col9\" class=\"col_heading level0 col9\" >9</th>\n",
       "      <th id=\"T_72433_level0_col10\" class=\"col_heading level0 col10\" >10</th>\n",
       "      <th id=\"T_72433_level0_col11\" class=\"col_heading level0 col11\" >11</th>\n",
       "      <th id=\"T_72433_level0_col12\" class=\"col_heading level0 col12\" >12</th>\n",
       "      <th id=\"T_72433_level0_col13\" class=\"col_heading level0 col13\" >13</th>\n",
       "      <th id=\"T_72433_level0_col14\" class=\"col_heading level0 col14\" >14</th>\n",
       "      <th id=\"T_72433_level0_col15\" class=\"col_heading level0 col15\" >15</th>\n",
       "      <th id=\"T_72433_level0_col16\" class=\"col_heading level0 col16\" >16</th>\n",
       "      <th id=\"T_72433_level0_col17\" class=\"col_heading level0 col17\" >17</th>\n",
       "      <th id=\"T_72433_level0_col18\" class=\"col_heading level0 col18\" >18</th>\n",
       "      <th id=\"T_72433_level0_col19\" class=\"col_heading level0 col19\" >19</th>\n",
       "      <th id=\"T_72433_level0_col20\" class=\"col_heading level0 col20\" >20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_72433_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_72433_row0_col0\" class=\"data row0 col0\" >0.887810</td>\n",
       "      <td id=\"T_72433_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_72433_row0_col2\" class=\"data row0 col2\" >1.072370</td>\n",
       "      <td id=\"T_72433_row0_col3\" class=\"data row0 col3\" >0.161596</td>\n",
       "      <td id=\"T_72433_row0_col4\" class=\"data row0 col4\" >-0.114048</td>\n",
       "      <td id=\"T_72433_row0_col5\" class=\"data row0 col5\" >0.203232</td>\n",
       "      <td id=\"T_72433_row0_col6\" class=\"data row0 col6\" >-0.029634</td>\n",
       "      <td id=\"T_72433_row0_col7\" class=\"data row0 col7\" >0.371479</td>\n",
       "      <td id=\"T_72433_row0_col8\" class=\"data row0 col8\" >0.000000</td>\n",
       "      <td id=\"T_72433_row0_col9\" class=\"data row0 col9\" >0.000000</td>\n",
       "      <td id=\"T_72433_row0_col10\" class=\"data row0 col10\" >0.000000</td>\n",
       "      <td id=\"T_72433_row0_col11\" class=\"data row0 col11\" >0.000000</td>\n",
       "      <td id=\"T_72433_row0_col12\" class=\"data row0 col12\" >0.000000</td>\n",
       "      <td id=\"T_72433_row0_col13\" class=\"data row0 col13\" >0.000000</td>\n",
       "      <td id=\"T_72433_row0_col14\" class=\"data row0 col14\" >-0.186330</td>\n",
       "      <td id=\"T_72433_row0_col15\" class=\"data row0 col15\" >0.140999</td>\n",
       "      <td id=\"T_72433_row0_col16\" class=\"data row0 col16\" >0.000000</td>\n",
       "      <td id=\"T_72433_row0_col17\" class=\"data row0 col17\" >0.186337</td>\n",
       "      <td id=\"T_72433_row0_col18\" class=\"data row0 col18\" >0.000000</td>\n",
       "      <td id=\"T_72433_row0_col19\" class=\"data row0 col19\" >0.000000</td>\n",
       "      <td id=\"T_72433_row0_col20\" class=\"data row0 col20\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72433_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_72433_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "      <td id=\"T_72433_row1_col1\" class=\"data row1 col1\" >0.128117</td>\n",
       "      <td id=\"T_72433_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
       "      <td id=\"T_72433_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "      <td id=\"T_72433_row1_col4\" class=\"data row1 col4\" >0.000000</td>\n",
       "      <td id=\"T_72433_row1_col5\" class=\"data row1 col5\" >0.000000</td>\n",
       "      <td id=\"T_72433_row1_col6\" class=\"data row1 col6\" >0.000000</td>\n",
       "      <td id=\"T_72433_row1_col7\" class=\"data row1 col7\" >0.000000</td>\n",
       "      <td id=\"T_72433_row1_col8\" class=\"data row1 col8\" >0.000000</td>\n",
       "      <td id=\"T_72433_row1_col9\" class=\"data row1 col9\" >-0.161843</td>\n",
       "      <td id=\"T_72433_row1_col10\" class=\"data row1 col10\" >0.000000</td>\n",
       "      <td id=\"T_72433_row1_col11\" class=\"data row1 col11\" >0.163531</td>\n",
       "      <td id=\"T_72433_row1_col12\" class=\"data row1 col12\" >0.000000</td>\n",
       "      <td id=\"T_72433_row1_col13\" class=\"data row1 col13\" >0.000000</td>\n",
       "      <td id=\"T_72433_row1_col14\" class=\"data row1 col14\" >0.000000</td>\n",
       "      <td id=\"T_72433_row1_col15\" class=\"data row1 col15\" >0.000000</td>\n",
       "      <td id=\"T_72433_row1_col16\" class=\"data row1 col16\" >0.000000</td>\n",
       "      <td id=\"T_72433_row1_col17\" class=\"data row1 col17\" >0.000000</td>\n",
       "      <td id=\"T_72433_row1_col18\" class=\"data row1 col18\" >0.000000</td>\n",
       "      <td id=\"T_72433_row1_col19\" class=\"data row1 col19\" >0.000000</td>\n",
       "      <td id=\"T_72433_row1_col20\" class=\"data row1 col20\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72433_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_72433_row2_col0\" class=\"data row2 col0\" >1.139353</td>\n",
       "      <td id=\"T_72433_row2_col1\" class=\"data row2 col1\" >0.000000</td>\n",
       "      <td id=\"T_72433_row2_col2\" class=\"data row2 col2\" >-0.126210</td>\n",
       "      <td id=\"T_72433_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n",
       "      <td id=\"T_72433_row2_col4\" class=\"data row2 col4\" >-0.010420</td>\n",
       "      <td id=\"T_72433_row2_col5\" class=\"data row2 col5\" >0.000000</td>\n",
       "      <td id=\"T_72433_row2_col6\" class=\"data row2 col6\" >0.000000</td>\n",
       "      <td id=\"T_72433_row2_col7\" class=\"data row2 col7\" >0.074580</td>\n",
       "      <td id=\"T_72433_row2_col8\" class=\"data row2 col8\" >0.000000</td>\n",
       "      <td id=\"T_72433_row2_col9\" class=\"data row2 col9\" >0.104580</td>\n",
       "      <td id=\"T_72433_row2_col10\" class=\"data row2 col10\" >0.000000</td>\n",
       "      <td id=\"T_72433_row2_col11\" class=\"data row2 col11\" >0.078580</td>\n",
       "      <td id=\"T_72433_row2_col12\" class=\"data row2 col12\" >0.000000</td>\n",
       "      <td id=\"T_72433_row2_col13\" class=\"data row2 col13\" >0.000000</td>\n",
       "      <td id=\"T_72433_row2_col14\" class=\"data row2 col14\" >0.000000</td>\n",
       "      <td id=\"T_72433_row2_col15\" class=\"data row2 col15\" >-0.351405</td>\n",
       "      <td id=\"T_72433_row2_col16\" class=\"data row2 col16\" >0.000000</td>\n",
       "      <td id=\"T_72433_row2_col17\" class=\"data row2 col17\" >0.000000</td>\n",
       "      <td id=\"T_72433_row2_col18\" class=\"data row2 col18\" >0.000000</td>\n",
       "      <td id=\"T_72433_row2_col19\" class=\"data row2 col19\" >0.000000</td>\n",
       "      <td id=\"T_72433_row2_col20\" class=\"data row2 col20\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72433_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_72433_row3_col0\" class=\"data row3 col0\" >0.772120</td>\n",
       "      <td id=\"T_72433_row3_col1\" class=\"data row3 col1\" >0.000000</td>\n",
       "      <td id=\"T_72433_row3_col2\" class=\"data row3 col2\" >0.000000</td>\n",
       "      <td id=\"T_72433_row3_col3\" class=\"data row3 col3\" >0.149682</td>\n",
       "      <td id=\"T_72433_row3_col4\" class=\"data row3 col4\" >0.108130</td>\n",
       "      <td id=\"T_72433_row3_col5\" class=\"data row3 col5\" >2.066880</td>\n",
       "      <td id=\"T_72433_row3_col6\" class=\"data row3 col6\" >0.138196</td>\n",
       "      <td id=\"T_72433_row3_col7\" class=\"data row3 col7\" >0.152025</td>\n",
       "      <td id=\"T_72433_row3_col8\" class=\"data row3 col8\" >0.000000</td>\n",
       "      <td id=\"T_72433_row3_col9\" class=\"data row3 col9\" >0.000000</td>\n",
       "      <td id=\"T_72433_row3_col10\" class=\"data row3 col10\" >-0.032159</td>\n",
       "      <td id=\"T_72433_row3_col11\" class=\"data row3 col11\" >0.130025</td>\n",
       "      <td id=\"T_72433_row3_col12\" class=\"data row3 col12\" >0.279682</td>\n",
       "      <td id=\"T_72433_row3_col13\" class=\"data row3 col13\" >-0.086894</td>\n",
       "      <td id=\"T_72433_row3_col14\" class=\"data row3 col14\" >0.000000</td>\n",
       "      <td id=\"T_72433_row3_col15\" class=\"data row3 col15\" >0.000000</td>\n",
       "      <td id=\"T_72433_row3_col16\" class=\"data row3 col16\" >0.000000</td>\n",
       "      <td id=\"T_72433_row3_col17\" class=\"data row3 col17\" >0.000000</td>\n",
       "      <td id=\"T_72433_row3_col18\" class=\"data row3 col18\" >0.202161</td>\n",
       "      <td id=\"T_72433_row3_col19\" class=\"data row3 col19\" >0.000000</td>\n",
       "      <td id=\"T_72433_row3_col20\" class=\"data row3 col20\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72433_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_72433_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "      <td id=\"T_72433_row4_col1\" class=\"data row4 col1\" >0.000000</td>\n",
       "      <td id=\"T_72433_row4_col2\" class=\"data row4 col2\" >0.000000</td>\n",
       "      <td id=\"T_72433_row4_col3\" class=\"data row4 col3\" >0.000000</td>\n",
       "      <td id=\"T_72433_row4_col4\" class=\"data row4 col4\" >0.000000</td>\n",
       "      <td id=\"T_72433_row4_col5\" class=\"data row4 col5\" >0.000000</td>\n",
       "      <td id=\"T_72433_row4_col6\" class=\"data row4 col6\" >0.000000</td>\n",
       "      <td id=\"T_72433_row4_col7\" class=\"data row4 col7\" >0.015949</td>\n",
       "      <td id=\"T_72433_row4_col8\" class=\"data row4 col8\" >0.000000</td>\n",
       "      <td id=\"T_72433_row4_col9\" class=\"data row4 col9\" >0.000000</td>\n",
       "      <td id=\"T_72433_row4_col10\" class=\"data row4 col10\" >0.000000</td>\n",
       "      <td id=\"T_72433_row4_col11\" class=\"data row4 col11\" >0.095246</td>\n",
       "      <td id=\"T_72433_row4_col12\" class=\"data row4 col12\" >0.000000</td>\n",
       "      <td id=\"T_72433_row4_col13\" class=\"data row4 col13\" >0.000000</td>\n",
       "      <td id=\"T_72433_row4_col14\" class=\"data row4 col14\" >0.000000</td>\n",
       "      <td id=\"T_72433_row4_col15\" class=\"data row4 col15\" >0.000000</td>\n",
       "      <td id=\"T_72433_row4_col16\" class=\"data row4 col16\" >0.000000</td>\n",
       "      <td id=\"T_72433_row4_col17\" class=\"data row4 col17\" >0.000000</td>\n",
       "      <td id=\"T_72433_row4_col18\" class=\"data row4 col18\" >0.000000</td>\n",
       "      <td id=\"T_72433_row4_col19\" class=\"data row4 col19\" >0.023537</td>\n",
       "      <td id=\"T_72433_row4_col20\" class=\"data row4 col20\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72433_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_72433_row5_col0\" class=\"data row5 col0\" >0.096716</td>\n",
       "      <td id=\"T_72433_row5_col1\" class=\"data row5 col1\" >0.000000</td>\n",
       "      <td id=\"T_72433_row5_col2\" class=\"data row5 col2\" >-0.016908</td>\n",
       "      <td id=\"T_72433_row5_col3\" class=\"data row5 col3\" >0.000000</td>\n",
       "      <td id=\"T_72433_row5_col4\" class=\"data row5 col4\" >0.000000</td>\n",
       "      <td id=\"T_72433_row5_col5\" class=\"data row5 col5\" >0.247048</td>\n",
       "      <td id=\"T_72433_row5_col6\" class=\"data row5 col6\" >-0.211766</td>\n",
       "      <td id=\"T_72433_row5_col7\" class=\"data row5 col7\" >0.056092</td>\n",
       "      <td id=\"T_72433_row5_col8\" class=\"data row5 col8\" >-0.237028</td>\n",
       "      <td id=\"T_72433_row5_col9\" class=\"data row5 col9\" >0.000000</td>\n",
       "      <td id=\"T_72433_row5_col10\" class=\"data row5 col10\" >0.000000</td>\n",
       "      <td id=\"T_72433_row5_col11\" class=\"data row5 col11\" >0.000000</td>\n",
       "      <td id=\"T_72433_row5_col12\" class=\"data row5 col12\" >0.000000</td>\n",
       "      <td id=\"T_72433_row5_col13\" class=\"data row5 col13\" >0.000000</td>\n",
       "      <td id=\"T_72433_row5_col14\" class=\"data row5 col14\" >0.000000</td>\n",
       "      <td id=\"T_72433_row5_col15\" class=\"data row5 col15\" >0.000000</td>\n",
       "      <td id=\"T_72433_row5_col16\" class=\"data row5 col16\" >0.000000</td>\n",
       "      <td id=\"T_72433_row5_col17\" class=\"data row5 col17\" >0.000000</td>\n",
       "      <td id=\"T_72433_row5_col18\" class=\"data row5 col18\" >0.000000</td>\n",
       "      <td id=\"T_72433_row5_col19\" class=\"data row5 col19\" >0.000000</td>\n",
       "      <td id=\"T_72433_row5_col20\" class=\"data row5 col20\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72433_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_72433_row6_col0\" class=\"data row6 col0\" >0.354000</td>\n",
       "      <td id=\"T_72433_row6_col1\" class=\"data row6 col1\" >0.000000</td>\n",
       "      <td id=\"T_72433_row6_col2\" class=\"data row6 col2\" >0.000000</td>\n",
       "      <td id=\"T_72433_row6_col3\" class=\"data row6 col3\" >0.042860</td>\n",
       "      <td id=\"T_72433_row6_col4\" class=\"data row6 col4\" >0.000000</td>\n",
       "      <td id=\"T_72433_row6_col5\" class=\"data row6 col5\" >0.000000</td>\n",
       "      <td id=\"T_72433_row6_col6\" class=\"data row6 col6\" >0.000000</td>\n",
       "      <td id=\"T_72433_row6_col7\" class=\"data row6 col7\" >0.000000</td>\n",
       "      <td id=\"T_72433_row6_col8\" class=\"data row6 col8\" >0.000000</td>\n",
       "      <td id=\"T_72433_row6_col9\" class=\"data row6 col9\" >0.003860</td>\n",
       "      <td id=\"T_72433_row6_col10\" class=\"data row6 col10\" >0.000000</td>\n",
       "      <td id=\"T_72433_row6_col11\" class=\"data row6 col11\" >0.000000</td>\n",
       "      <td id=\"T_72433_row6_col12\" class=\"data row6 col12\" >0.000000</td>\n",
       "      <td id=\"T_72433_row6_col13\" class=\"data row6 col13\" >0.000000</td>\n",
       "      <td id=\"T_72433_row6_col14\" class=\"data row6 col14\" >0.000000</td>\n",
       "      <td id=\"T_72433_row6_col15\" class=\"data row6 col15\" >0.000000</td>\n",
       "      <td id=\"T_72433_row6_col16\" class=\"data row6 col16\" >0.000000</td>\n",
       "      <td id=\"T_72433_row6_col17\" class=\"data row6 col17\" >0.000000</td>\n",
       "      <td id=\"T_72433_row6_col18\" class=\"data row6 col18\" >0.000000</td>\n",
       "      <td id=\"T_72433_row6_col19\" class=\"data row6 col19\" >0.000000</td>\n",
       "      <td id=\"T_72433_row6_col20\" class=\"data row6 col20\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72433_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_72433_row7_col0\" class=\"data row7 col0\" >1.014042</td>\n",
       "      <td id=\"T_72433_row7_col1\" class=\"data row7 col1\" >0.000000</td>\n",
       "      <td id=\"T_72433_row7_col2\" class=\"data row7 col2\" >0.000000</td>\n",
       "      <td id=\"T_72433_row7_col3\" class=\"data row7 col3\" >0.000000</td>\n",
       "      <td id=\"T_72433_row7_col4\" class=\"data row7 col4\" >0.000000</td>\n",
       "      <td id=\"T_72433_row7_col5\" class=\"data row7 col5\" >0.000000</td>\n",
       "      <td id=\"T_72433_row7_col6\" class=\"data row7 col6\" >0.000000</td>\n",
       "      <td id=\"T_72433_row7_col7\" class=\"data row7 col7\" >0.000000</td>\n",
       "      <td id=\"T_72433_row7_col8\" class=\"data row7 col8\" >0.000000</td>\n",
       "      <td id=\"T_72433_row7_col9\" class=\"data row7 col9\" >0.000000</td>\n",
       "      <td id=\"T_72433_row7_col10\" class=\"data row7 col10\" >0.000000</td>\n",
       "      <td id=\"T_72433_row7_col11\" class=\"data row7 col11\" >0.000000</td>\n",
       "      <td id=\"T_72433_row7_col12\" class=\"data row7 col12\" >0.000000</td>\n",
       "      <td id=\"T_72433_row7_col13\" class=\"data row7 col13\" >0.000000</td>\n",
       "      <td id=\"T_72433_row7_col14\" class=\"data row7 col14\" >0.000000</td>\n",
       "      <td id=\"T_72433_row7_col15\" class=\"data row7 col15\" >0.000000</td>\n",
       "      <td id=\"T_72433_row7_col16\" class=\"data row7 col16\" >0.089750</td>\n",
       "      <td id=\"T_72433_row7_col17\" class=\"data row7 col17\" >0.000000</td>\n",
       "      <td id=\"T_72433_row7_col18\" class=\"data row7 col18\" >0.000000</td>\n",
       "      <td id=\"T_72433_row7_col19\" class=\"data row7 col19\" >0.000000</td>\n",
       "      <td id=\"T_72433_row7_col20\" class=\"data row7 col20\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72433_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_72433_row8_col0\" class=\"data row8 col0\" >0.044463</td>\n",
       "      <td id=\"T_72433_row8_col1\" class=\"data row8 col1\" >0.221952</td>\n",
       "      <td id=\"T_72433_row8_col2\" class=\"data row8 col2\" >0.000000</td>\n",
       "      <td id=\"T_72433_row8_col3\" class=\"data row8 col3\" >0.000000</td>\n",
       "      <td id=\"T_72433_row8_col4\" class=\"data row8 col4\" >0.000000</td>\n",
       "      <td id=\"T_72433_row8_col5\" class=\"data row8 col5\" >0.000000</td>\n",
       "      <td id=\"T_72433_row8_col6\" class=\"data row8 col6\" >0.000000</td>\n",
       "      <td id=\"T_72433_row8_col7\" class=\"data row8 col7\" >0.000000</td>\n",
       "      <td id=\"T_72433_row8_col8\" class=\"data row8 col8\" >0.000000</td>\n",
       "      <td id=\"T_72433_row8_col9\" class=\"data row8 col9\" >0.000000</td>\n",
       "      <td id=\"T_72433_row8_col10\" class=\"data row8 col10\" >-0.123305</td>\n",
       "      <td id=\"T_72433_row8_col11\" class=\"data row8 col11\" >0.000000</td>\n",
       "      <td id=\"T_72433_row8_col12\" class=\"data row8 col12\" >0.118832</td>\n",
       "      <td id=\"T_72433_row8_col13\" class=\"data row8 col13\" >0.000000</td>\n",
       "      <td id=\"T_72433_row8_col14\" class=\"data row8 col14\" >0.033325</td>\n",
       "      <td id=\"T_72433_row8_col15\" class=\"data row8 col15\" >0.000000</td>\n",
       "      <td id=\"T_72433_row8_col16\" class=\"data row8 col16\" >0.000000</td>\n",
       "      <td id=\"T_72433_row8_col17\" class=\"data row8 col17\" >0.000000</td>\n",
       "      <td id=\"T_72433_row8_col18\" class=\"data row8 col18\" >0.000000</td>\n",
       "      <td id=\"T_72433_row8_col19\" class=\"data row8 col19\" >0.000000</td>\n",
       "      <td id=\"T_72433_row8_col20\" class=\"data row8 col20\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72433_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_72433_row9_col0\" class=\"data row9 col0\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col1\" class=\"data row9 col1\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col2\" class=\"data row9 col2\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col3\" class=\"data row9 col3\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col4\" class=\"data row9 col4\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col5\" class=\"data row9 col5\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col6\" class=\"data row9 col6\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col7\" class=\"data row9 col7\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col8\" class=\"data row9 col8\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col9\" class=\"data row9 col9\" >-0.022000</td>\n",
       "      <td id=\"T_72433_row9_col10\" class=\"data row9 col10\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col11\" class=\"data row9 col11\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col12\" class=\"data row9 col12\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col13\" class=\"data row9 col13\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col14\" class=\"data row9 col14\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col15\" class=\"data row9 col15\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col16\" class=\"data row9 col16\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col17\" class=\"data row9 col17\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col18\" class=\"data row9 col18\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col19\" class=\"data row9 col19\" >0.000000</td>\n",
       "      <td id=\"T_72433_row9_col20\" class=\"data row9 col20\" >0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72433_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_72433_row10_col0\" class=\"data row10 col0\" >0.010000</td>\n",
       "      <td id=\"T_72433_row10_col1\" class=\"data row10 col1\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col2\" class=\"data row10 col2\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col3\" class=\"data row10 col3\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col4\" class=\"data row10 col4\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col5\" class=\"data row10 col5\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col6\" class=\"data row10 col6\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col7\" class=\"data row10 col7\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col8\" class=\"data row10 col8\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col9\" class=\"data row10 col9\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col10\" class=\"data row10 col10\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col11\" class=\"data row10 col11\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col12\" class=\"data row10 col12\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col13\" class=\"data row10 col13\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col14\" class=\"data row10 col14\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col15\" class=\"data row10 col15\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col16\" class=\"data row10 col16\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col17\" class=\"data row10 col17\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col18\" class=\"data row10 col18\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col19\" class=\"data row10 col19\" >0.000000</td>\n",
       "      <td id=\"T_72433_row10_col20\" class=\"data row10 col20\" >0.037101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f974d1ef8b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def highlight_max_and_threshold(row):\n",
    "    max_value = row.max()  # Find the max value in the row\n",
    "    styles = []\n",
    "    for value in row:\n",
    "        if value == max_value:\n",
    "            styles.append('background-color: blue')  # Highlight max value\n",
    "        elif value > 0.0:\n",
    "            styles.append('background-color: green')  # Highlight values over threshold\n",
    "        elif value < 0.0:\n",
    "            styles.append('background-color: red')\n",
    "        else:\n",
    "            styles.append('')  # No styling for other cells\n",
    "            \n",
    "    return styles\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "\n",
    "df = pd.DataFrame(obj.q_table[:,:obj.number_of_actions])\n",
    "styled_df = df.head(len(obj.state_ref_data)).style.apply(highlight_max_and_threshold, axis = 1)\n",
    "\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "986a2ab1-6b76-459e-ac98-e5a319f3f9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0867730670144624"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f88c75d-3677-419e-9002-d12630a4d707",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart_failure_clinical_records_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33a6639-c016-4e2e-9e8e-a2b98cd53734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... 100%\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i in range(1, 6):\n",
    "    print(f\"\\rLoading... {i*20}%\", end=\"\")\n",
    "    time.sleep(1)\n",
    "print(\"\\nDone!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
